<!doctype html><html lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>Prompt Engineering完全指南：从提示工程到上下文工程的实战教程 - 每日深度思考 | 技术、经济分析与深度思考</title><meta name=Description content="全面掌握Prompt Engineering与Context Engineering核心技术：从基础提示词设计到高级上下文管理，包括RAG、上下文优化、持久化等技术。解决实际开发中的污染问题、注意力偏移等挑战，提升AI应用效果。"><meta property="og:url" content="https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B3/"><meta property="og:site_name" content="每日深度思考 | 技术、经济分析与深度思考"><meta property="og:title" content="Prompt Engineering完全指南：从提示工程到上下文工程的实战教程"><meta property="og:description" content="全面掌握Prompt Engineering与Context Engineering核心技术：从基础提示词设计到高级上下文管理，包括RAG、上下文优化、持久化等技术。解决实际开发中的污染问题、注意力偏移等挑战，提升AI应用效果。"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-11-05T09:58:24+08:00"><meta property="article:modified_time" content="2025-11-06T13:19:28+08:00"><meta property="article:tag" content="Prompt Engineering"><meta property="article:tag" content="Context Engineering"><meta property="article:tag" content="提示词工程"><meta property="article:tag" content="上下文工程"><meta property="article:tag" content="RAG"><meta property="article:tag" content="检索增强生成"><meta property="og:image" content="https://byronfinn.github.io/static/avatar/angryCat.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://byronfinn.github.io/static/avatar/angryCat.png"><meta name=twitter:title content="Prompt Engineering完全指南：从提示工程到上下文工程的实战教程"><meta name=twitter:description content="全面掌握Prompt Engineering与Context Engineering核心技术：从基础提示词设计到高级上下文管理，包括RAG、上下文优化、持久化等技术。解决实际开发中的污染问题、注意力偏移等挑战，提升AI应用效果。"><meta name=application-name content="Daily Deep Think"><meta name=apple-mobile-web-app-title content="Daily Deep Think"><meta name=theme-color content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel=icon href=/static/icos/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B3/><link rel=prev href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B4/><link rel=next href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B2/><link rel=stylesheet href=/css/main.min.css><link rel=stylesheet href=/css/style.min.css><meta name=google-site-verification content="google8f3e688b6959e353"><meta name=msvalidate.01 content="请在此添加你的Bing验证码"><meta name=yandex-verification content="请在此添加你的Yandex验证码"><meta name=p:domain_verify content="请在此添加你的Pinterest验证码"><meta name=baidu-site-verification content="请在此添加你的百度验证码"><meta name=sogou_site_verification content="请在此添加你的搜狗验证码"><meta name=360-site-verification content="请在此添加你的360搜索验证码"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Prompt Engineering完全指南：从提示工程到上下文工程的实战教程","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B3/"},"image":["https://byronfinn.github.io/static/avatar/angryCat.png"],"genre":"posts","keywords":["Prompt Engineering","Context Engineering","提示词工程","上下文工程","RAG","检索增强生成","AI应用开发","LLM优化","上下文管理","人工智能"],"wordcount":3306,"url":"https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B3/","datePublished":"2025-11-05T09:58:24+08:00","dateModified":"2025-11-06T13:19:28+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Finn","url":"https://blog.baifan.site"},"description":"全面掌握Prompt Engineering与Context Engineering核心技术：从基础提示词设计到高级上下文管理，包括RAG、上下文优化、持久化等技术。解决实际开发中的污染问题、注意力偏移等挑战，提升AI应用效果。"}</script></head><body data-instant-intensity=viewport class="tw-flex tw-min-h-screen tw-flex-col"><script>function setTheme(e){document.body.setAttribute("theme",e),document.documentElement.className=e,document.documentElement.style.setProperty("color-scheme",e==="light"?"light":"dark"),e==="light"?document.documentElement.classList.remove("tw-dark"):document.documentElement.classList.add("tw-dark"),window.theme=e,window.isDark=window.theme!=="light"}function saveTheme(e){window.localStorage&&localStorage.setItem("theme",e)}function getMeta(e){const t=document.getElementsByTagName("meta");for(let n=0;n<t.length;n++)if(t[n].getAttribute("name")===e)return t[n];return""}if(window.localStorage&&localStorage.getItem("theme")){let e=localStorage.getItem("theme");e==="light"||e==="dark"?setTheme(e):setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")}else"auto"==="light"||"auto"==="dark"?(setTheme("auto"),saveTheme("auto")):(saveTheme("auto"),setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"));let metaColors={light:"#f8f8f8",dark:"#161b22"};getMeta("theme-color").content=metaColors[document.body.getAttribute("theme")],window.switchThemeEventSet=new Set</script><div id=back-to-top></div><div id=mask></div><header class="desktop print:!tw-hidden" id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="每日深度思考 | 技术、经济分析与深度思考"><span id=desktop-header-typeit class=typeit></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/profile/ title=了解我的个人信息和专业背景>关于我 </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder=搜索... id=search-input-desktop>
<button class="search-button search-toggle" id=search-toggle-desktop title=搜索>
<svg class="icon" viewBox="0 0 512 512"><path d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</button>
<button class="search-button search-clear" id=search-clear-desktop title=清空>
<svg class="icon" viewBox="0 0 512 512"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm121.6 313.1c4.7 4.7 4.7 12.3.0 17L338 377.6c-4.7 4.7-12.3 4.7-17 0L256 312l-65.1 65.6c-4.7 4.7-12.3 4.7-17 0L134.4 338c-4.7-4.7-4.7-12.3.0-17l65.6-65-65.6-65.1c-4.7-4.7-4.7-12.3.0-17l39.6-39.6c4.7-4.7 12.3-4.7 17 0l65 65.7 65.1-65.6c4.7-4.7 12.3-4.7 17 0l39.6 39.6c4.7 4.7 4.7 12.3.0 17L312 256l65.6 65.1z"/></svg>
</button>
<span class="search-button search-loading tw-animate-spin" id=search-loading-desktop><svg class="icon" viewBox="0 0 512 512"><path d="M304 48c0 26.51-21.49 48-48 48s-48-21.49-48-48 21.49-48 48-48 48 21.49 48 48zm-48 368c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm208-208c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zM96 256c0-26.51-21.49-48-48-48S0 229.49.0 256s21.49 48 48 48 48-21.49 48-48zm12.922 99.078c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.491-48-48-48zm294.156.0c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.49-48-48-48zM108.922 60.922c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.491-48-48-48z"/></svg>
</span></span><button class="menu-item theme-switch" aria-label=切换主题>
<svg class="icon" viewBox="0 0 512 512"><path d="M8 256c0 136.966 111.033 248 248 248s248-111.034 248-248S392.966 8 256 8 8 119.033 8 256zm248 184V72c101.705.0 184 82.311 184 184 0 101.705-82.311 184-184 184z"/></svg></button></div></div></div></header><header class="mobile print:!tw-hidden" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="每日深度思考 | 技术、经济分析与深度思考"><span id=mobile-header-typeit class=typeit></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索... id=search-input-mobile>
<button class="search-button search-toggle tw-h-10" id=search-toggle-mobile title=搜索>
<svg class="icon" viewBox="0 0 512 512"><path d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</button>
<button class="search-button search-clear tw-h-fit" id=search-clear-mobile title=清空>
<svg class="icon" viewBox="0 0 512 512"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm121.6 313.1c4.7 4.7 4.7 12.3.0 17L338 377.6c-4.7 4.7-12.3 4.7-17 0L256 312l-65.1 65.6c-4.7 4.7-12.3 4.7-17 0L134.4 338c-4.7-4.7-4.7-12.3.0-17l65.6-65-65.6-65.1c-4.7-4.7-4.7-12.3.0-17l39.6-39.6c4.7-4.7 12.3-4.7 17 0l65 65.7 65.1-65.6c4.7-4.7 12.3-4.7 17 0l39.6 39.6c4.7 4.7 4.7 12.3.0 17L312 256l65.6 65.1z"/></svg>
</button>
<span class="search-button search-loading tw-animate-spin" id=search-loading-mobile><svg class="icon" viewBox="0 0 512 512"><path d="M304 48c0 26.51-21.49 48-48 48s-48-21.49-48-48 21.49-48 48-48 48 21.49 48 48zm-48 368c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm208-208c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zM96 256c0-26.51-21.49-48-48-48S0 229.49.0 256s21.49 48 48 48 48-21.49 48-48zm12.922 99.078c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.491-48-48-48zm294.156.0c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.49-48-48-48zM108.922 60.922c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.491-48-48-48z"/></svg></span></div><button class=search-cancel id=search-cancel-mobile>
取消</button></div><a class=menu-item href=/posts/ title>文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/profile/ title=了解我的个人信息和专业背景>关于我</a><button class="menu-item theme-switch tw-w-full" aria-label=切换主题>
<svg class="icon" viewBox="0 0 512 512"><path d="M8 256c0 136.966 111.033 248 248 248s248-111.034 248-248S392.966 8 256 8 8 119.033 8 256zm248 184V72c101.705.0 184 82.311 184 184 0 101.705-82.311 184-184 184z"/></svg></button></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class="tw-mx-4 tw-flex-1"><dialog id=toc-dialog class="tw-max-w-full tw-w-full tw-max-h-full tw-h-full tw-ml-16"><div class="toc tw-mx-4 tw-max-w-full"><h2 class="tw-mx-0 tw-my-6 tw-uppercase tw-text-2xl">目录</h2><div class=toc-content><nav id=TableOfContents><ul><li><a href=#1-基础概念>1. 基础概念</a><ul><li><a href=#11-什么是-prompt-engineering>1.1 什么是 Prompt Engineering</a></li><li><a href=#12-提示词的必要格式>1.2 提示词的必要格式</a></li><li><a href=#13-什么是-context-engineering>1.3 什么是 Context Engineering</a></li><li><a href=#14-与操作系统的类比>1.4 与操作系统的类比</a></li></ul></li><li><a href=#2-prompt-engineering-与-context-engineering-对比>2. Prompt Engineering 与 Context Engineering 对比</a><ul><li><a href=#21-prompt-engineering>2.1 Prompt Engineering</a></li><li><a href=#22-context-engineering>2.2 Context Engineering</a></li></ul></li><li><a href=#3-上下文工程面临的挑战>3. 上下文工程面临的挑战</a><ul><li><a href=#31-上下文长度限制>3.1 上下文长度限制</a></li><li><a href=#32-污染问题poisoning>3.2 污染问题（Poisoning）</a></li><li><a href=#33-注意力偏移misalignment>3.3 注意力偏移（Misalignment）</a></li><li><a href=#34-语义冲突与混乱semantic-conflict--confusion>3.4 语义冲突与混乱（Semantic Conflict & Confusion）</a></li></ul></li><li><a href=#4-上下文工程技术体系>4. 上下文工程技术体系</a><ul><li><a href=#41-上下文增强context-augmentation>4.1 上下文增强（Context Augmentation）</a></li><li><a href=#42-上下文优化context-optimization>4.2 上下文优化（Context Optimization）</a><ul><li><a href=#上下文隔离>上下文隔离</a></li><li><a href=#上下文压缩>上下文压缩</a></li></ul></li><li><a href=#43-上下文持久化context-persistence>4.3 上下文持久化（Context Persistence）</a></li></ul></li><li><a href=#5-实战建议与最佳实践>5. 实战建议与最佳实践</a></li><li><a href=#-延伸阅读>📚 延伸阅读</a><ul><li><a href=#-ai-大模型系统教程系列>🔗 AI 大模型系统教程系列</a></li><li><a href=#-实践建议>🎯 实践建议</a></li></ul></li></ul></nav></div></div></dialog><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC","false")</script><article class="page single print:!tw-w-full print:!tw-max-w-none print:!tw-m-0 print:!tw-p-0"><h1 class=single-title data-pagefind-meta=date:2025-11-05 data-pagefind-body>Prompt Engineering完全指南：从提示工程到上下文工程的实战教程</h1><div class=post-meta><div class=post-meta-line><span class=post-author><img class="tw-inline-block tw-max-h-4 tw-rounded-full tw-translate-y-[-2px] tw-mr-1" src=/static/avatar/angryCat.png alt="Finn avatar" height=16 width=16><a href=https://blog.baifan.site title=Author target=_blank rel="noopener noreferrer author" class=author>Finn</a>
</span>&nbsp;<span class=post-category>收录于 </span>&nbsp;<span class=post-category>类别 <a href=/categories/ai%E6%95%99%E7%A8%8B/><svg class="icon" viewBox="0 0 512 512"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49.0 112v288c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>AI教程</a>&nbsp;<a href=/categories/%E6%8A%80%E6%9C%AF%E6%B7%B1%E5%BA%A6/><svg class="icon" viewBox="0 0 512 512"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49.0 112v288c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>技术深度</a>&nbsp;<a href=/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/><svg class="icon" viewBox="0 0 512 512"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49.0 112v288c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>人工智能</a></span>&nbsp;<span class=post-category>和</span>&nbsp;<span class=post-series>系列 <a href><svg class="icon" viewBox="0 0 512 512"><path d="M464 32H48C21.49 32 0 53.49.0 80v352c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V80c0-26.51-21.49-48-48-48zm-6 4e2H54a6 6 0 01-6-6V86a6 6 0 016-6h404a6 6 0 016 6v340a6 6 0 01-6 6zm-42-92v24c0 6.627-5.373 12-12 12H204c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h2e2c6.627.0 12 5.373 12 12zm0-96v24c0 6.627-5.373 12-12 12H204c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h2e2c6.627.0 12 5.373 12 12zm0-96v24c0 6.627-5.373 12-12 12H204c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h2e2c6.627.0 12 5.373 12 12zm-252 12c0 19.882-16.118 36-36 36s-36-16.118-36-36 16.118-36 36-36 36 16.118 36 36zm0 96c0 19.882-16.118 36-36 36s-36-16.118-36-36 16.118-36 36-36 36 16.118 36 36zm0 96c0 19.882-16.118 36-36 36s-36-16.118-36-36 16.118-36 36-36 36 16.118 36 36z"/></svg></a></span></div><div class=post-meta-line><svg class="icon" viewBox="0 0 448 512"><path d="M148 288h-40c-6.6.0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h48c26.5.0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3.0 6-2.7 6-6z"/></svg>&nbsp;<time datetime=2025-11-05>2025-11-05</time>&nbsp;<svg class="icon" viewBox="0 0 576 512"><path d="M402.3 344.9l32-32c5-5 13.7-1.5 13.7 5.7V464c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h273.5c7.1.0 10.7 8.6 5.7 13.7l-32 32c-1.5 1.5-3.5 2.3-5.7 2.3H48v352h352V350.5c0-2.1.8-4.1 2.3-5.6zm156.6-201.8L296.3 405.7l-90.4 10c-26.2 2.9-48.5-19.2-45.6-45.6l10-90.4L432.9 17.1c22.9-22.9 59.9-22.9 82.7.0l43.2 43.2c22.9 22.9 22.9 60 .1 82.8zM460.1 174 402 115.9 216.2 301.8l-7.3 65.3 65.3-7.3L460.1 174zm64.8-79.7-43.2-43.2c-4.1-4.1-10.8-4.1-14.8.0L436 82l58.1 58.1 30.9-30.9c4-4.2 4-10.8-.1-14.9z"/></svg>&nbsp;<time datetime=2025-11-06>2025-11-06</time>&nbsp;<svg class="icon" viewBox="0 0 512 512"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3.0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9.0l60.1 60.1c18.8 18.7 18.8 49.1.0 67.9zM284.2 99.8 21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3.0-17l-111-111c-4.8-4.7-12.4-4.7-17.1.0zM124.1 339.9c-5.5-5.5-5.5-14.3.0-19.8l154-154c5.5-5.5 14.3-5.5 19.8.0s5.5 14.3.0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8.0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg>&nbsp;约 3306 字&nbsp;
<svg class="icon" viewBox="0 0 512 512"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5.0-2e2-89.5-2e2-2e2S145.5 56 256 56s2e2 89.5 2e2 2e2-89.5 2e2-2e2 2e2zm61.8-104.4-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6.0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"/></svg>&nbsp;预计阅读 15 分钟&nbsp;</div></div><div class="details toc print:!tw-block" id=toc-static kept=true><div class="details-summary toc-title"><span>目录</span>
<span class=details-icon><svg class="icon" viewBox="0 0 256 512"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9.0l-22.6-22.6c-9.4-9.4-9.4-24.6.0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6.0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9.0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#1-基础概念>1. 基础概念</a><ul><li><a href=#11-什么是-prompt-engineering>1.1 什么是 Prompt Engineering</a></li><li><a href=#12-提示词的必要格式>1.2 提示词的必要格式</a></li><li><a href=#13-什么是-context-engineering>1.3 什么是 Context Engineering</a></li><li><a href=#14-与操作系统的类比>1.4 与操作系统的类比</a></li></ul></li><li><a href=#2-prompt-engineering-与-context-engineering-对比>2. Prompt Engineering 与 Context Engineering 对比</a><ul><li><a href=#21-prompt-engineering>2.1 Prompt Engineering</a></li><li><a href=#22-context-engineering>2.2 Context Engineering</a></li></ul></li><li><a href=#3-上下文工程面临的挑战>3. 上下文工程面临的挑战</a><ul><li><a href=#31-上下文长度限制>3.1 上下文长度限制</a></li><li><a href=#32-污染问题poisoning>3.2 污染问题（Poisoning）</a></li><li><a href=#33-注意力偏移misalignment>3.3 注意力偏移（Misalignment）</a></li><li><a href=#34-语义冲突与混乱semantic-conflict--confusion>3.4 语义冲突与混乱（Semantic Conflict & Confusion）</a></li></ul></li><li><a href=#4-上下文工程技术体系>4. 上下文工程技术体系</a><ul><li><a href=#41-上下文增强context-augmentation>4.1 上下文增强（Context Augmentation）</a></li><li><a href=#42-上下文优化context-optimization>4.2 上下文优化（Context Optimization）</a><ul><li><a href=#上下文隔离>上下文隔离</a></li><li><a href=#上下文压缩>上下文压缩</a></li></ul></li><li><a href=#43-上下文持久化context-persistence>4.3 上下文持久化（Context Persistence）</a></li></ul></li><li><a href=#5-实战建议与最佳实践>5. 实战建议与最佳实践</a></li><li><a href=#-延伸阅读>📚 延伸阅读</a><ul><li><a href=#-ai-大模型系统教程系列>🔗 AI 大模型系统教程系列</a></li><li><a href=#-实践建议>🎯 实践建议</a></li></ul></li></ul></nav></div></div><div class=content id=content data-pagefind-body><h1 id=ai-教程prompt-engineering class=headerLink><a href=#ai-%e6%95%99%e7%a8%8bprompt-engineering class=header-mark></a>AI 教程：Prompt Engineering</h1><p>提示工程主要关注提示词的设计、优化与策略制定，致力于帮助用户更高效地调动大语言模型的能力，进而推动其在各类实际场景和研究领域中的应用。</p><h2 id=1-基础概念 class=headerLink><a href=#1-%e5%9f%ba%e7%a1%80%e6%a6%82%e5%bf%b5 class=header-mark></a>1. 基础概念</h2><h3 id=11-什么是-prompt-engineering class=headerLink><a href=#11-%e4%bb%80%e4%b9%88%e6%98%af-prompt-engineering class=header-mark></a>1.1 什么是 Prompt Engineering</h3><p>提示词就是：你通过自然语言的方式去告诉模型应该做什么，应该怎么做，什么能做，什么不能做，就这么简单。</p><h3 id=12-提示词的必要格式 class=headerLink><a href=#12-%e6%8f%90%e7%a4%ba%e8%af%8d%e7%9a%84%e5%bf%85%e8%a6%81%e6%a0%bc%e5%bc%8f class=header-mark></a>1.2 提示词的必要格式</h3><ul><li><strong>指令（Instruction）</strong>：明确告诉模型需要它做什么</li><li><strong>上下文（Context）</strong>：相关的背景信息，让模型有更多的上下文用于决策</li><li><strong>输入数据（Input Data）</strong>：必要的输入，可以是问题、目标等</li><li><strong>输出提示（Output Constraints）</strong>：约束输出格式、风格或长度，让结果更符合你的需求</li></ul><h3 id=13-什么是-context-engineering class=headerLink><a href=#13-%e4%bb%80%e4%b9%88%e6%98%af-context-engineering class=header-mark></a>1.3 什么是 Context Engineering</h3><p>上下文工程是一种为大语言模型构建、优化、动态管理输入上下文的工程化方法。主要包括：</p><ul><li><strong>信息收集和整合</strong>：从多源数据中获取与任务高度相关的内容</li><li><strong>结构化和格式化</strong>：将信息结构化组织，按照一定格式提供给大模型</li><li><strong>上下文管理</strong>：在有限的上下文窗口内，通过裁剪、隔离、压缩、持久化等手段来管理</li><li><strong>工具和外部系统接入</strong>：通过与外部工具和系统交互，增强模型的能力</li></ul><h3 id=14-与操作系统的类比 class=headerLink><a href=#14-%e4%b8%8e%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f%e7%9a%84%e7%b1%bb%e6%af%94 class=header-mark></a>1.4 与操作系统的类比</h3><p>大语言模型（LLM，Large Language Model）可以类比为新一代操作系统（OS，Operating System），其中上下文窗口（Context Window）相当于内存（RAM），而上下文工程则类似于操作系统中的调度器，负责将最关键的进程和数据装载到有限的内存空间中。</p><p>本质上，上下文工程是让大模型在特定场景下具备即插即用的任务能力。大模型在推理的时候所拥有的只有训练阶段获得的能力 + 上下文内容，在前者无法改变的情况之下，后者显得尤为重要。</p><blockquote><p><strong>核心洞察</strong>：不管大模型曾经执行或者交互过多少轮次，最新的这次只能依赖所提供的上下文去做推理，因此上下文在推理阶段才如此重要。</p></blockquote><p>大语言模型需要上下文，错误源于信息不足，而不是模型不够好，复杂任务及多源信息融合的挑战。</p><p><strong>训练和微调决定了模型的能力，上下文工程则决定了模型能发挥出多少能力。</strong></p><h2 id=2-prompt-engineering-与-context-engineering-对比 class=headerLink><a href=#2-prompt-engineering-%e4%b8%8e-context-engineering-%e5%af%b9%e6%af%94 class=header-mark></a>2. Prompt Engineering 与 Context Engineering 对比</h2><h3 id=21-prompt-engineering class=headerLink><a href=#21-prompt-engineering class=header-mark></a>2.1 Prompt Engineering</h3><p>是用一句话、一段话、一个格式、一个 role prompt 来激发模型的潜力。</p><p><strong>特点：</strong></p><ul><li>静态、单轮、指令导向</li><li>适用于封闭任务、结构化回答</li><li>零样本提示/少样本提示/思维链提示 等技巧层出不穷</li></ul><h3 id=22-context-engineering class=headerLink><a href=#22-context-engineering class=header-mark></a>2.2 Context Engineering</h3><p>在运行时持续的获取相关的信息，基于这些信息做出最佳的决策，产生最合适的结果。</p><p><strong>特点：</strong></p><ul><li>动态、多轮、环境导向</li><li>支持状态管理、任务演进、链式推理</li><li>具备 Agent 级别的操作能力</li></ul><figure class=center><img src=/pictures/note/2025-11-05-ai-03-001.png alt=这张图用较为直观的方式展示了上下文工程中，目前涉及的一些技术手段><figcaption><h4>上下文工程维恩图</h4><p>这张图用较为直观的方式展示了上下文工程中，目前涉及的一些技术手段</p></figcaption></figure><h2 id=3-上下文工程面临的挑战 class=headerLink><a href=#3-%e4%b8%8a%e4%b8%8b%e6%96%87%e5%b7%a5%e7%a8%8b%e9%9d%a2%e4%b8%b4%e7%9a%84%e6%8c%91%e6%88%98 class=header-mark></a>3. 上下文工程面临的挑战</h2><h3 id=31-上下文长度限制 class=headerLink><a href=#31-%e4%b8%8a%e4%b8%8b%e6%96%87%e9%95%bf%e5%ba%a6%e9%99%90%e5%88%b6 class=header-mark></a>3.1 上下文长度限制</h3><p>传入太少，信息不足，无法推理出好的结果；传入太多，模型注意力分散，无法聚焦。上下文工程就是制造合适的上下文供模型使用推理。</p><h3 id=32-污染问题poisoning class=headerLink><a href=#32-%e6%b1%a1%e6%9f%93%e9%97%ae%e9%a2%98poisoning class=header-mark></a>3.2 污染问题（Poisoning）</h3><p>错误信息持续留在上下文中，造成重复错误行为、目标偏离和行为死循环。</p><p><strong>问题描述：</strong>
在上下文过长的情况之下，因为一些错误或者不合适的信息混杂在上下文中并且一直持续存在于上下文中，导致 Agent 可能不断重复做出错误的决策或举动。</p><p><strong>重要提醒：</strong> 更大的上下文不一定是最好的选择，还是要取决于具体的使用场景和上下文工程策略来决定，因此不要盲目追求大上下文窗口和超长上下文的组装，那样有可能让结果恶化。</p><p><strong>典型示例：</strong>
大模型擅长模仿，当他审阅简历时，如果之前 20 份都是不通过，即使下一份简历不错，大模型也可能会模仿之前的操作，给予简历不通过。大模型倾向于模仿，因此如果提供的样本是规律重复的，就会导致模型倾向于模仿样本，导致后续的行为不断重复。</p><p><strong>解决方案：</strong>
引入更多的多样性。通过在动作和观察中加入少量有结构的变化来实现这一点——比如使用不同的序列化模板、替换措辞、在顺序或格式上加入细微扰动。这种"可控的随机性"有助于打破固定模式，重新调整模型的注意力焦点。</p><blockquote><p><strong>经验总结：</strong> 别让 few-shot 提示把你困在一种套路里。上下文越单一、越一致，你的智能体就越脆弱。</p></blockquote><p><strong>核心原理：</strong> 无论是 LLM 陷入错误幻觉与循环还是因为单一样本/少样本提示而产生重复行为，其本质都是上下文中充斥了不相干、误导性或错误信息，从而使大模型产生错误倾向的结果。这种错误倾向短期内无法被快速纠正，需要有检测和预防机制。</p><h3 id=33-注意力偏移misalignment class=headerLink><a href=#33-%e6%b3%a8%e6%84%8f%e5%8a%9b%e5%81%8f%e7%a7%bbmisalignment class=header-mark></a>3.3 注意力偏移（Misalignment）</h3><p>上下文长度增加会导致效果变差，其中的核心是上下文分心，模型被上下文分散了注意力，并且还会进一步让注意力从目标或指令转向无关的上下文。</p><p><strong>问题表现：</strong></p><ul><li>过长的上下文</li><li>相似但无关的上下文</li><li>当上下文长度到达一定程度的时候，会导致模型过于专注于上下文，而忽略了在训练时获得的知识</li><li>上下文过长，模型无法专注于指令（instruction）</li></ul><p><strong>解决方案：</strong>
每次都更新 todo list，锁定大模型的注意力，将最新的 todo list 放在最后，效果更好。</p><h3 id=34-语义冲突与混乱semantic-conflict--confusion class=headerLink><a href=#34-%e8%af%ad%e4%b9%89%e5%86%b2%e7%aa%81%e4%b8%8e%e6%b7%b7%e4%b9%b1semantic-conflict--confusion class=header-mark></a>3.4 语义冲突与混乱（Semantic Conflict & Confusion）</h3><p>上下文存在歧义、矛盾或冗余等情况，导致模型难以理解和识别，导致最终效果不符合预期。</p><p><strong>问题原因：</strong>
新引入的信息或工具与已有上下文中的内容产生矛盾，导致模型产生困惑、做出错误判断，甚至出现"随机选择"的不稳定行为。</p><p><strong>典型示例：</strong></p><ul><li><strong>多轮交互问题：</strong> 将单轮次的交互拆成多轮次，会导致模型的效果显著下降。每次模型接收到的信息都是局部的，不够完整，模型在早期做出了不完整甚至是错误的回答，这些错误信息会持续留在上下文中，并在最终生成答案时影响模型判断。</li><li><strong>工具冲突：</strong> 如果挂载过多的工具，无论是内置还是 MCP，可能会出现相似描述导致模型不知道选择哪个，最终结果就是在相似的工具里进行非确定性选择（或可称为随机选择），导致生成结果不稳定甚至错误。</li></ul><p><strong>对比优势：</strong> 单轮直接给予全量信息，则可以让大模型产生更少的错误信息。</p><h2 id=4-上下文工程技术体系 class=headerLink><a href=#4-%e4%b8%8a%e4%b8%8b%e6%96%87%e5%b7%a5%e7%a8%8b%e6%8a%80%e6%9c%af%e4%bd%93%e7%b3%bb class=header-mark></a>4. 上下文工程技术体系</h2><h3 id=41-上下文增强context-augmentation class=headerLink><a href=#41-%e4%b8%8a%e4%b8%8b%e6%96%87%e5%a2%9e%e5%bc%bacontext-augmentation class=header-mark></a>4.1 上下文增强（Context Augmentation）</h3><p><strong>主要目的：</strong> 补充信息</p><p><strong>技术手段：</strong></p><ul><li><strong>prompt</strong>：提示词技术</li><li><strong>RAG</strong>：检索增强生成</li><li><strong>tools</strong>：工具调用（FunctionCall, MCP, skills）</li></ul><h3 id=42-上下文优化context-optimization class=headerLink><a href=#42-%e4%b8%8a%e4%b8%8b%e6%96%87%e4%bc%98%e5%8c%96context-optimization class=header-mark></a>4.2 上下文优化（Context Optimization）</h3><p><strong>主要目的：</strong> 清洗和优化上下文</p><h4 id=上下文隔离 class=headerLink><a href=#%e4%b8%8a%e4%b8%8b%e6%96%87%e9%9a%94%e7%a6%bb class=header-mark></a>上下文隔离</h4><ul><li><strong>拆分无状态任务</strong>：给 sub agent 执行，sub agent 就是独立的上下文</li><li><strong>记忆系统</strong>：通过长期记忆与短期记忆隔离管理，在需要时引入</li><li><strong>专业上下文</strong>：为专业任务配置专属上下文，如医疗、法律、编程等</li></ul><h4 id=上下文压缩 class=headerLink><a href=#%e4%b8%8a%e4%b8%8b%e6%96%87%e5%8e%8b%e7%bc%a9 class=header-mark></a>上下文压缩</h4><ul><li><strong>提取式摘要（Extractive Summarization）</strong>：直接选出原文中最相关的段落、句子</li><li><strong>抽象式摘要（Abstractive Summarization）</strong>：用自己的话总结信息，常结合 LLM 实现</li><li><strong>结构化摘要（Structured Summarization）</strong>：提取出知识点、任务、目标等结构化信息，如 To-do 列表、决策路径</li><li><strong>自我总结（Self-summarization）</strong>：模型每一轮对话之后，自动总结这轮信息并作为输入传递，形成压缩上下文链</li><li><strong>摘要记忆（Summarized Memory）</strong>：结合记忆机制，将历史摘要作为长期记忆引用</li><li><strong>时间窗口裁剪（Time-based Pruning）</strong>：仅保留最近或关键时段的上下文，剔除历史冗余信息，提升推理精度</li></ul><h3 id=43-上下文持久化context-persistence class=headerLink><a href=#43-%e4%b8%8a%e4%b8%8b%e6%96%87%e6%8c%81%e4%b9%85%e5%8c%96context-persistence class=header-mark></a>4.3 上下文持久化（Context Persistence）</h3><p><strong>主要目的：</strong> 保留信息</p><p><strong>实现方式：</strong> 涉及一些外部记忆模块的持久化服务，使用文件系统/数据库。</p><h2 id=5-实战建议与最佳实践 class=headerLink><a href=#5-%e5%ae%9e%e6%88%98%e5%bb%ba%e8%ae%ae%e4%b8%8e%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5 class=header-mark></a>5. 实战建议与最佳实践</h2><ol><li><strong>平衡上下文长度</strong>：根据具体任务选择合适的上下文大小，避免过长或过短</li><li><strong>预防上下文污染</strong>：定期清理和更新上下文，引入多样性防止模式固化</li><li><strong>管理注意力焦点</strong>：使用 todo list 等工具锁定模型注意力</li><li><strong>避免语义冲突</strong>：确保上下文信息的一致性和逻辑性</li><li><strong>选择合适的技术组合</strong>：根据场景灵活运用增强、优化和持久化技术</li></ol><hr><h2 id=-延伸阅读 class=headerLink><a href=#-%e5%bb%b6%e4%bc%b8%e9%98%85%e8%af%bb class=header-mark></a>📚 延伸阅读</h2><h3 id=-ai-大模型系统教程系列 class=headerLink><a href=#-ai-%e5%a4%a7%e6%a8%a1%e5%9e%8b%e7%b3%bb%e7%bb%9f%e6%95%99%e7%a8%8b%e7%b3%bb%e5%88%97 class=header-mark></a>🔗 AI 大模型系统教程系列</h3><ol><li><strong><a href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B1/ rel>AI 大模型完全指南</a></strong> - 从零基础到 Token 与向量的深度解析</li><li><strong><a href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B2/ rel>Transformer 架构深度解析</a></strong> - 注意力机制与 AI 大模型的核心技术</li><li><strong>[本文] Prompt Engineering 完全指南</strong> - 从提示工程到上下文工程的实战教程</li><li><strong><a href=https://byronfinn.github.io/ai%E4%B8%93%E4%B8%9A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A%E8%A1%A8/ rel>AI 专业名词解释表</a></strong> - 270+术语完全指南与 AI 技术体系词典</li></ol><h3 id=-实践建议 class=headerLink><a href=#-%e5%ae%9e%e8%b7%b5%e5%bb%ba%e8%ae%ae class=header-mark></a>🎯 实践建议</h3><ul><li><strong>理论结合</strong>：先掌握 AI 大模型基础概念，再学习本文的实战技巧</li><li><strong>架构理解</strong>：深入理解 Transformer 架构有助于优化 Prompt 设计</li><li><strong>术语参考</strong>：开发过程中遇到专业术语时，随时查阅 AI 专业名词解释表</li></ul><hr></div><h2>相关内容</h2><div class=related-container><div class=related-item-container><h2 class=related-title><a href=/ai%E4%B8%93%E4%B8%9A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A%E8%A1%A8/>AI专业名词解释表：270+术语完全指南与AI技术体系词典</a></h2></div><div class=related-item-container><h2 class=related-title><a href=/ai%E6%95%99%E7%A8%8B5/>RAG系统完全指南——从零搭建本地检索增强生成系统</a></h2></div><div class=related-item-container><h2 class=related-title><a href=/pg-vector%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/>Docker安装PostgreSQL+pgvector完整教程：AI向量数据库快速部署指南</a></h2></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>更新于 2025-11-06</span></div><div class=post-info-license></div></div><div class="post-info-line print:!tw-hidden"><div class=post-info-md></div><div class=post-info-share><button title="分享到 Twitter" data-sharer=twitter data-url=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B3/ data-title="Prompt Engineering完全指南：从提示工程到上下文工程的实战教程" data-hashtags="Prompt Engineering,Context Engineering,提示词工程,上下文工程,RAG,检索增强生成,AI应用开发,LLM优化,上下文管理"><svg class="icon" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></button><button title="分享到 Evernote" data-sharer=evernote data-url=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B3/ data-title="Prompt Engineering完全指南：从提示工程到上下文工程的实战教程"><svg class="icon" viewBox="0 0 384 512"><path d="M120.82 132.21c1.6 22.31-17.55 21.59-21.61 21.59-68.93.0-73.64-1-83.58 3.34-.56.22-.74.0-.37-.37L123.79 46.45c.38-.37.6-.22.38.37-4.35 9.99-3.35 15.09-3.35 85.39zm79 308c-14.68-37.08 13-76.93 52.52-76.62 17.49.0 22.6 23.21 7.95 31.42-6.19 3.3-24.95 1.74-25.14 19.2-.05 17.09 19.67 25 31.2 24.89A45.64 45.64.0 00312 393.45v-.08c0-11.63-7.79-47.22-47.54-55.34-7.72-1.54-65-6.35-68.35-50.52-3.74 16.93-17.4 63.49-43.11 69.09-8.74 1.94-69.68 7.64-112.92-36.77.0.0-18.57-15.23-28.23-57.95-3.38-15.75-9.28-39.7-11.14-62 0-18 11.14-30.45 25.07-32.2 81 0 90 2.32 101-7.8 9.82-9.24 7.8-15.5 7.8-102.78 1-8.3 7.79-30.81 53.41-24.14 6 .86 31.91 4.18 37.48 30.64l64.26 11.15c20.43 3.71 70.94 7 80.6 57.94 22.66 121.09 8.91 238.46 7.8 238.46C362.15 485.53 267.06 480 267.06 480c-18.95-.23-54.25-9.4-67.27-39.83zm80.94-204.84c-1 1.92-2.2 6 .85 7 14.09 4.93 39.75 6.84 45.88 5.53 3.11-.25 3.05-4.43 2.48-6.65-3.53-21.85-40.83-26.5-49.24-5.92z"/></svg></button></div></div></div><div class=post-info-more><section class=post-tags><svg class="icon" viewBox="0 0 640 512"><path d="M497.941 225.941 286.059 14.059A48 48 0 00252.118.0H48C21.49.0.0 21.49.0 48v204.118a48 48 0 0014.059 33.941l211.882 211.882c18.744 18.745 49.136 18.746 67.882.0l204.118-204.118c18.745-18.745 18.745-49.137.0-67.882zM112 160c-26.51.0-48-21.49-48-48s21.49-48 48-48 48 21.49 48 48-21.49 48-48 48zm513.941 133.823L421.823 497.941c-18.745 18.745-49.137 18.745-67.882.0l-.36-.36L527.64 323.522c16.999-16.999 26.36-39.6 26.36-63.64s-9.362-46.641-26.36-63.64L331.397.0h48.721a48 48 0 0133.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137.0 67.882z"/></svg>&nbsp;<a href=/tags/prompt-engineering/>Prompt Engineering</a>,&nbsp;<a href=/tags/context-engineering/>Context Engineering</a>,&nbsp;<a href=/tags/%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B/>提示词工程</a>,&nbsp;<a href=/tags/%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B/>上下文工程</a>,&nbsp;<a href=/tags/rag/>RAG</a>,&nbsp;<a href=/tags/%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/>检索增强生成</a>,&nbsp;<a href=/tags/ai%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/>AI应用开发</a>,&nbsp;<a href=/tags/llm%E4%BC%98%E5%8C%96/>LLM优化</a>,&nbsp;<a href=/tags/%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86/>上下文管理</a></section><section class=print:!tw-hidden><span><button class="tw-text-fgColor-link-muted hover:tw-text-fgColor-link-muted-hover" onclick=window.history.back()>返回</button></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class="post-nav print:tw-hidden"><a href=/ai%E6%95%99%E7%A8%8B4/ class=prev rel=prev title="CPU/GPU 与大模型训练"><svg class="icon" viewBox="0 0 256 512"><path d="M31.7 239l136-136c9.4-9.4 24.6-9.4 33.9.0l22.6 22.6c9.4 9.4 9.4 24.6.0 33.9L127.9 256l96.4 96.4c9.4 9.4 9.4 24.6.0 33.9L201.7 409c-9.4 9.4-24.6 9.4-33.9.0l-136-136c-9.5-9.4-9.5-24.6-.1-34z"/></svg>CPU/GPU 与大模型训练</a>
<a href=/ai%E6%95%99%E7%A8%8B2/ class=next rel=next title=Transformer架构深度解析：注意力机制与AI大模型的核心技术>Transformer架构深度解析：注意力机制与AI大模型的核心技术<svg class="icon" viewBox="0 0 256 512"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9.0l-22.6-22.6c-9.4-9.4-9.4-24.6.0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6.0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9.0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a></div></div><div id=comments class="print:!tw-hidden tw-pt-32 tw-pb-8"><div id=giscus></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://giscus.app/>giscus</a>.</noscript></div></article></main><footer class=footer><div class=footer-container><div class=footer-line><svg class="icon" viewBox="0 0 512 512"><path d="M256 8C119.033 8 8 119.033 8 256s111.033 248 248 248 248-111.033 248-248S392.967 8 256 8zm0 448c-110.532.0-2e2-89.451-2e2-2e2.0-110.531 89.451-2e2 2e2-2e2 110.532.0 2e2 89.451 2e2 2e2.0 110.532-89.451 2e2-2e2 2e2zm107.351-101.064c-9.614 9.712-45.53 41.396-104.065 41.396-82.43.0-140.484-61.425-140.484-141.567.0-79.152 60.275-139.401 139.762-139.401 55.531.0 88.738 26.62 97.593 34.779a11.965 11.965.0 011.936 15.322l-18.155 28.113c-3.841 5.95-11.966 7.282-17.499 2.921-8.595-6.776-31.814-22.538-61.708-22.538-48.303.0-77.916 35.33-77.916 80.082.0 41.589 26.888 83.692 78.277 83.692 32.657.0 56.843-19.039 65.726-27.225 5.27-4.857 13.596-4.039 17.82 1.738l19.865 27.17a11.947 11.947.0 01-1.152 15.518z"/></svg>2025<span class=author>&nbsp;<a href=https://blog.baifan.site target=_blank rel="noopener noreferrer">Finn</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class=footer-line></div><div class=footer-line></div></div><script>"serviceWorker"in navigator&&(navigator.serviceWorker.register("/sw.min.js",{scope:"/"}).then(function(){}),navigator.serviceWorker.ready.then(function(){}))</script></footer><div class="print:!tw-hidden tw-flex tw-flex-col tw-fixed tw-right-4 tw-bottom-4 tw-gap-2"><a href=#back-to-top id=back-to-top-button class="tw-transition-opacity tw-opacity-0 tw-block tw-bg-bgColor-secondary tw-rounded-full" style=padding:.6rem;line-height:1.3rem;font-size:1rem title=回到顶部><svg class="icon" viewBox="0 0 448 512"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6.0-33.9L207 39c9.4-9.4 24.6-9.4 33.9.0l194.3 194.3c9.4 9.4 9.4 24.6.0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3.0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg>
</a><button id=toc-drawer-button class="tw-block tw-bg-bgColor-secondary tw-rounded-full md:tw-hidden" style=padding:.6rem;line-height:1.3rem;font-size:1rem>
<svg class="icon" viewBox="0 0 448 512"><path d="M16 132h416c8.837.0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163.0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"/></svg>
</button><a href=#comments id=view-comments class="tw-block tw-bg-bgColor-secondary tw-rounded-full" style=padding:.6rem;line-height:1.3rem;font-size:1rem title=查看评论>
<svg class="icon" viewBox="0 0 512 512"><path d="M256 32C114.6 32 0 125.1.0 240c0 49.6 21.4 95 57 130.7C44.5 421.1 2.7 466 2.2 466.5c-2.2 2.3-2.8 5.7-1.5 8.7S4.8 480 8 480c66.3.0 116-31.8 140.6-51.4 32.7 12.3 69 19.4 107.4 19.4 141.4.0 256-93.1 256-208S397.4 32 256 32z"/></svg></a></div><div id=cookieconsent-container></div><link rel=stylesheet href=/lib/katex/katex.min.0c8126645bb983a788b167b1b97abe2505a962ad45e049001463c46012012a9b.css integrity="sha256-DIEmZFu5g6eIsWexuXq+JQWpYq1F4EkAFGPEYBIBKps="><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/katex/copy-tex.min.cf8e3e934d92a839d209ffdac331fa693da5958a6dff2c8788a4713cc1f50a47.css integrity="sha256-z44+k02SqDnSCf/awzH6aT2llYpt/yyHiKRxPMH1Ckc="><noscript><link rel=stylesheet href=/lib/katex/copy-tex.min.cf8e3e934d92a839d209ffdac331fa693da5958a6dff2c8788a4713cc1f50a47.css integrity="sha256-z44+k02SqDnSCf/awzH6aT2llYpt/yyHiKRxPMH1Ckc="></noscript><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.cd0d0b6e50ff01ff2f3a9a70d7cfb66a7c6cb9acf7a566325568be6d3bd31fc4.css integrity="sha256-zQ0LblD/Af8vOppw18+2anxsuaz3pWYyVWi+bTvTH8Q="><script>window.config={"autocomplete.min.js":"/lib/autocomplete/autocomplete.min.js",comment:{giscus:{darkTheme:"dark",dataCategory:"Announcements",dataCategoryId:"DIC_kwDOQOVlP84Cxa17",dataEmitMetadata:"0",dataInputPosition:"top",dataLang:"zh-CN",dataLoading:"lazy",dataMapping:"pathname",dataReactionsEnabled:"1",dataRepo:"ByronFinn/ByronFinn.github.io",dataRepoId:"R_kgDOQOVlPw",dataStrict:"0",lightTheme:"light"}},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验."},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},data:{"desktop-header-typeit":"Daily Deep Think","mobile-header-typeit":"Daily Deep Think"},"fuse.min.js":"/lib/fuse/fuse.min.js",math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{distance:100,findAllMatches:!1,fuseIndexURL:"/index.json",highlightTag:"em",ignoreFieldNorm:!1,ignoreLocation:!1,isCaseSensitive:!1,location:0,maxResultLength:10,minMatchCharLength:2,noResultsFound:"没有找到结果",snippetLength:50,threshold:.3,type:"fuse",useExtendedSearch:!1},sharerjs:!0,table:{sort:!0},twemoji:!0,typeit:{cursorChar:"|",cursorSpeed:1e3,data:{"desktop-header-typeit":["desktop-header-typeit"],"mobile-header-typeit":["mobile-header-typeit"]},duration:-1,speed:100}}</script><script src=/lib/tablesort/tablesort.min.92de6dec051677787aed63503575b2f9be73f21f2745574e59647bc139a92d40.js integrity="sha256-kt5t7AUWd3h67WNQNXWy+b5z8h8nRVdOWWR7wTmpLUA="></script><script src=/lib/twemoji/twemoji.min.0e0e5259e3ff8ea805e0c5660c6336f7f46b14332e3cafb82939e1db3da8b6f8.js integrity="sha256-Dg5SWeP/jqgF4MVmDGM29/RrFDMuPK+4KTnh2z2otvg=" defer></script><script src=/js/twemoji.min.js defer></script><script src=/lib/sharer/sharer.min.8fe10eb615eb163a20f795484430a012805ec7c8c11df52df54ddb7a46084254.js integrity="sha256-j+EOthXrFjog95VIRDCgEoBex8jBHfUt9U3bekYIQlQ="></script><script src=/lib/typeit/typeit.min.06e0b9ba7bb3c9368aa26979037019306fef8e43dd2b9276854d227381445d0f.js integrity="sha256-BuC5unuzyTaKoml5A3AZMG/vjkPdK5J2hU0ic4FEXQ8="></script><script src=/lib/katex/katex.min.76d534cf1167067008fca12c4e903fc44cf8cfda8c5279c318d1f78cd90b086e.js integrity="sha256-dtU0zxFnBnAI/KEsTpA/xEz4z9qMUnnDGNH3jNkLCG4=" defer></script><script src=/lib/katex/auto-render.min.bb53eb953394531aae36fdd537065c4244eb8542901a3ce914601d932675b8ac.js integrity="sha256-u1PrlTOUUxquNv3VNwZcQkTrhUKQGjzpFGAdkyZ1uKw=" defer></script><script src=/lib/katex/copy-tex.min.07770af90943a1de1a1010794bc78c6a7346d46d48fb63e35cc76ba76b827604.js integrity="sha256-B3cK+QlDod4aEBB5S8eManNG1G1I+2PjXMdrp2uCdgQ=" defer></script><script src=/lib/katex/mhchem.min.9f87e5e9c384a160472d0045035a8641f6013358eddb3ece708634a50f946a40.js integrity="sha256-n4fl6cOEoWBHLQBFA1qGQfYBM1jt2z7OcIY0pQ+UakA=" defer></script><script src=/js/katex.min.js defer></script><script src=/lib/cookieconsent/cookieconsent.min.e55842a856a6d829feca3c3ad736c136b6c7549e9247274f78aa296259e06e24.js integrity="sha256-5VhCqFam2Cn+yjw61zbBNrbHVJ6SRydPeKopYlngbiQ=" defer></script><script src=/js/cookieconsent.min.js defer></script><script src=/js/theme.min.js defer></script><script src=/js/giscus.min.js defer></script><script type=speculationrules>
  {
    "prerender": [
      {
        "where": { "href_matches": "/*" },
        "eagerness": "moderate"
      }
    ]
  }
</script></body></html>