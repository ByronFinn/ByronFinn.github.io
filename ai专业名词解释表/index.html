<!doctype html><html lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>AI专业名词解释表：270+术语完全指南与AI技术体系词典 - 每日深度思考 | 技术、经济分析与深度思考</title><meta name=Description content="最全面的AI专业名词解释表，涵盖270+个AI术语：从Token、Transformer到RAG、Prompt工程。系统学习AI大模型技术体系，包含12大分类和A-Z速查表，是AI学习者的必备词典。"><meta property="og:url" content="https://byronfinn.github.io/ai%E4%B8%93%E4%B8%9A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A%E8%A1%A8/"><meta property="og:site_name" content="每日深度思考 | 技术、经济分析与深度思考"><meta property="og:title" content="AI专业名词解释表：270+术语完全指南与AI技术体系词典"><meta property="og:description" content="最全面的AI专业名词解释表，涵盖270+个AI术语：从Token、Transformer到RAG、Prompt工程。系统学习AI大模型技术体系，包含12大分类和A-Z速查表，是AI学习者的必备词典。"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-11-05T09:58:24+08:00"><meta property="article:modified_time" content="2025-11-05T09:58:24+08:00"><meta property="article:tag" content="AI专业名词"><meta property="article:tag" content="人工智能术语"><meta property="article:tag" content="AI词典"><meta property="article:tag" content="机器学习"><meta property="article:tag" content="深度学习"><meta property="article:tag" content="Transformer"><meta property="og:image" content="https://byronfinn.github.io/pictures/avatar/angryCat.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://byronfinn.github.io/pictures/avatar/angryCat.png"><meta name=twitter:title content="AI专业名词解释表：270+术语完全指南与AI技术体系词典"><meta name=twitter:description content="最全面的AI专业名词解释表，涵盖270+个AI术语：从Token、Transformer到RAG、Prompt工程。系统学习AI大模型技术体系，包含12大分类和A-Z速查表，是AI学习者的必备词典。"><meta name=application-name content="Daily Deep Think"><meta name=apple-mobile-web-app-title content="Daily Deep Think"><meta name=theme-color content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel=icon href=/static/icos/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://byronfinn.github.io/ai%E4%B8%93%E4%B8%9A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A%E8%A1%A8/><link rel=prev href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B3/><link rel=next href=https://byronfinn.github.io/tiktok%E7%9A%84%E5%9B%B0%E5%B1%80/><link rel=stylesheet href=/css/main.min.css><link rel=stylesheet href=/css/style.min.css><meta name=google-site-verification content="google8f3e688b6959e353"><meta name=msvalidate.01 content="请在此添加你的Bing验证码"><meta name=yandex-verification content="请在此添加你的Yandex验证码"><meta name=p:domain_verify content="请在此添加你的Pinterest验证码"><meta name=baidu-site-verification content="请在此添加你的百度验证码"><meta name=sogou_site_verification content="请在此添加你的搜狗验证码"><meta name=360-site-verification content="请在此添加你的360搜索验证码"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"AI专业名词解释表：270+术语完全指南与AI技术体系词典","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https://byronfinn.github.io/ai%E4%B8%93%E4%B8%9A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A%E8%A1%A8/"},"image":["https://byronfinn.github.io/pictures/avatar/angryCat.png"],"genre":"posts","keywords":["AI专业名词","人工智能","机器学习","深度学习","Transformer","LLM大模型","Prompt工程","RAG技术","向量数据库","注意力机制"],"wordcount":6756,"url":"https://byronfinn.github.io/ai%E4%B8%93%E4%B8%9A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A%E8%A1%A8/","datePublished":"2025-11-05T09:58:24+08:00","dateModified":"2025-11-05T09:58:24+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Finn","url":"https://blog.baifan.site"},"description":"最全面的AI专业名词解释表，涵盖270+个AI术语：从Token、Transformer到RAG、Prompt工程。系统学习AI大模型技术体系，包含12大分类和A-Z速查表，是AI学习者的必备词典。"}</script></head><body data-instant-intensity=viewport class="tw-flex tw-min-h-screen tw-flex-col"><script>function setTheme(e){document.body.setAttribute("theme",e),document.documentElement.className=e,document.documentElement.style.setProperty("color-scheme",e==="light"?"light":"dark"),e==="light"?document.documentElement.classList.remove("tw-dark"):document.documentElement.classList.add("tw-dark"),window.theme=e,window.isDark=window.theme!=="light"}function saveTheme(e){window.localStorage&&localStorage.setItem("theme",e)}function getMeta(e){const t=document.getElementsByTagName("meta");for(let n=0;n<t.length;n++)if(t[n].getAttribute("name")===e)return t[n];return""}if(window.localStorage&&localStorage.getItem("theme")){let e=localStorage.getItem("theme");e==="light"||e==="dark"?setTheme(e):setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")}else"auto"==="light"||"auto"==="dark"?(setTheme("auto"),saveTheme("auto")):(saveTheme("auto"),setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"));let metaColors={light:"#f8f8f8",dark:"#161b22"};getMeta("theme-color").content=metaColors[document.body.getAttribute("theme")],window.switchThemeEventSet=new Set</script><div id=back-to-top></div><div id=mask></div><header class="desktop print:!tw-hidden" id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="每日深度思考 | 技术、经济分析与深度思考"><span id=desktop-header-typeit class=typeit></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/profile/ title=了解我的个人信息和专业背景>关于我 </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder=搜索... id=search-input-desktop>
<button class="search-button search-toggle" id=search-toggle-desktop title=搜索>
<svg class="icon" viewBox="0 0 512 512"><path d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</button>
<button class="search-button search-clear" id=search-clear-desktop title=清空>
<svg class="icon" viewBox="0 0 512 512"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm121.6 313.1c4.7 4.7 4.7 12.3.0 17L338 377.6c-4.7 4.7-12.3 4.7-17 0L256 312l-65.1 65.6c-4.7 4.7-12.3 4.7-17 0L134.4 338c-4.7-4.7-4.7-12.3.0-17l65.6-65-65.6-65.1c-4.7-4.7-4.7-12.3.0-17l39.6-39.6c4.7-4.7 12.3-4.7 17 0l65 65.7 65.1-65.6c4.7-4.7 12.3-4.7 17 0l39.6 39.6c4.7 4.7 4.7 12.3.0 17L312 256l65.6 65.1z"/></svg>
</button>
<span class="search-button search-loading tw-animate-spin" id=search-loading-desktop><svg class="icon" viewBox="0 0 512 512"><path d="M304 48c0 26.51-21.49 48-48 48s-48-21.49-48-48 21.49-48 48-48 48 21.49 48 48zm-48 368c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm208-208c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zM96 256c0-26.51-21.49-48-48-48S0 229.49.0 256s21.49 48 48 48 48-21.49 48-48zm12.922 99.078c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.491-48-48-48zm294.156.0c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.49-48-48-48zM108.922 60.922c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.491-48-48-48z"/></svg>
</span></span><button class="menu-item theme-switch" aria-label=切换主题>
<svg class="icon" viewBox="0 0 512 512"><path d="M8 256c0 136.966 111.033 248 248 248s248-111.034 248-248S392.966 8 256 8 8 119.033 8 256zm248 184V72c101.705.0 184 82.311 184 184 0 101.705-82.311 184-184 184z"/></svg></button></div></div></div></header><header class="mobile print:!tw-hidden" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="每日深度思考 | 技术、经济分析与深度思考"><span id=mobile-header-typeit class=typeit></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索... id=search-input-mobile>
<button class="search-button search-toggle tw-h-10" id=search-toggle-mobile title=搜索>
<svg class="icon" viewBox="0 0 512 512"><path d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</button>
<button class="search-button search-clear tw-h-fit" id=search-clear-mobile title=清空>
<svg class="icon" viewBox="0 0 512 512"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm121.6 313.1c4.7 4.7 4.7 12.3.0 17L338 377.6c-4.7 4.7-12.3 4.7-17 0L256 312l-65.1 65.6c-4.7 4.7-12.3 4.7-17 0L134.4 338c-4.7-4.7-4.7-12.3.0-17l65.6-65-65.6-65.1c-4.7-4.7-4.7-12.3.0-17l39.6-39.6c4.7-4.7 12.3-4.7 17 0l65 65.7 65.1-65.6c4.7-4.7 12.3-4.7 17 0l39.6 39.6c4.7 4.7 4.7 12.3.0 17L312 256l65.6 65.1z"/></svg>
</button>
<span class="search-button search-loading tw-animate-spin" id=search-loading-mobile><svg class="icon" viewBox="0 0 512 512"><path d="M304 48c0 26.51-21.49 48-48 48s-48-21.49-48-48 21.49-48 48-48 48 21.49 48 48zm-48 368c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm208-208c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zM96 256c0-26.51-21.49-48-48-48S0 229.49.0 256s21.49 48 48 48 48-21.49 48-48zm12.922 99.078c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.491-48-48-48zm294.156.0c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.49-48-48-48zM108.922 60.922c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.491-48-48-48z"/></svg></span></div><button class=search-cancel id=search-cancel-mobile>
取消</button></div><a class=menu-item href=/posts/ title>文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/profile/ title=了解我的个人信息和专业背景>关于我</a><button class="menu-item theme-switch tw-w-full" aria-label=切换主题>
<svg class="icon" viewBox="0 0 512 512"><path d="M8 256c0 136.966 111.033 248 248 248s248-111.034 248-248S392.966 8 256 8 8 119.033 8 256zm248 184V72c101.705.0 184 82.311 184 184 0 101.705-82.311 184-184 184z"/></svg></button></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class="tw-mx-4 tw-flex-1"><dialog id=toc-dialog class="tw-max-w-full tw-w-full tw-max-h-full tw-h-full tw-ml-16"><div class="toc tw-mx-4 tw-max-w-full"><h2 class="tw-mx-0 tw-my-6 tw-uppercase tw-text-2xl">目录</h2><div class=toc-content><nav id=TableOfContents><ul><li><a href=#-基础概念篇>📚 基础概念篇</a></li><li><a href=#-架构技术篇>🏗️ 架构技术篇</a></li><li><a href=#-数学表示篇>🔢 数学表示篇</a></li><li><a href=#-处理流程篇>🔄 处理流程篇</a></li><li><a href=#-工程实践篇>🛠️ 工程实践篇</a></li><li><a href=#-传统模型对比篇>🧠 传统模型对比篇</a></li><li><a href=#-应用场景篇>📊 应用场景篇</a></li><li><a href=#-模型优化与训练技巧篇>🧩 模型优化与训练技巧篇</a></li><li><a href=#-向量检索与知识集成篇>🔍 向量检索与知识集成篇</a></li><li><a href=#-多模态与智能体篇>🧩 多模态与智能体篇</a></li><li><a href=#-模型评估与安全篇>⚙️ 模型评估与安全篇</a></li><li><a href=#-新兴趋势与未来方向篇>🧰 新兴趋势与未来方向篇</a></li><li><a href=#-学习建议>💡 学习建议</a><ul><li><a href=#-核心概念掌握优先级>🎯 核心概念掌握优先级</a></li><li><a href=#-学习路径建议>📖 学习路径建议</a></li><li><a href=#-概念关联图>🔗 概念关联图</a></li></ul></li><li><a href=#-延伸阅读>📚 延伸阅读</a><ul><li><a href=#-ai大模型系统教程系列>🔗 AI大模型系统教程系列</a></li><li><a href=#-使用建议>🎯 使用建议</a></li></ul></li><li><a href=#-附录ai专业术语中英对照速查表az-glossary>📘 附录：AI专业术语中英对照速查表（A–Z Glossary）</a></li></ul></nav></div></div></dialog><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC","false")</script><article class="page single print:!tw-w-full print:!tw-max-w-none print:!tw-m-0 print:!tw-p-0"><h1 class=single-title data-pagefind-meta=date:2025-11-05 data-pagefind-body>AI专业名词解释表：270+术语完全指南与AI技术体系词典</h1><div class=post-meta><div class=post-meta-line><span class=post-author><img class="tw-inline-block tw-max-h-4 tw-rounded-full tw-translate-y-[-2px] tw-mr-1" src=/pictures/avatar/angryCat.png alt="Finn avatar" height=16 width=16><a href=https://blog.baifan.site title=Author target=_blank rel="noopener noreferrer author" class=author>Finn</a>
</span>&nbsp;<span class=post-category>收录于 </span>&nbsp;<span class=post-category>类别 <a href=/categories/ai%E6%95%99%E7%A8%8B/><svg class="icon" viewBox="0 0 512 512"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49.0 112v288c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>AI教程</a>&nbsp;<a href=/categories/%E6%8A%80%E6%9C%AF%E6%B7%B1%E5%BA%A6/><svg class="icon" viewBox="0 0 512 512"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49.0 112v288c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>技术深度</a>&nbsp;<a href=/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/><svg class="icon" viewBox="0 0 512 512"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49.0 112v288c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>人工智能</a></span>&nbsp;<span class=post-category>和</span>&nbsp;<span class=post-series>系列 <a href><svg class="icon" viewBox="0 0 512 512"><path d="M464 32H48C21.49 32 0 53.49.0 80v352c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V80c0-26.51-21.49-48-48-48zm-6 4e2H54a6 6 0 01-6-6V86a6 6 0 016-6h404a6 6 0 016 6v340a6 6 0 01-6 6zm-42-92v24c0 6.627-5.373 12-12 12H204c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h2e2c6.627.0 12 5.373 12 12zm0-96v24c0 6.627-5.373 12-12 12H204c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h2e2c6.627.0 12 5.373 12 12zm0-96v24c0 6.627-5.373 12-12 12H204c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h2e2c6.627.0 12 5.373 12 12zm-252 12c0 19.882-16.118 36-36 36s-36-16.118-36-36 16.118-36 36-36 36 16.118 36 36zm0 96c0 19.882-16.118 36-36 36s-36-16.118-36-36 16.118-36 36-36 36 16.118 36 36zm0 96c0 19.882-16.118 36-36 36s-36-16.118-36-36 16.118-36 36-36 36 16.118 36 36z"/></svg></a></span></div><div class=post-meta-line><svg class="icon" viewBox="0 0 448 512"><path d="M148 288h-40c-6.6.0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h48c26.5.0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3.0 6-2.7 6-6z"/></svg>&nbsp;<time datetime=2025-11-05>2025-11-05</time>&nbsp;<svg class="icon" viewBox="0 0 576 512"><path d="M402.3 344.9l32-32c5-5 13.7-1.5 13.7 5.7V464c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h273.5c7.1.0 10.7 8.6 5.7 13.7l-32 32c-1.5 1.5-3.5 2.3-5.7 2.3H48v352h352V350.5c0-2.1.8-4.1 2.3-5.6zm156.6-201.8L296.3 405.7l-90.4 10c-26.2 2.9-48.5-19.2-45.6-45.6l10-90.4L432.9 17.1c22.9-22.9 59.9-22.9 82.7.0l43.2 43.2c22.9 22.9 22.9 60 .1 82.8zM460.1 174 402 115.9 216.2 301.8l-7.3 65.3 65.3-7.3L460.1 174zm64.8-79.7-43.2-43.2c-4.1-4.1-10.8-4.1-14.8.0L436 82l58.1 58.1 30.9-30.9c4-4.2 4-10.8-.1-14.9z"/></svg>&nbsp;<time datetime=2025-11-05>2025-11-05</time>&nbsp;<svg class="icon" viewBox="0 0 512 512"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3.0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9.0l60.1 60.1c18.8 18.7 18.8 49.1.0 67.9zM284.2 99.8 21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3.0-17l-111-111c-4.8-4.7-12.4-4.7-17.1.0zM124.1 339.9c-5.5-5.5-5.5-14.3.0-19.8l154-154c5.5-5.5 14.3-5.5 19.8.0s5.5 14.3.0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8.0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg>&nbsp;约 6756 字&nbsp;
<svg class="icon" viewBox="0 0 512 512"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5.0-2e2-89.5-2e2-2e2S145.5 56 256 56s2e2 89.5 2e2 2e2-89.5 2e2-2e2 2e2zm61.8-104.4-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6.0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"/></svg>&nbsp;预计阅读 30 分钟&nbsp;</div></div><div class="details toc print:!tw-block" id=toc-static kept=true><div class="details-summary toc-title"><span>目录</span>
<span class=details-icon><svg class="icon" viewBox="0 0 256 512"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9.0l-22.6-22.6c-9.4-9.4-9.4-24.6.0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6.0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9.0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#-基础概念篇>📚 基础概念篇</a></li><li><a href=#-架构技术篇>🏗️ 架构技术篇</a></li><li><a href=#-数学表示篇>🔢 数学表示篇</a></li><li><a href=#-处理流程篇>🔄 处理流程篇</a></li><li><a href=#-工程实践篇>🛠️ 工程实践篇</a></li><li><a href=#-传统模型对比篇>🧠 传统模型对比篇</a></li><li><a href=#-应用场景篇>📊 应用场景篇</a></li><li><a href=#-模型优化与训练技巧篇>🧩 模型优化与训练技巧篇</a></li><li><a href=#-向量检索与知识集成篇>🔍 向量检索与知识集成篇</a></li><li><a href=#-多模态与智能体篇>🧩 多模态与智能体篇</a></li><li><a href=#-模型评估与安全篇>⚙️ 模型评估与安全篇</a></li><li><a href=#-新兴趋势与未来方向篇>🧰 新兴趋势与未来方向篇</a></li><li><a href=#-学习建议>💡 学习建议</a><ul><li><a href=#-核心概念掌握优先级>🎯 核心概念掌握优先级</a></li><li><a href=#-学习路径建议>📖 学习路径建议</a></li><li><a href=#-概念关联图>🔗 概念关联图</a></li></ul></li><li><a href=#-延伸阅读>📚 延伸阅读</a><ul><li><a href=#-ai大模型系统教程系列>🔗 AI大模型系统教程系列</a></li><li><a href=#-使用建议>🎯 使用建议</a></li></ul></li><li><a href=#-附录ai专业术语中英对照速查表az-glossary>📘 附录：AI专业术语中英对照速查表（A–Z Glossary）</a></li></ul></nav></div></div><div class=content id=content data-pagefind-body><h1 id=ai专业名词解释表 class=headerLink><a href=#ai%e4%b8%93%e4%b8%9a%e5%90%8d%e8%af%8d%e8%a7%a3%e9%87%8a%e8%a1%a8 class=header-mark></a>AI专业名词解释表</h1><p>本文档整理了AI大模型领域的核心专业术语，从基础概念到高级技术架构，帮助您系统性地理解人工智能技术体系。</p><hr><h2 id=-基础概念篇 class=headerLink><a href=#-%e5%9f%ba%e7%a1%80%e6%a6%82%e5%bf%b5%e7%af%87 class=header-mark></a>📚 基础概念篇</h2><div class=table-wrapper><table><thead><tr><th style=text-align:>名词</th><th style=text-align:>专业解释</th><th style=text-align:>通俗解释</th><th style=text-align:>举例说明</th></tr></thead><tbody><tr><td style=text-align:><strong>AGI（通用人工智能）</strong></td><td style=text-align:>Artificial General Intelligence，具备人类水平智能的AI系统</td><td style=text-align:>能像人一样思考、学习、创造的全能AI</td><td style=text-align:>一个能同时写诗、编程、做饭、聊天的机器人</td></tr><tr><td style=text-align:><strong>LLM（大语言模型）</strong></td><td style=text-align:>Large Language Model，基于海量数据训练的大型神经网络模型</td><td style=text-align:>能理解和生成人类语言的"超级大脑"</td><td style=text-align:>GPT-4、Claude、文心一言等都是LLM</td></tr><tr><td style=text-align:><strong>训练</strong></td><td style=text-align:>通过大量数据训练神经网络参数的过程</td><td style=text-align:>AI的"学习阶段"，像人读书积累知识</td><td style=text-align:>用互联网所有文本训练一个模型学会语言</td></tr><tr><td style=text-align:><strong>推理</strong></td><td style=text-align:>训练完成的模型根据输入生成输出的过程</td><td style=text-align:>AI的"应用阶段"，像人运用所学知识回答问题</td><td style=text-align:>输入问题后模型生成回答的过程</td></tr><tr><td style=text-align:><strong>Token（词元）</strong></td><td style=text-align:>模型处理文本的最小单元，通过分词算法切分的文本片段</td><td style=text-align:>AI语言的"字粒子"，模型一个一个处理</td><td style=text-align:>&ldquo;我喜欢苹果&rdquo; → [&ldquo;我&rdquo;, &ldquo;喜欢&rdquo;, &ldquo;苹果&rdquo;]</td></tr></tbody></table></div><hr><h2 id=-架构技术篇 class=headerLink><a href=#-%e6%9e%b6%e6%9e%84%e6%8a%80%e6%9c%af%e7%af%87 class=header-mark></a>🏗️ 架构技术篇</h2><div class=table-wrapper><table><thead><tr><th style=text-align:>名词</th><th style=text-align:>专业解释</th><th style=text-align:>通俗解释</th><th style=text-align:>举例说明</th></tr></thead><tbody><tr><td style=text-align:><strong>Transformer</strong></td><td style=text-align:>基于自注意力机制的深度学习架构，2017年Google提出</td><td style=text-align:>现代AI的"神经骨架"，让模型高效理解语言</td><td style=text-align:>GPT、BERT等所有大模型都基于Transformer</td></tr><tr><td style=text-align:><strong>Encoder（编码器）</strong></td><td style=text-align:>将输入序列编码为语义表示的神经网络组件</td><td style=text-align:>AI的"理解器"，把文字变成机器懂的向量</td><td style=text-align:>BERT使用Encoder做文本理解任务</td></tr><tr><td style=text-align:><strong>Decoder（解码器）</strong></td><td style=text-align:>根据上下文逐token生成输出的神经网络组件</td><td style=text-align:>AI的"写作器"，根据理解生成回答</td><td style=text-align:>GPT系列都是Decoder-only模型</td></tr><tr><td style=text-align:><strong>Self-Attention（自注意力）</strong></td><td style=text-align:>计算序列中每个元素与其他元素相关性的机制</td><td style=text-align:>AI自动"关注重点"，像人阅读时抓重点</td><td style=text-align:>&ldquo;银行"在"存钱"中关注"钱&rdquo;，在"钓鱼"中关注"河"</td></tr><tr><td style=text-align:><strong>Multi-Head Attention（多头注意力）</strong></td><td style=text-align:>并行多个自注意力机制，捕获不同类型的依赖关系</td><td style=text-align:>AI从多个角度同时理解文本</td><td style=text-align:>一个头关注语法，另一个头关注语义</td></tr><tr><td style=text-align:><strong>Positional Encoding（位置编码）</strong></td><td style=text-align:>为每个token添加位置信息的向量表示</td><td style=text-align:>让模型知道"谁在前谁在后"</td><td style=text-align:>&ldquo;我爱你"与"你爱我"意义不同</td></tr><tr><td style=text-align:><strong>Query（查询向量）</strong></td><td style=text-align:>主动查询相关信息的向量，表示当前词需要什么信息</td><td style=text-align:>&ldquo;我要找什么"的数字表达</td><td style=text-align:>&ldquo;苹果"查询相关的味道、颜色等属性</td></tr><tr><td style=text-align:><strong>Key（键向量）</strong></td><td style=text-align:>被查询信息的标识向量，表示每个词能提供什么信息</td><td style=text-align:>&ldquo;我能提供什么"的标签</td><td style=text-align:>&ldquo;甜"作为味道特征的Key，等待被查询</td></tr><tr><td style=text-align:><strong>Value（值向量）</strong></td><td style=text-align:>实际内容的表示向量，包含词的真实语义信息</td><td style=text-align:>&ldquo;我的具体内容"的数值化</td><td style=text-align:>&ldquo;甜"的实际语义表示[0.8, 0.2, -0.1]</td></tr><tr><td style=text-align:><strong>Attention Weight（注意力权重）</strong></td><td style=text-align:>表示关注程度的重要性分数，通常通过softmax归一化</td><td style=text-align:>&ldquo;关注程度"的数值化</td><td style=text-align:>0.8表示强烈关注，0.1表示弱关注，所有权重和为1</td></tr><tr><td style=text-align:><strong>Cross-Attention（交叉注意力）</strong></td><td style=text-align:>不同序列间的注意力机制，Query来自一个序列，Key/Value来自另一个序列</td><td style=text-align:>跨模态信息交互</td><td style=text-align:>图文匹配中文字Query关注图像Key/Value</td></tr><tr><td style=text-align:><strong>Causal Attention（因果注意力）</strong></td><td style=text-align:>只能关注当前位置及之前内容的注意力机制，防止未来信息泄露</td><td style=text-align:>&ldquo;只能向前看"的注意力</td><td style=text-align:>GPT生成时第5个词只能看前4个词</td></tr><tr><td style=text-align:><strong>Softmax Function</strong></td><td style=text-align:>将任意实数向量转换为概率分布的激活函数</td><td style=text-align:>转换为"重要性百分比&rdquo;</td><td style=text-align:><code>[2,1,0] → [0.67,0.24,0.09]</code>，保持相对大小关系</td></tr></tbody></table></div><hr><h2 id=-数学表示篇 class=headerLink><a href=#-%e6%95%b0%e5%ad%a6%e8%a1%a8%e7%a4%ba%e7%af%87 class=header-mark></a>🔢 数学表示篇</h2><div class=table-wrapper><table><thead><tr><th style=text-align:>名词</th><th style=text-align:>专业解释</th><th style=text-align:>通俗解释</th><th style=text-align:>举例说明</th></tr></thead><tbody><tr><td style=text-align:><strong>Vector（向量）</strong></td><td style=text-align:>具有大小和方向的数学对象，一组有序数字</td><td style=text-align:>事物的"数字身份证&rdquo;，用数字描述特征</td><td style=text-align:><code>[25, 180, 70]</code>可表示一个人的年龄、身高、体重</td></tr><tr><td style=text-align:><strong>Embedding（嵌入）</strong></td><td style=text-align:>将离散符号映射到连续向量空间的技术</td><td style=text-align:>把文字变成"数字坐标&rdquo;</td><td style=text-align:><code>"国王"→[0.25, -0.12, 0.78, ...]</code></td></tr><tr><td style=text-align:><strong>Query / Key / Value</strong></td><td style=text-align:>自注意力机制中的三个核心向量矩阵，分别代表查询需求、标识信息、实际内容</td><td style=text-align:>Query=我要什么，Key=我能提供什么，Value=我的具体内容</td><td style=text-align:><code>Query=[0.1,0.2]</code>查询味道，<code>Key=[0.8,0.1]</code>标识甜味，<code>Value=[0.9,0.05]</code>甜味的实际表示</td></tr><tr><td style=text-align:><strong>Feed-Forward Network（前馈网络）</strong></td><td style=text-align:>对每个位置独立进行非线性变换</td><td style=text-align:>深化每个词的理解</td><td style=text-align:>&ldquo;春天"进一步联想到"温暖、生长&rdquo;</td></tr><tr><td style=text-align:><strong>Layer Normalization（层归一化）</strong></td><td style=text-align:>标准化层输入</td><td style=text-align:>训练"稳定器&rdquo;</td><td style=text-align:>防止梯度爆炸或发散</td></tr><tr><td style=text-align:><strong>Residual Connection（残差连接）</strong></td><td style=text-align:>跨层连接，保留原始信息</td><td style=text-align:>信息"直通车&rdquo;，防止丢失</td><td style=text-align:>类似捷径路径避免深层网络退化</td></tr></tbody></table></div><hr><h2 id=-处理流程篇 class=headerLink><a href=#-%e5%a4%84%e7%90%86%e6%b5%81%e7%a8%8b%e7%af%87 class=header-mark></a>🔄 处理流程篇</h2><div class=table-wrapper><table><thead><tr><th style=text-align:>名词</th><th style=text-align:>专业解释</th><th style=text-align:>通俗解释</th><th style=text-align:>举例说明</th></tr></thead><tbody><tr><td style=text-align:><strong>Tokenizer（分词器）</strong></td><td style=text-align:>将文本转换为token序列</td><td style=text-align:>&ldquo;文字切菜刀&rdquo;</td><td style=text-align:><code>"Hello world" → ["Hello", " world"]</code></td></tr><tr><td style=text-align:><strong>Context Window（上下文窗口）</strong></td><td style=text-align:>模型能处理的最大token数量限制</td><td style=text-align:>AI的"记忆力上限&rdquo;</td><td style=text-align:>GPT-4有128K上下文</td></tr><tr><td style=text-align:><strong>Decoding（解码）</strong></td><td style=text-align:>根据概率分布逐token生成文本</td><td style=text-align:>AI"写字过程&rdquo;</td><td style=text-align:>从最可能的词开始生成</td></tr><tr><td style=text-align:><strong>Temperature（温度参数）</strong></td><td style=text-align:>控制生成随机性的参数</td><td style=text-align:>&ldquo;创意调节器&rdquo;</td><td style=text-align:>高温更有创意，低温更稳健</td></tr><tr><td style=text-align:><strong>Top-p采样</strong></td><td style=text-align:>基于累积概率的采样策略</td><td style=text-align:>&ldquo;精华筛选器&rdquo;</td><td style=text-align:>只考虑累计概率达到90%的候选词</td></tr><tr><td style=text-align:><strong>Max Tokens（最大令牌数）</strong></td><td style=text-align:>限制生成输出长度</td><td style=text-align:>&ldquo;字数限制器&rdquo;</td><td style=text-align:>防止AI回答过长</td></tr></tbody></table></div><hr><h2 id=-工程实践篇 class=headerLink><a href=#-%e5%b7%a5%e7%a8%8b%e5%ae%9e%e8%b7%b5%e7%af%87 class=header-mark></a>🛠️ 工程实践篇</h2><div class=table-wrapper><table><thead><tr><th style=text-align:>名词</th><th style=text-align:>专业解释</th><th style=text-align:>通俗解释</th><th style=text-align:>举例说明</th></tr></thead><tbody><tr><td style=text-align:><strong>RAG（检索增强生成）</strong></td><td style=text-align:>结合检索和生成的AI方法</td><td style=text-align:>&ldquo;开卷考试"式AI</td><td style=text-align:>先查资料再回答问题</td></tr><tr><td style=text-align:><strong>Prompt Engineering（提示工程）</strong></td><td style=text-align:>设计优化提示词的技术</td><td style=text-align:>&ldquo;说话艺术&rdquo;</td><td style=text-align:>让AI更好理解需求</td></tr><tr><td style=text-align:><strong>Fine-tuning（微调）</strong></td><td style=text-align:>在预训练模型上进行特定任务训练</td><td style=text-align:>&ldquo;定向培训&rdquo;</td><td style=text-align:>让通用模型变成医疗助手</td></tr><tr><td style=text-align:><strong>BPE（字节对编码）</strong></td><td style=text-align:>一种常见分词算法</td><td style=text-align:>&ldquo;文字压缩术&rdquo;</td><td style=text-align:><code>"unhappiness" → ["un","happi","ness"]</code></td></tr><tr><td style=text-align:><strong>Detokenization（反分词）</strong></td><td style=text-align:>将token序列还原为可读文本</td><td style=text-align:>&ldquo;拼字还原&rdquo;</td><td style=text-align:><code>["我","喜欢","苹果"]→"我喜欢苹果"</code></td></tr><tr><td style=text-align:><strong>Streaming（流式输出）</strong></td><td style=text-align:>逐token实时生成输出</td><td style=text-align:>&ldquo;打字机效果&rdquo;</td><td style=text-align:>聊天机器人边输出边思考</td></tr></tbody></table></div><hr><h2 id=-传统模型对比篇 class=headerLink><a href=#-%e4%bc%a0%e7%bb%9f%e6%a8%a1%e5%9e%8b%e5%af%b9%e6%af%94%e7%af%87 class=header-mark></a>🧠 传统模型对比篇</h2><div class=table-wrapper><table><thead><tr><th style=text-align:>名词</th><th style=text-align:>专业解释</th><th style=text-align:>通俗解释</th><th style=text-align:>举例说明</th></tr></thead><tbody><tr><td style=text-align:><strong>RNN（循环神经网络）</strong></td><td style=text-align:>逐步处理序列数据的神经网络</td><td style=text-align:>&ldquo;逐字阅读AI&rdquo;</td><td style=text-align:>翻译<code>"我爱你"</code>逐词处理</td></tr><tr><td style=text-align:><strong>LSTM（长短期记忆网络）</strong></td><td style=text-align:>改进型RNN，解决长期依赖问题</td><td style=text-align:>&ldquo;记忆力更强&rdquo;</td><td style=text-align:>能记住开头内容</td></tr><tr><td style=text-align:><strong>CNN（卷积神经网络）</strong></td><td style=text-align:>擅长处理图像模式的神经网络</td><td style=text-align:>&ldquo;图像专家&rdquo;</td><td style=text-align:>识别猫狗人脸</td></tr><tr><td style=text-align:><strong>Encoder-Decoder架构</strong></td><td style=text-align:>同时包含理解与生成模块的模型</td><td style=text-align:>&ldquo;全能型AI&rdquo;</td><td style=text-align:>机器翻译模型</td></tr></tbody></table></div><hr><h2 id=-应用场景篇 class=headerLink><a href=#-%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af%e7%af%87 class=header-mark></a>📊 应用场景篇</h2><div class=table-wrapper><table><thead><tr><th style=text-align:>名词</th><th style=text-align:>专业解释</th><th style=text-align:>通俗解释</th><th style=text-align:>举例说明</th></tr></thead><tbody><tr><td style=text-align:><strong>对话产品</strong></td><td style=text-align:>面向用户的AI应用接口</td><td style=text-align:>&ldquo;AI聊天壳&rdquo;</td><td style=text-align:>ChatGPT、Claude</td></tr><tr><td style=text-align:><strong>API调用</strong></td><td style=text-align:>程序间通信接口</td><td style=text-align:>&ldquo;AI电话线&rdquo;</td><td style=text-align:>程序调用OpenAI API</td></tr><tr><td style=text-align:><strong>上下文管理</strong></td><td style=text-align:>维护对话历史的技术</td><td style=text-align:>&ldquo;AI记忆力&rdquo;</td><td style=text-align:>聊天机器人记住你说过的话</td></tr><tr><td style=text-align:><strong>多轮对话</strong></td><td style=text-align:>连续人机交互模式</td><td style=text-align:>&ldquo;连续聊天&rdquo;</td><td style=text-align:>先问天气，再问穿衣</td></tr><tr><td style=text-align:><strong>工具调用（Function Calling）</strong></td><td style=text-align:>模型可调用外部API执行任务</td><td style=text-align:>&ldquo;AI动手能力&rdquo;</td><td style=text-align:>AI自动查天气或搜索资料</td></tr></tbody></table></div><hr><h2 id=-模型优化与训练技巧篇 class=headerLink><a href=#-%e6%a8%a1%e5%9e%8b%e4%bc%98%e5%8c%96%e4%b8%8e%e8%ae%ad%e7%bb%83%e6%8a%80%e5%b7%a7%e7%af%87 class=header-mark></a>🧩 模型优化与训练技巧篇</h2><div class=table-wrapper><table><thead><tr><th style=text-align:>名词</th><th style=text-align:>专业解释</th><th style=text-align:>通俗解释</th><th style=text-align:>举例说明</th></tr></thead><tbody><tr><td style=text-align:><strong>LoRA（低秩适配）</strong></td><td style=text-align:>通过低秩矩阵微调模型参数</td><td style=text-align:>&ldquo;轻量级微调&rdquo;</td><td style=text-align:>让LLM快速适应新领域</td></tr><tr><td style=text-align:><strong>Quantization（量化）</strong></td><td style=text-align:>用低精度表示模型参数</td><td style=text-align:>&ldquo;模型瘦身&rdquo;</td><td style=text-align:>FP32→INT8加速推理</td></tr><tr><td style=text-align:><strong>Pruning（剪枝）</strong></td><td style=text-align:>删除冗余神经元或连接</td><td style=text-align:>&ldquo;修枝整形&rdquo;</td><td style=text-align:>去除无效参数</td></tr><tr><td style=text-align:><strong>Distillation（知识蒸馏）</strong></td><td style=text-align:>用大模型指导小模型学习</td><td style=text-align:>&ldquo;老师带学生&rdquo;</td><td style=text-align:>GPT-4教小模型</td></tr><tr><td style=text-align:><strong>Checkpoint（检查点）</strong></td><td style=text-align:>模型训练中保存的中间状态</td><td style=text-align:>&ldquo;训练存档点&rdquo;</td><td style=text-align:>防止断电丢失进度</td></tr></tbody></table></div><hr><h2 id=-向量检索与知识集成篇 class=headerLink><a href=#-%e5%90%91%e9%87%8f%e6%a3%80%e7%b4%a2%e4%b8%8e%e7%9f%a5%e8%af%86%e9%9b%86%e6%88%90%e7%af%87 class=header-mark></a>🔍 向量检索与知识集成篇</h2><div class=table-wrapper><table><thead><tr><th style=text-align:>名词</th><th style=text-align:>专业解释</th><th style=text-align:>通俗解释</th><th style=text-align:>举例说明</th></tr></thead><tbody><tr><td style=text-align:><strong>Embedding Model（向量模型）</strong></td><td style=text-align:>将文本转为语义向量的模型</td><td style=text-align:>&ldquo;语义坐标机&rdquo;</td><td style=text-align:>text-embedding-3-large</td></tr><tr><td style=text-align:><strong>Vector Database（向量数据库）</strong></td><td style=text-align:>支持向量检索的数据库</td><td style=text-align:>&ldquo;语义仓库&rdquo;</td><td style=text-align:>Milvus、Pinecone、FAISS</td></tr><tr><td style=text-align:><strong>Cosine Similarity（余弦相似度）</strong></td><td style=text-align:>衡量两个向量方向相似度</td><td style=text-align:>&ldquo;语义相似度计&rdquo;</td><td style=text-align:><code>"猫在睡觉"≈"猫咪休息中"</code></td></tr><tr><td style=text-align:><strong>Knowledge Graph（知识图谱）</strong></td><td style=text-align:>用节点和关系存储知识结构</td><td style=text-align:>&ldquo;知识地图&rdquo;</td><td style=text-align:><code>"苹果→是→水果"</code></td></tr><tr><td style=text-align:><strong>Hybrid Search（混合检索）</strong></td><td style=text-align:>结合语义检索与关键词匹配</td><td style=text-align:>&ldquo;双保险搜索&rdquo;</td><td style=text-align:>同时检索<code>"猫"</code>和<code>"宠物动物"</code></td></tr></tbody></table></div><hr><h2 id=-多模态与智能体篇 class=headerLink><a href=#-%e5%a4%9a%e6%a8%a1%e6%80%81%e4%b8%8e%e6%99%ba%e8%83%bd%e4%bd%93%e7%af%87 class=header-mark></a>🧩 多模态与智能体篇</h2><div class=table-wrapper><table><thead><tr><th style=text-align:>名词</th><th style=text-align:>专业解释</th><th style=text-align:>通俗解释</th><th style=text-align:>举例说明</th></tr></thead><tbody><tr><td style=text-align:><strong>Multimodal Model（多模态模型）</strong></td><td style=text-align:>同时处理文本、图像、音频等模态</td><td style=text-align:>&ldquo;全感官AI&rdquo;</td><td style=text-align:>GPT-4V、Gemini</td></tr><tr><td style=text-align:><strong>VLM（视觉语言模型）</strong></td><td style=text-align:>Vision-Language Model</td><td style=text-align:>&ldquo;会看图的AI&rdquo;</td><td style=text-align:>看图问答AI</td></tr><tr><td style=text-align:><strong>Speech Recognition（语音识别）</strong></td><td style=text-align:>将语音转文字</td><td style=text-align:>&ldquo;听写AI&rdquo;</td><td style=text-align:>语音输入法</td></tr><tr><td style=text-align:><strong>TTS（文本转语音）</strong></td><td style=text-align:>将文字转语音</td><td style=text-align:>&ldquo;AI播音员&rdquo;</td><td style=text-align:>AI读出回答</td></tr><tr><td style=text-align:><strong>AI Agent（智能体）</strong></td><td style=text-align:>具备自主行动与决策能力的AI</td><td style=text-align:>&ldquo;能动的AI助手&rdquo;</td><td style=text-align:>Devin、AutoGPT</td></tr></tbody></table></div><hr><h2 id=-模型评估与安全篇 class=headerLink><a href=#-%e6%a8%a1%e5%9e%8b%e8%af%84%e4%bc%b0%e4%b8%8e%e5%ae%89%e5%85%a8%e7%af%87 class=header-mark></a>⚙️ 模型评估与安全篇</h2><div class=table-wrapper><table><thead><tr><th style=text-align:>名词</th><th style=text-align:>专业解释</th><th style=text-align:>通俗解释</th><th style=text-align:>举例说明</th></tr></thead><tbody><tr><td style=text-align:><strong>Hallucination（幻觉）</strong></td><td style=text-align:>模型生成虚假信息</td><td style=text-align:>&ldquo;一本正经胡说八道&rdquo;</td><td style=text-align:>编造论文或事实</td></tr><tr><td style=text-align:><strong>Alignment（对齐）</strong></td><td style=text-align:>模型与人类价值观对齐</td><td style=text-align:>&ldquo;价值观调教&rdquo;</td><td style=text-align:>RLHF调教模型</td></tr><tr><td style=text-align:><strong>RLHF（人类反馈强化学习）</strong></td><td style=text-align:>用人类偏好优化模型</td><td style=text-align:>&ldquo;人教AI说话&rdquo;</td><td style=text-align:>ChatGPT的训练方式</td></tr><tr><td style=text-align:><strong>Red Teaming（红队测试）</strong></td><td style=text-align:>对抗性测试模型安全</td><td style=text-align:>&ldquo;安全渗透测试&rdquo;</td><td style=text-align:>测试模型是否泄密</td></tr><tr><td style=text-align:><strong>Bias（偏差）</strong></td><td style=text-align:>模型输出的系统性偏见</td><td style=text-align:>&ldquo;AI偏心&rdquo;</td><td style=text-align:>对性别或语言偏好</td></tr></tbody></table></div><hr><h2 id=-新兴趋势与未来方向篇 class=headerLink><a href=#-%e6%96%b0%e5%85%b4%e8%b6%8b%e5%8a%bf%e4%b8%8e%e6%9c%aa%e6%9d%a5%e6%96%b9%e5%90%91%e7%af%87 class=header-mark></a>🧰 新兴趋势与未来方向篇</h2><div class=table-wrapper><table><thead><tr><th style=text-align:>名词</th><th style=text-align:>专业解释</th><th style=text-align:>通俗解释</th><th style=text-align:>举例说明</th></tr></thead><tbody><tr><td style=text-align:><strong>Mixture of Experts（专家混合）</strong></td><td style=text-align:>包含多个子模型动态激活结构</td><td style=text-align:>&ldquo;专家组AI&rdquo;</td><td style=text-align:><code>Gemini 1.5 Pro</code>架构</td></tr><tr><td style=text-align:><strong>Context Compression（上下文压缩）</strong></td><td style=text-align:>压缩历史对话节省token</td><td style=text-align:>&ldquo;记忆压缩&rdquo;</td><td style=text-align:>长对话摘要</td></tr><tr><td style=text-align:><strong>Memory-Augmented Model（记忆增强模型）</strong></td><td style=text-align:>结合长期记忆机制的AI</td><td style=text-align:>&ldquo;有记忆的AI&rdquo;</td><td style=text-align:><code>ChatGPT</code>长期记忆功能</td></tr><tr><td style=text-align:><strong>Autonomous Agent（自主智能体）</strong></td><td style=text-align:>能自我规划执行任务的AI</td><td style=text-align:>&ldquo;自理AI&rdquo;</td><td style=text-align:><code>AutoGPT</code>、<code>Devin</code></td></tr><tr><td style=text-align:><strong>Synthetic Data（合成数据）</strong></td><td style=text-align:>由AI生成的虚拟训练数据</td><td style=text-align:>&ldquo;AI自制教材&rdquo;</td><td style=text-align:>用AI扩充训练集</td></tr></tbody></table></div><hr><h2 id=-学习建议 class=headerLink><a href=#-%e5%ad%a6%e4%b9%a0%e5%bb%ba%e8%ae%ae class=header-mark></a>💡 学习建议</h2><h3 id=-核心概念掌握优先级 class=headerLink><a href=#-%e6%a0%b8%e5%bf%83%e6%a6%82%e5%bf%b5%e6%8e%8c%e6%8f%a1%e4%bc%98%e5%85%88%e7%ba%a7 class=header-mark></a>🎯 核心概念掌握优先级</h3><ol><li><strong>入门级（必掌握）</strong>：Token、Embedding、Transformer、LLM</li><li><strong>进阶级（重要）</strong>：Self-Attention、RAG、Context Window</li><li><strong>高级（可选）</strong>：LoRA、Mixture of Experts、Red Teaming</li></ol><h3 id=-学习路径建议 class=headerLink><a href=#-%e5%ad%a6%e4%b9%a0%e8%b7%af%e5%be%84%e5%bb%ba%e8%ae%ae class=header-mark></a>📖 学习路径建议</h3><ol><li><strong>理解基本原理</strong>：Token是什么，为什么需要向量表示</li><li><strong>掌握核心架构</strong>：Transformer的Encoder-Decoder结构</li><li><strong>实践应用技巧</strong>：Prompt工程与RAG结合</li><li><strong>深入技术细节</strong>：注意力机制与对齐训练</li></ol><h3 id=-概念关联图 class=headerLink><a href=#-%e6%a6%82%e5%bf%b5%e5%85%b3%e8%81%94%e5%9b%be class=header-mark></a>🔗 概念关联图</h3><div class="code-block highlight is-open show-line-numbers tw-group tw-my-2"><div class="tw-flex
tw-flex-row
tw-flex-1
tw-justify-between
tw-w-full tw-bg-bgColor-secondary"><button class="code-block-button
tw-mx-2
tw-flex
tw-flex-row
tw-flex-1" aria-hidden=true><div class="group-[.is-open]:tw-rotate-90 tw-transition-[transform] tw-duration-500 tw-ease-in-out print:!tw-hidden tw-w-min tw-h-min tw-my-1 tw-mx-1"><svg class="icon" viewBox="0 0 320 512"><path d="M285.476 272.971 91.132 467.314c-9.373 9.373-24.569 9.373-33.941.0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941.0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z"/></svg></div><p class="tw-select-none !tw-my-1">text</p></button><div class=tw-flex><button class="line-number-button
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
group-[.show-line-numbers]:tw-text-fgColor-link
print:!tw-hidden" title="Toggle line numbers"><svg class="icon" viewBox="0 0 512 512"><path d="M61.77 401l17.5-20.15a19.92 19.92.0 005.07-14.19v-3.31C84.34 356 80.5 352 73 352H16a8 8 0 00-8 8v16a8 8 0 008 8h22.83a157.41 157.41.0 00-11 12.31l-5.61 7c-4 5.07-5.25 10.13-2.8 14.88l1.05 1.93c3 5.76 6.29 7.88 12.25 7.88h4.73c10.33.0 15.94 2.44 15.94 9.09.0 4.72-4.2 8.22-14.36 8.22a41.54 41.54.0 01-15.47-3.12c-6.49-3.88-11.74-3.5-15.6 3.12l-5.59 9.31c-3.72 6.13-3.19 11.72 2.63 15.94 7.71 4.69 20.38 9.44 37 9.44 34.16.0 48.5-22.75 48.5-44.12-.03-14.38-9.12-29.76-28.73-34.88zM496 224H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16v-32a16 16 0 00-16-16zm0-160H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16V80a16 16 0 00-16-16zm0 320H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16v-32a16 16 0 00-16-16zM16 160h64a8 8 0 008-8v-16a8 8 0 00-8-8H64V40a8 8 0 00-8-8H32a8 8 0 00-7.14 4.42l-8 16A8 8 0 0024 64h8v64H16a8 8 0 00-8 8v16a8 8 0 008 8zm-3.91 160H80a8 8 0 008-8v-16a8 8 0 00-8-8H41.32c3.29-10.29 48.34-18.68 48.34-56.44.0-29.06-25-39.56-44.47-39.56-21.36.0-33.8 10-40.46 18.75-4.37 5.59-3 10.84 2.8 15.37l8.58 6.88c5.61 4.56 11 2.47 16.12-2.44a13.44 13.44.0 019.46-3.84c3.33.0 9.28 1.56 9.28 8.75C51 248.19.0 257.31.0 304.59v4C0 316 5.08 320 12.09 320z"/></svg></button>
<button class="wrap-code-button
tw-select-none
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
group-[.is-wrap]:tw-text-fgColor-link
print:!tw-hidden" title="Toggle code wrap"><svg class="icon" viewBox="0 0 448 512"><path d="M16 132h416c8.837.0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163.0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"/></svg></button>
<button class="copy-code-button
tw-select-none
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
hover:tw-text-fgColor-link
print:!tw-hidden" title="Copy code">
<span class="copy-icon tw-block"><svg class="icon" viewBox="0 0 448 512"><path d="M433.941 65.941l-51.882-51.882A48 48 0 00348.118.0H176c-26.51.0-48 21.49-48 48v48H48c-26.51.0-48 21.49-48 48v320c0 26.51 21.49 48 48 48h224c26.51.0 48-21.49 48-48v-48h80c26.51.0 48-21.49 48-48V99.882a48 48 0 00-14.059-33.941zM266 464H54a6 6 0 01-6-6V150a6 6 0 016-6h74v224c0 26.51 21.49 48 48 48h96v42a6 6 0 01-6 6zm128-96H182a6 6 0 01-6-6V54a6 6 0 016-6h106v88c0 13.255 10.745 24 24 24h88v202a6 6 0 01-6 6zm6-256h-64V48h9.632c1.591.0 3.117.632 4.243 1.757l48.368 48.368a6 6 0 011.757 4.243V112z"/></svg></span>
<span class="check-icon tw-hidden"><svg class="icon" viewBox="0 0 512 512"><path d="M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206.0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204.0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204.0l36.203 36.204c9.997 9.997 9.997 26.206.0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z"/></svg></span>
</button>
<button class="tw-select-none
tw-mx-2
tw-block
group-[.is-open]:tw-hidden
print:!tw-hidden" disabled aria-hidden=true><svg class="icon" viewBox="0 0 512 512"><path d="M328 256c0 39.8-32.2 72-72 72s-72-32.2-72-72 32.2-72 72-72 72 32.2 72 72zm104-72c-39.8.0-72 32.2-72 72s32.2 72 72 72 72-32.2 72-72-32.2-72-72-72zm-352 0c-39.8.0-72 32.2-72 72s32.2 72 72 72 72-32.2 72-72-32.2-72-72-72z"/></svg></button></div></div><pre style=counter-reset:codeblock class="tw-block tw-m-0 tw-p-0"><code id=codeblock-id-1 class="chroma
!tw-block
tw-p-0
tw-m-0
tw-transition-[max-height]
tw-duration-500
tw-ease-in-out
group-[.is-closed]:!tw-max-h-0
group-[.is-wrap]:tw-text-wrap
tw-overflow-y-hidden
tw-overflow-x-auto
tw-scrollbar-thin"><span class=line><span class=cl>基础概念 → 数学表示 → 架构技术 → 处理流程 → 工程实践 → 优化 → 检索 → 智能体
</span></span><span class=line><span class=cl>↓         ↓         ↓         ↓         ↓         ↓       ↓         ↓
</span></span><span class=line><span class=cl>Token   → Vector   → Transformer → Decoding → RAG → LoRA → Embedding → Agent
</span></span><span class=line><span class=cl>LLM     → Q/K/V    → Attention  → Context → Prompt → Quant → Knowledge → Memory</span></span></code></pre></div><hr><blockquote><p>🚀 <strong>提示</strong>：AI技术体系庞大但高度关联。建议从"理解→实现→优化→安全"四个维度系统学习。</p></blockquote><hr><h2 id=-延伸阅读 class=headerLink><a href=#-%e5%bb%b6%e4%bc%b8%e9%98%85%e8%af%bb class=header-mark></a>📚 延伸阅读</h2><h3 id=-ai大模型系统教程系列 class=headerLink><a href=#-ai%e5%a4%a7%e6%a8%a1%e5%9e%8b%e7%b3%bb%e7%bb%9f%e6%95%99%e7%a8%8b%e7%b3%bb%e5%88%97 class=header-mark></a>🔗 AI大模型系统教程系列</h3><ol><li><strong><a href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B1/ rel>AI大模型完全指南</a></strong> - 从零基础到Token与向量的深度解析</li><li><strong><a href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B2/ rel>Transformer架构深度解析</a></strong> - 注意力机制与AI大模型的核心技术</li><li><strong><a href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B3/ rel>Prompt Engineering完全指南</a></strong> - 从提示工程到上下文工程的实战教程</li><li><strong>[本文] AI专业名词解释表</strong> - 270+术语完全指南与AI技术体系词典</li></ol><h3 id=-使用建议 class=headerLink><a href=#-%e4%bd%bf%e7%94%a8%e5%bb%ba%e8%ae%ae class=header-mark></a>🎯 使用建议</h3><ul><li><strong>学习顺序</strong>：建议按照教程1→教程2→教程3的顺序系统学习，本文作为参考词典随时查阅</li><li><strong>术语查找</strong>：阅读其他教程时遇到不熟悉的术语，可直接在本文中搜索</li><li><strong>知识体系</strong>：结合教程的理论学习和本文的术语解释，建立完整的AI知识体系</li></ul><hr><h2 id=-附录ai专业术语中英对照速查表az-glossary class=headerLink><a href=#-%e9%99%84%e5%bd%95ai%e4%b8%93%e4%b8%9a%e6%9c%af%e8%af%ad%e4%b8%ad%e8%8b%b1%e5%af%b9%e7%85%a7%e9%80%9f%e6%9f%a5%e8%a1%a8az-glossary class=header-mark></a>📘 附录：AI专业术语中英对照速查表（A–Z Glossary）</h2><div class=table-wrapper><table><thead><tr><th style=text-align:>英文缩写 / 术语</th><th style=text-align:>中文名称</th><th style=text-align:>简要说明</th></tr></thead><tbody><tr><td style=text-align:><strong>AGI (Artificial General Intelligence)</strong></td><td style=text-align:>通用人工智能</td><td style=text-align:>具备人类水平通用智能的AI</td></tr><tr><td style=text-align:><strong>Alignment</strong></td><td style=text-align:>对齐</td><td style=text-align:>让AI行为符合人类价值观的过程</td></tr><tr><td style=text-align:><strong>API (Application Programming Interface)</strong></td><td style=text-align:>应用程序接口</td><td style=text-align:>程序间通信调用的标准方式</td></tr><tr><td style=text-align:><strong>AutoGPT / Autonomous Agent</strong></td><td style=text-align:>自主智能体</td><td style=text-align:>能自主规划和执行任务的AI系统</td></tr><tr><td style=text-align:><strong>BERT (Bidirectional Encoder Representations from Transformers)</strong></td><td style=text-align:>双向Transformer编码模型</td><td style=text-align:>代表性的NLP预训练模型</td></tr><tr><td style=text-align:><strong>Bias</strong></td><td style=text-align:>偏差</td><td style=text-align:>模型输出中的系统性不公平</td></tr><tr><td style=text-align:><strong>BPE (Byte Pair Encoding)</strong></td><td style=text-align:>字节对编码</td><td style=text-align:>常用的文本分词算法</td></tr><tr><td style=text-align:><strong>Checkpoint</strong></td><td style=text-align:>检查点</td><td style=text-align:>模型训练过程中保存的中间状态</td></tr><tr><td style=text-align:><strong>CNN (Convolutional Neural Network)</strong></td><td style=text-align:>卷积神经网络</td><td style=text-align:>擅长图像识别的网络结构</td></tr><tr><td style=text-align:><strong>Context Window</strong></td><td style=text-align:>上下文窗口</td><td style=text-align:>模型可处理的最大token数量</td></tr><tr><td style=text-align:><strong>Context Compression</strong></td><td style=text-align:>上下文压缩</td><td style=text-align:>对历史内容进行摘要以节省上下文</td></tr><tr><td style=text-align:><strong>Cosine Similarity</strong></td><td style=text-align:>余弦相似度</td><td style=text-align:>衡量向量间语义相似度的指标</td></tr><tr><td style=text-align:><strong>Decoder</strong></td><td style=text-align:>解码器</td><td style=text-align:>将语义向量生成文本的网络模块</td></tr><tr><td style=text-align:><strong>Decoding</strong></td><td style=text-align:>解码过程</td><td style=text-align:>模型生成文本的过程</td></tr><tr><td style=text-align:><strong>Detokenization</strong></td><td style=text-align:>反分词</td><td style=text-align:>将token序列还原为文字</td></tr><tr><td style=text-align:><strong>Distillation (Knowledge Distillation)</strong></td><td style=text-align:>知识蒸馏</td><td style=text-align:>大模型指导小模型学习的技术</td></tr><tr><td style=text-align:><strong>Embedding</strong></td><td style=text-align:>嵌入</td><td style=text-align:>将离散词语映射到连续向量空间</td></tr><tr><td style=text-align:><strong>Embedding Model</strong></td><td style=text-align:>向量模型</td><td style=text-align:>生成文本语义向量的模型</td></tr><tr><td style=text-align:><strong>Encoder</strong></td><td style=text-align:>编码器</td><td style=text-align:>将文本转换为语义表示的网络组件</td></tr><tr><td style=text-align:><strong>Encoder–Decoder</strong></td><td style=text-align:>编码–解码结构</td><td style=text-align:>同时具备理解与生成能力的模型架构</td></tr><tr><td style=text-align:><strong>Feed Forward Network (FFN)</strong></td><td style=text-align:>前馈网络</td><td style=text-align:>Transformer层内的非线性变换模块</td></tr><tr><td style=text-align:><strong>Fine-tuning</strong></td><td style=text-align:>微调</td><td style=text-align:>基于预训练模型进行特定任务再训练</td></tr><tr><td style=text-align:><strong>Function Calling</strong></td><td style=text-align:>工具调用</td><td style=text-align:>模型调用外部API执行操作的能力</td></tr><tr><td style=text-align:><strong>Hallucination</strong></td><td style=text-align:>幻觉</td><td style=text-align:>模型生成虚假或编造信息的现象</td></tr><tr><td style=text-align:><strong>Hybrid Search</strong></td><td style=text-align:>混合检索</td><td style=text-align:>结合语义检索与关键词搜索的技术</td></tr><tr><td style=text-align:><strong>Knowledge Graph</strong></td><td style=text-align:>知识图谱</td><td style=text-align:>用节点和关系结构化存储知识的网络</td></tr><tr><td style=text-align:><strong>Layer Normalization</strong></td><td style=text-align:>层归一化</td><td style=text-align:>网络层输入的标准化过程</td></tr><tr><td style=text-align:><strong>Latency</strong></td><td style=text-align:>延迟</td><td style=text-align:>模型从输入到输出的响应时间</td></tr><tr><td style=text-align:><strong>LLM (Large Language Model)</strong></td><td style=text-align:>大语言模型</td><td style=text-align:>基于大规模语料训练的语言模型</td></tr><tr><td style=text-align:><strong>LoRA (Low-Rank Adaptation)</strong></td><td style=text-align:>低秩适配</td><td style=text-align:>轻量级模型微调方法</td></tr><tr><td style=text-align:><strong>LSTM (Long Short-Term Memory)</strong></td><td style=text-align:>长短期记忆网络</td><td style=text-align:>能捕获长距离依赖的RNN变体</td></tr><tr><td style=text-align:><strong>Memory-Augmented Model</strong></td><td style=text-align:>记忆增强模型</td><td style=text-align:>具备长期记忆能力的AI</td></tr><tr><td style=text-align:><strong>Mixture of Experts (MoE)</strong></td><td style=text-align:>专家混合模型</td><td style=text-align:>动态选择多个子模型协作的架构</td></tr><tr><td style=text-align:><strong>Multi-Head Attention</strong></td><td style=text-align:>多头注意力</td><td style=text-align:>并行计算多种注意力的机制</td></tr><tr><td style=text-align:><strong>Positional Encoding</strong></td><td style=text-align:>位置编码</td><td style=text-align:>为token添加位置信息的方式</td></tr><tr><td style=text-align:><strong>Pruning</strong></td><td style=text-align:>剪枝</td><td style=text-align:>删除冗余参数减小模型规模</td></tr><tr><td style=text-align:><strong>Prompt Engineering</strong></td><td style=text-align:>提示工程</td><td style=text-align:>优化提示词以提升模型输出质量</td></tr><tr><td style=text-align:><strong>Quantization</strong></td><td style=text-align:>量化</td><td style=text-align:>用低精度表示模型参数以提升性能</td></tr><tr><td style=text-align:><strong>Query / Key / Value (QKV)</strong></td><td style=text-align:>查询 / 键 / 值</td><td style=text-align:>自注意力机制的三要素</td></tr><tr><td style=text-align:><strong>RAG (Retrieval-Augmented Generation)</strong></td><td style=text-align:>检索增强生成</td><td style=text-align:>将外部知识检索与生成结合的技术</td></tr><tr><td style=text-align:><strong>Red Teaming</strong></td><td style=text-align:>红队测试</td><td style=text-align:>通过对抗输入评估模型安全性</td></tr><tr><td style=text-align:><strong>Residual Connection</strong></td><td style=text-align:>残差连接</td><td style=text-align:>跨层信息直通结构，防止梯度退化</td></tr><tr><td style=text-align:><strong>RLHF (Reinforcement Learning from Human Feedback)</strong></td><td style=text-align:>人类反馈强化学习</td><td style=text-align:>通过人类偏好优化模型输出</td></tr><tr><td style=text-align:><strong>RNN (Recurrent Neural Network)</strong></td><td style=text-align:>循环神经网络</td><td style=text-align:>逐步处理序列数据的网络结构</td></tr><tr><td style=text-align:><strong>Self-Attention</strong></td><td style=text-align:>自注意力</td><td style=text-align:>计算序列中元素相关性的机制</td></tr><tr><td style=text-align:><strong>Streaming</strong></td><td style=text-align:>流式输出</td><td style=text-align:>模型边生成边输出的方式</td></tr><tr><td style=text-align:><strong>Synthetic Data</strong></td><td style=text-align:>合成数据</td><td style=text-align:>AI生成的虚拟训练数据</td></tr><tr><td style=text-align:><strong>Temperature</strong></td><td style=text-align:>温度参数</td><td style=text-align:>控制生成随机性的参数</td></tr><tr><td style=text-align:><strong>Throughput</strong></td><td style=text-align:>吞吐量</td><td style=text-align:>每秒处理的请求数量</td></tr><tr><td style=text-align:><strong>Token</strong></td><td style=text-align:>词元</td><td style=text-align:>模型处理文本的最小单位</td></tr><tr><td style=text-align:><strong>Tokenizer</strong></td><td style=text-align:>分词器</td><td style=text-align:>将文本拆分为token的工具</td></tr><tr><td style=text-align:><strong>Top-p Sampling</strong></td><td style=text-align:>累积概率采样</td><td style=text-align:>过滤低概率词汇的生成策略</td></tr><tr><td style=text-align:><strong>Transformer</strong></td><td style=text-align:>Transformer架构</td><td style=text-align:>基于注意力机制的核心神经网络</td></tr><tr><td style=text-align:><strong>TTS (Text-to-Speech)</strong></td><td style=text-align:>文本转语音</td><td style=text-align:>将文字转为自然语音</td></tr><tr><td style=text-align:><strong>Vector</strong></td><td style=text-align:>向量</td><td style=text-align:>数字化表示实体特征的数学结构</td></tr><tr><td style=text-align:><strong>Vector Database</strong></td><td style=text-align:>向量数据库</td><td style=text-align:>存储并按语义检索向量数据的系统</td></tr><tr><td style=text-align:><strong>VLM (Vision-Language Model)</strong></td><td style=text-align:>视觉语言模型</td><td style=text-align:>同时理解图像与语言的模型</td></tr><tr><td style=text-align:><strong>Weight</strong></td><td style=text-align:>权重参数</td><td style=text-align:>模型中可学习的核心数值参数</td></tr></tbody></table></div><hr></div><h2>相关内容</h2><div class=related-container><div class=related-item-container><h2 class=related-title><a href=/pg-vector%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/>Docker安装PostgreSQL+pgvector完整教程：AI向量数据库快速部署指南</a></h2></div><div class=related-item-container><h2 class=related-title><a href=/ai%E6%95%99%E7%A8%8B4/>CPU/GPU 与大模型训练</a></h2></div><div class=related-item-container><h2 class=related-title><a href=/ai%E6%95%99%E7%A8%8B5/>RAG系统完全指南——从零搭建本地检索增强生成系统</a></h2></div><div class=related-item-container><h2 class=related-title><a href=/ai%E6%95%99%E7%A8%8B3/>Prompt Engineering完全指南：从提示工程到上下文工程的实战教程</a></h2></div><div class=related-item-container><h2 class=related-title><a href=/ai%E6%95%99%E7%A8%8B2/>Transformer架构深度解析：注意力机制与AI大模型的核心技术</a></h2></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>更新于 2025-11-05</span></div><div class=post-info-license></div></div><div class="post-info-line print:!tw-hidden"><div class=post-info-md></div><div class=post-info-share><button title="分享到 Twitter" data-sharer=twitter data-url=https://byronfinn.github.io/ai%E4%B8%93%E4%B8%9A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A%E8%A1%A8/ data-title=AI专业名词解释表：270+术语完全指南与AI技术体系词典 data-hashtags=AI专业名词,人工智能术语,AI词典,机器学习,深度学习,Transformer,LLM,Prompt工程,RAG,向量数据库,注意力机制,神经网络><svg class="icon" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></button><button title="分享到 Evernote" data-sharer=evernote data-url=https://byronfinn.github.io/ai%E4%B8%93%E4%B8%9A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A%E8%A1%A8/ data-title=AI专业名词解释表：270+术语完全指南与AI技术体系词典><svg class="icon" viewBox="0 0 384 512"><path d="M120.82 132.21c1.6 22.31-17.55 21.59-21.61 21.59-68.93.0-73.64-1-83.58 3.34-.56.22-.74.0-.37-.37L123.79 46.45c.38-.37.6-.22.38.37-4.35 9.99-3.35 15.09-3.35 85.39zm79 308c-14.68-37.08 13-76.93 52.52-76.62 17.49.0 22.6 23.21 7.95 31.42-6.19 3.3-24.95 1.74-25.14 19.2-.05 17.09 19.67 25 31.2 24.89A45.64 45.64.0 00312 393.45v-.08c0-11.63-7.79-47.22-47.54-55.34-7.72-1.54-65-6.35-68.35-50.52-3.74 16.93-17.4 63.49-43.11 69.09-8.74 1.94-69.68 7.64-112.92-36.77.0.0-18.57-15.23-28.23-57.95-3.38-15.75-9.28-39.7-11.14-62 0-18 11.14-30.45 25.07-32.2 81 0 90 2.32 101-7.8 9.82-9.24 7.8-15.5 7.8-102.78 1-8.3 7.79-30.81 53.41-24.14 6 .86 31.91 4.18 37.48 30.64l64.26 11.15c20.43 3.71 70.94 7 80.6 57.94 22.66 121.09 8.91 238.46 7.8 238.46C362.15 485.53 267.06 480 267.06 480c-18.95-.23-54.25-9.4-67.27-39.83zm80.94-204.84c-1 1.92-2.2 6 .85 7 14.09 4.93 39.75 6.84 45.88 5.53 3.11-.25 3.05-4.43 2.48-6.65-3.53-21.85-40.83-26.5-49.24-5.92z"/></svg></button></div></div></div><div class=post-info-more><section class=post-tags><svg class="icon" viewBox="0 0 640 512"><path d="M497.941 225.941 286.059 14.059A48 48 0 00252.118.0H48C21.49.0.0 21.49.0 48v204.118a48 48 0 0014.059 33.941l211.882 211.882c18.744 18.745 49.136 18.746 67.882.0l204.118-204.118c18.745-18.745 18.745-49.137.0-67.882zM112 160c-26.51.0-48-21.49-48-48s21.49-48 48-48 48 21.49 48 48-21.49 48-48 48zm513.941 133.823L421.823 497.941c-18.745 18.745-49.137 18.745-67.882.0l-.36-.36L527.64 323.522c16.999-16.999 26.36-39.6 26.36-63.64s-9.362-46.641-26.36-63.64L331.397.0h48.721a48 48 0 0133.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137.0 67.882z"/></svg>&nbsp;<a href=/tags/ai%E4%B8%93%E4%B8%9A%E5%90%8D%E8%AF%8D/>AI专业名词</a>,&nbsp;<a href=/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%9C%AF%E8%AF%AD/>人工智能术语</a>,&nbsp;<a href=/tags/ai%E8%AF%8D%E5%85%B8/>AI词典</a>,&nbsp;<a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a>,&nbsp;<a href=/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/>深度学习</a>,&nbsp;<a href=/tags/transformer/>Transformer</a>,&nbsp;<a href=/tags/llm/>LLM</a>,&nbsp;<a href=/tags/prompt%E5%B7%A5%E7%A8%8B/>Prompt工程</a>,&nbsp;<a href=/tags/rag/>RAG</a>,&nbsp;<a href=/tags/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/>向量数据库</a>,&nbsp;<a href=/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/>注意力机制</a>,&nbsp;<a href=/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/>神经网络</a></section><section class=print:!tw-hidden><span><button class="tw-text-fgColor-link-muted hover:tw-text-fgColor-link-muted-hover" onclick=window.history.back()>返回</button></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class="post-nav print:tw-hidden"><a href=/ai%E6%95%99%E7%A8%8B3/ class=prev rel=prev title="Prompt Engineering完全指南：从提示工程到上下文工程的实战教程"><svg class="icon" viewBox="0 0 256 512"><path d="M31.7 239l136-136c9.4-9.4 24.6-9.4 33.9.0l22.6 22.6c9.4 9.4 9.4 24.6.0 33.9L127.9 256l96.4 96.4c9.4 9.4 9.4 24.6.0 33.9L201.7 409c-9.4 9.4-24.6 9.4-33.9.0l-136-136c-9.5-9.4-9.5-24.6-.1-34z"/></svg>Prompt Engineering完全指南：从提示工程到上下文工程的实战教程</a>
<a href=/tiktok%E7%9A%84%E5%9B%B0%E5%B1%80/ class=next rel=next title=当TikTok遇上特朗普：做多错多，何以关关难过关关过>当TikTok遇上特朗普：做多错多，何以关关难过关关过<svg class="icon" viewBox="0 0 256 512"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9.0l-22.6-22.6c-9.4-9.4-9.4-24.6.0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6.0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9.0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a></div></div><div id=comments class="print:!tw-hidden tw-pt-32 tw-pb-8"><div id=giscus></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://giscus.app/>giscus</a>.</noscript></div></article></main><footer class=footer><div class=footer-container><div class=footer-line><svg class="icon" viewBox="0 0 512 512"><path d="M256 8C119.033 8 8 119.033 8 256s111.033 248 248 248 248-111.033 248-248S392.967 8 256 8zm0 448c-110.532.0-2e2-89.451-2e2-2e2.0-110.531 89.451-2e2 2e2-2e2 110.532.0 2e2 89.451 2e2 2e2.0 110.532-89.451 2e2-2e2 2e2zm107.351-101.064c-9.614 9.712-45.53 41.396-104.065 41.396-82.43.0-140.484-61.425-140.484-141.567.0-79.152 60.275-139.401 139.762-139.401 55.531.0 88.738 26.62 97.593 34.779a11.965 11.965.0 011.936 15.322l-18.155 28.113c-3.841 5.95-11.966 7.282-17.499 2.921-8.595-6.776-31.814-22.538-61.708-22.538-48.303.0-77.916 35.33-77.916 80.082.0 41.589 26.888 83.692 78.277 83.692 32.657.0 56.843-19.039 65.726-27.225 5.27-4.857 13.596-4.039 17.82 1.738l19.865 27.17a11.947 11.947.0 01-1.152 15.518z"/></svg>2025<span class=author>&nbsp;<a href=https://blog.baifan.site target=_blank rel="noopener noreferrer">Finn</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class=footer-line></div><div class=footer-line></div></div><script>"serviceWorker"in navigator&&(navigator.serviceWorker.register("/sw.min.js",{scope:"/"}).then(function(){}),navigator.serviceWorker.ready.then(function(){}))</script></footer><div class="print:!tw-hidden tw-flex tw-flex-col tw-fixed tw-right-4 tw-bottom-4 tw-gap-2"><a href=#back-to-top id=back-to-top-button class="tw-transition-opacity tw-opacity-0 tw-block tw-bg-bgColor-secondary tw-rounded-full" style=padding:.6rem;line-height:1.3rem;font-size:1rem title=回到顶部><svg class="icon" viewBox="0 0 448 512"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6.0-33.9L207 39c9.4-9.4 24.6-9.4 33.9.0l194.3 194.3c9.4 9.4 9.4 24.6.0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3.0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg>
</a><button id=toc-drawer-button class="tw-block tw-bg-bgColor-secondary tw-rounded-full md:tw-hidden" style=padding:.6rem;line-height:1.3rem;font-size:1rem>
<svg class="icon" viewBox="0 0 448 512"><path d="M16 132h416c8.837.0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163.0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"/></svg>
</button><a href=#comments id=view-comments class="tw-block tw-bg-bgColor-secondary tw-rounded-full" style=padding:.6rem;line-height:1.3rem;font-size:1rem title=查看评论>
<svg class="icon" viewBox="0 0 512 512"><path d="M256 32C114.6 32 0 125.1.0 240c0 49.6 21.4 95 57 130.7C44.5 421.1 2.7 466 2.2 466.5c-2.2 2.3-2.8 5.7-1.5 8.7S4.8 480 8 480c66.3.0 116-31.8 140.6-51.4 32.7 12.3 69 19.4 107.4 19.4 141.4.0 256-93.1 256-208S397.4 32 256 32z"/></svg></a></div><div id=cookieconsent-container></div><link rel=stylesheet href=/lib/katex/katex.min.0c8126645bb983a788b167b1b97abe2505a962ad45e049001463c46012012a9b.css integrity="sha256-DIEmZFu5g6eIsWexuXq+JQWpYq1F4EkAFGPEYBIBKps="><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/katex/copy-tex.min.cf8e3e934d92a839d209ffdac331fa693da5958a6dff2c8788a4713cc1f50a47.css integrity="sha256-z44+k02SqDnSCf/awzH6aT2llYpt/yyHiKRxPMH1Ckc="><noscript><link rel=stylesheet href=/lib/katex/copy-tex.min.cf8e3e934d92a839d209ffdac331fa693da5958a6dff2c8788a4713cc1f50a47.css integrity="sha256-z44+k02SqDnSCf/awzH6aT2llYpt/yyHiKRxPMH1Ckc="></noscript><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.cd0d0b6e50ff01ff2f3a9a70d7cfb66a7c6cb9acf7a566325568be6d3bd31fc4.css integrity="sha256-zQ0LblD/Af8vOppw18+2anxsuaz3pWYyVWi+bTvTH8Q="><link rel=stylesheet href=/css/profile.003e858ff1233d9b981c64a8f06ff6ef394ebd60f81a472e374eb195bb673c7d.css integrity="sha256-AD6Fj/EjPZuYHGSo8G/27zlOvWD4GkcuN06xlbtnPH0="><script>window.config={"autocomplete.min.js":"/lib/autocomplete/autocomplete.min.js",comment:{giscus:{darkTheme:"dark",dataCategory:"Announcements",dataCategoryId:"DIC_kwDOQOVlP84Cxa17",dataEmitMetadata:"0",dataInputPosition:"top",dataLang:"zh-CN",dataLoading:"lazy",dataMapping:"pathname",dataReactionsEnabled:"1",dataRepo:"ByronFinn/ByronFinn.github.io",dataRepoId:"R_kgDOQOVlPw",dataStrict:"0",lightTheme:"light"}},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验."},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},data:{"desktop-header-typeit":"Daily Deep Think","mobile-header-typeit":"Daily Deep Think"},"fuse.min.js":"/lib/fuse/fuse.min.js",math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{distance:100,findAllMatches:!1,fuseIndexURL:"/index.json",highlightTag:"em",ignoreFieldNorm:!1,ignoreLocation:!1,isCaseSensitive:!1,location:0,maxResultLength:10,minMatchCharLength:2,noResultsFound:"没有找到结果",snippetLength:50,threshold:.3,type:"fuse",useExtendedSearch:!1},sharerjs:!0,table:{sort:!0},twemoji:!0,typeit:{cursorChar:"|",cursorSpeed:1e3,data:{"desktop-header-typeit":["desktop-header-typeit"],"mobile-header-typeit":["mobile-header-typeit"]},duration:-1,speed:100}}</script><script src=/lib/tablesort/tablesort.min.92de6dec051677787aed63503575b2f9be73f21f2745574e59647bc139a92d40.js integrity="sha256-kt5t7AUWd3h67WNQNXWy+b5z8h8nRVdOWWR7wTmpLUA="></script><script src=/lib/twemoji/twemoji.min.0e0e5259e3ff8ea805e0c5660c6336f7f46b14332e3cafb82939e1db3da8b6f8.js integrity="sha256-Dg5SWeP/jqgF4MVmDGM29/RrFDMuPK+4KTnh2z2otvg=" defer></script><script src=/js/twemoji.min.js defer></script><script src=/lib/sharer/sharer.min.8fe10eb615eb163a20f795484430a012805ec7c8c11df52df54ddb7a46084254.js integrity="sha256-j+EOthXrFjog95VIRDCgEoBex8jBHfUt9U3bekYIQlQ="></script><script src=/lib/typeit/typeit.min.06e0b9ba7bb3c9368aa26979037019306fef8e43dd2b9276854d227381445d0f.js integrity="sha256-BuC5unuzyTaKoml5A3AZMG/vjkPdK5J2hU0ic4FEXQ8="></script><script src=/lib/katex/katex.min.76d534cf1167067008fca12c4e903fc44cf8cfda8c5279c318d1f78cd90b086e.js integrity="sha256-dtU0zxFnBnAI/KEsTpA/xEz4z9qMUnnDGNH3jNkLCG4=" defer></script><script src=/lib/katex/auto-render.min.bb53eb953394531aae36fdd537065c4244eb8542901a3ce914601d932675b8ac.js integrity="sha256-u1PrlTOUUxquNv3VNwZcQkTrhUKQGjzpFGAdkyZ1uKw=" defer></script><script src=/lib/katex/copy-tex.min.07770af90943a1de1a1010794bc78c6a7346d46d48fb63e35cc76ba76b827604.js integrity="sha256-B3cK+QlDod4aEBB5S8eManNG1G1I+2PjXMdrp2uCdgQ=" defer></script><script src=/lib/katex/mhchem.min.9f87e5e9c384a160472d0045035a8641f6013358eddb3ece708634a50f946a40.js integrity="sha256-n4fl6cOEoWBHLQBFA1qGQfYBM1jt2z7OcIY0pQ+UakA=" defer></script><script src=/js/katex.min.js defer></script><script src=/lib/cookieconsent/cookieconsent.min.e55842a856a6d829feca3c3ad736c136b6c7549e9247274f78aa296259e06e24.js integrity="sha256-5VhCqFam2Cn+yjw61zbBNrbHVJ6SRydPeKopYlngbiQ=" defer></script><script src=/js/cookieconsent.min.js defer></script><script src=/js/theme.min.js defer></script><script src=/js/giscus.min.js defer></script><script type=speculationrules>
  {
    "prerender": [
      {
        "where": { "href_matches": "/*" },
        "eagerness": "moderate"
      }
    ]
  }
</script></body></html>