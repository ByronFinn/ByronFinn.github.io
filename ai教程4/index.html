<!doctype html><html lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>CPU/GPU 与大模型训练 - 每日深度思考 | 技术、经济分析与深度思考</title><meta name=Description content="AI教程第四篇：深度学习GPU加速实战指南。涵盖CPU/GPU架构对比、张量与精度量化、CUDA编程实战、PyTorch训练工作流、硬件选型与显存优化，包含面试问答与排错清单，助你掌握AI模型训练的核心工程技能。"><meta property="og:url" content="https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B4/"><meta property="og:site_name" content="每日深度思考 | 技术、经济分析与深度思考"><meta property="og:title" content="CPU/GPU 与大模型训练"><meta property="og:description" content="AI教程第四篇：深度学习GPU加速实战指南。涵盖CPU/GPU架构对比、张量与精度量化、CUDA编程实战、PyTorch训练工作流、硬件选型与显存优化，包含面试问答与排错清单，助你掌握AI模型训练的核心工程技能。"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-11-06T09:36:42+08:00"><meta property="article:modified_time" content="2025-11-06T09:36:42+08:00"><meta property="article:tag" content="GPU"><meta property="article:tag" content="CUDA"><meta property="article:tag" content="PyTorch"><meta property="article:tag" content="模型训练"><meta property="article:tag" content="深度学习"><meta property="article:tag" content="教程"><meta property="og:image" content="https://byronfinn.github.io/pictures/avatar/angryCat.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://byronfinn.github.io/pictures/avatar/angryCat.png"><meta name=twitter:title content="CPU/GPU 与大模型训练"><meta name=twitter:description content="AI教程第四篇：深度学习GPU加速实战指南。涵盖CPU/GPU架构对比、张量与精度量化、CUDA编程实战、PyTorch训练工作流、硬件选型与显存优化，包含面试问答与排错清单，助你掌握AI模型训练的核心工程技能。"><meta name=application-name content="Daily Deep Think"><meta name=apple-mobile-web-app-title content="Daily Deep Think"><meta name=theme-color content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel=icon href=/static/icos/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B4/><link rel=prev href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B5/><link rel=next href=https://byronfinn.github.io/pg-vector%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/><link rel=stylesheet href=/css/main.min.css><link rel=stylesheet href=/css/style.min.css><meta name=google-site-verification content="google8f3e688b6959e353"><meta name=msvalidate.01 content="请在此添加你的Bing验证码"><meta name=yandex-verification content="请在此添加你的Yandex验证码"><meta name=p:domain_verify content="请在此添加你的Pinterest验证码"><meta name=baidu-site-verification content="请在此添加你的百度验证码"><meta name=sogou_site_verification content="请在此添加你的搜狗验证码"><meta name=360-site-verification content="请在此添加你的360搜索验证码"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"CPU/GPU 与大模型训练","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B4/"},"image":["https://byronfinn.github.io/pictures/avatar/angryCat.png"],"genre":"posts","keywords":["GPU训练","CUDA编程","张量精度","模型量化","深度学习硬件","PyTorch教程","AI模型训练","显存优化","硬件选型","AI实战"],"wordcount":3592,"url":"https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B4/","datePublished":"2025-11-06T09:36:42+08:00","dateModified":"2025-11-06T09:36:42+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Finn","url":"https://blog.baifan.site"},"description":"AI教程第四篇：深度学习GPU加速实战指南。涵盖CPU/GPU架构对比、张量与精度量化、CUDA编程实战、PyTorch训练工作流、硬件选型与显存优化，包含面试问答与排错清单，助你掌握AI模型训练的核心工程技能。"}</script></head><body data-instant-intensity=viewport class="tw-flex tw-min-h-screen tw-flex-col"><script>function setTheme(e){document.body.setAttribute("theme",e),document.documentElement.className=e,document.documentElement.style.setProperty("color-scheme",e==="light"?"light":"dark"),e==="light"?document.documentElement.classList.remove("tw-dark"):document.documentElement.classList.add("tw-dark"),window.theme=e,window.isDark=window.theme!=="light"}function saveTheme(e){window.localStorage&&localStorage.setItem("theme",e)}function getMeta(e){const t=document.getElementsByTagName("meta");for(let n=0;n<t.length;n++)if(t[n].getAttribute("name")===e)return t[n];return""}if(window.localStorage&&localStorage.getItem("theme")){let e=localStorage.getItem("theme");e==="light"||e==="dark"?setTheme(e):setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")}else"auto"==="light"||"auto"==="dark"?(setTheme("auto"),saveTheme("auto")):(saveTheme("auto"),setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"));let metaColors={light:"#f8f8f8",dark:"#161b22"};getMeta("theme-color").content=metaColors[document.body.getAttribute("theme")],window.switchThemeEventSet=new Set</script><div id=back-to-top></div><div id=mask></div><header class="desktop print:!tw-hidden" id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="每日深度思考 | 技术、经济分析与深度思考"><span id=desktop-header-typeit class=typeit></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/profile/ title=了解我的个人信息和专业背景>关于我 </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder=搜索... id=search-input-desktop>
<button class="search-button search-toggle" id=search-toggle-desktop title=搜索>
<svg class="icon" viewBox="0 0 512 512"><path d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</button>
<button class="search-button search-clear" id=search-clear-desktop title=清空>
<svg class="icon" viewBox="0 0 512 512"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm121.6 313.1c4.7 4.7 4.7 12.3.0 17L338 377.6c-4.7 4.7-12.3 4.7-17 0L256 312l-65.1 65.6c-4.7 4.7-12.3 4.7-17 0L134.4 338c-4.7-4.7-4.7-12.3.0-17l65.6-65-65.6-65.1c-4.7-4.7-4.7-12.3.0-17l39.6-39.6c4.7-4.7 12.3-4.7 17 0l65 65.7 65.1-65.6c4.7-4.7 12.3-4.7 17 0l39.6 39.6c4.7 4.7 4.7 12.3.0 17L312 256l65.6 65.1z"/></svg>
</button>
<span class="search-button search-loading tw-animate-spin" id=search-loading-desktop><svg class="icon" viewBox="0 0 512 512"><path d="M304 48c0 26.51-21.49 48-48 48s-48-21.49-48-48 21.49-48 48-48 48 21.49 48 48zm-48 368c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm208-208c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zM96 256c0-26.51-21.49-48-48-48S0 229.49.0 256s21.49 48 48 48 48-21.49 48-48zm12.922 99.078c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.491-48-48-48zm294.156.0c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.49-48-48-48zM108.922 60.922c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.491-48-48-48z"/></svg>
</span></span><button class="menu-item theme-switch" aria-label=切换主题>
<svg class="icon" viewBox="0 0 512 512"><path d="M8 256c0 136.966 111.033 248 248 248s248-111.034 248-248S392.966 8 256 8 8 119.033 8 256zm248 184V72c101.705.0 184 82.311 184 184 0 101.705-82.311 184-184 184z"/></svg></button></div></div></div></header><header class="mobile print:!tw-hidden" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="每日深度思考 | 技术、经济分析与深度思考"><span id=mobile-header-typeit class=typeit></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索... id=search-input-mobile>
<button class="search-button search-toggle tw-h-10" id=search-toggle-mobile title=搜索>
<svg class="icon" viewBox="0 0 512 512"><path d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</button>
<button class="search-button search-clear tw-h-fit" id=search-clear-mobile title=清空>
<svg class="icon" viewBox="0 0 512 512"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm121.6 313.1c4.7 4.7 4.7 12.3.0 17L338 377.6c-4.7 4.7-12.3 4.7-17 0L256 312l-65.1 65.6c-4.7 4.7-12.3 4.7-17 0L134.4 338c-4.7-4.7-4.7-12.3.0-17l65.6-65-65.6-65.1c-4.7-4.7-4.7-12.3.0-17l39.6-39.6c4.7-4.7 12.3-4.7 17 0l65 65.7 65.1-65.6c4.7-4.7 12.3-4.7 17 0l39.6 39.6c4.7 4.7 4.7 12.3.0 17L312 256l65.6 65.1z"/></svg>
</button>
<span class="search-button search-loading tw-animate-spin" id=search-loading-mobile><svg class="icon" viewBox="0 0 512 512"><path d="M304 48c0 26.51-21.49 48-48 48s-48-21.49-48-48 21.49-48 48-48 48 21.49 48 48zm-48 368c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm208-208c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zM96 256c0-26.51-21.49-48-48-48S0 229.49.0 256s21.49 48 48 48 48-21.49 48-48zm12.922 99.078c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.491-48-48-48zm294.156.0c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.49-48-48-48zM108.922 60.922c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.491-48-48-48z"/></svg></span></div><button class=search-cancel id=search-cancel-mobile>
取消</button></div><a class=menu-item href=/posts/ title>文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/profile/ title=了解我的个人信息和专业背景>关于我</a><button class="menu-item theme-switch tw-w-full" aria-label=切换主题>
<svg class="icon" viewBox="0 0 512 512"><path d="M8 256c0 136.966 111.033 248 248 248s248-111.034 248-248S392.966 8 256 8 8 119.033 8 256zm248 184V72c101.705.0 184 82.311 184 184 0 101.705-82.311 184-184 184z"/></svg></button></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class="tw-mx-4 tw-flex-1"><dialog id=toc-dialog class="tw-max-w-full tw-w-full tw-max-h-full tw-h-full tw-ml-16"><div class="toc tw-mx-4 tw-max-w-full"><h2 class="tw-mx-0 tw-my-6 tw-uppercase tw-text-2xl">目录</h2><div class=toc-content><nav id=TableOfContents><ul><li><a href=#0-速览30-秒>0. 速览（30 秒）</a></li><li><a href=#1-cpu-与-gpu差异场景与类比>1. CPU 与 GPU：差异、场景与类比</a><ul><li><a href=#11-一句话对比>1.1 一句话对比</a></li><li><a href=#12-形象类比>1.2 形象类比</a></li><li><a href=#13-可选-mermaid-图cpu-执行-vs-gpu-并行>1.3 可选 Mermaid 图（CPU 执行 vs GPU 并行）</a></li></ul></li><li><a href=#2-张量tensor精度与量化配例子>2. 张量（Tensor）、精度与量化（配例子）</a><ul><li><a href=#21-张量分级>2.1 张量分级</a></li><li><a href=#22-精度floating-point>2.2 精度（Floating Point）</a></li><li><a href=#23-量化integer>2.3 量化（Integer）</a></li></ul></li><li><a href=#3-cuda-与生态>3. CUDA 与生态</a></li><li><a href=#4-训练工作流从-0-到-1>4. 训练工作流（从 0 到 1）</a><ul><li><a href=#41-训练循环通用版>4.1 训练循环（通用版）</a></li><li><a href=#42-pytorch-最小闭环可直接粘贴>4.2 PyTorch 最小闭环（可直接粘贴）</a></li></ul></li><li><a href=#5-硬件选型与显存感知>5. 硬件选型与显存感知</a><ul><li><a href=#51-粗略显存直觉仅作量级参考>5.1 粗略显存直觉（仅作量级参考）</a></li><li><a href=#52-常见卡与场景示意>5.2 常见卡与场景（示意）</a></li></ul></li><li><a href=#6-面试常见问答可背要点>6. 面试常见问答（可背要点）</a></li><li><a href=#7-常见排错清单checklist>7. 常见排错清单（Checklist）</a></li><li><a href=#8-术语小词典面试快速解释>8. 术语小词典（面试快速解释）</a></li><li><a href=#9-附录简明示例与片段>9. 附录：简明示例与片段</a><ul><li><a href=#91-张量形状与上卡>9.1 张量形状与上卡</a></li><li><a href=#92-混合精度训练骨架>9.2 混合精度训练骨架</a></li><li><a href=#93-dataparallelddp-提示>9.3 DataParallel/DDP 提示</a></li></ul></li><li><a href=#10-一页总结可口号式记忆>10. 一页总结（可口号式记忆）</a></li><li><a href=#-延伸阅读>📚 延伸阅读</a><ul><li><a href=#-ai-大模型系统教程系列>🔗 AI 大模型系统教程系列</a></li><li><a href=#-实战建议>🎯 实战建议</a></li></ul></li></ul></nav></div></div></dialog><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC","false")</script><article class="page single print:!tw-w-full print:!tw-max-w-none print:!tw-m-0 print:!tw-p-0"><h1 class=single-title data-pagefind-meta=date:2025-11-06 data-pagefind-body>CPU/GPU 与大模型训练</h1><div class=post-meta><div class=post-meta-line><span class=post-author><img class="tw-inline-block tw-max-h-4 tw-rounded-full tw-translate-y-[-2px] tw-mr-1" src=/pictures/avatar/angryCat.png alt="Finn avatar" height=16 width=16><a href=https://blog.baifan.site title=Author target=_blank rel="noopener noreferrer author" class=author>Finn</a>
</span>&nbsp;<span class=post-category>收录于 </span>&nbsp;<span class=post-category>类别 <a href=/categories/ai%E6%8A%80%E6%9C%AF/><svg class="icon" viewBox="0 0 512 512"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49.0 112v288c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>AI技术</a></span>&nbsp;<span class=post-category>和</span>&nbsp;<span class=post-series>系列 <a href><svg class="icon" viewBox="0 0 512 512"><path d="M464 32H48C21.49 32 0 53.49.0 80v352c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V80c0-26.51-21.49-48-48-48zm-6 4e2H54a6 6 0 01-6-6V86a6 6 0 016-6h404a6 6 0 016 6v340a6 6 0 01-6 6zm-42-92v24c0 6.627-5.373 12-12 12H204c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h2e2c6.627.0 12 5.373 12 12zm0-96v24c0 6.627-5.373 12-12 12H204c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h2e2c6.627.0 12 5.373 12 12zm0-96v24c0 6.627-5.373 12-12 12H204c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h2e2c6.627.0 12 5.373 12 12zm-252 12c0 19.882-16.118 36-36 36s-36-16.118-36-36 16.118-36 36-36 36 16.118 36 36zm0 96c0 19.882-16.118 36-36 36s-36-16.118-36-36 16.118-36 36-36 36 16.118 36 36zm0 96c0 19.882-16.118 36-36 36s-36-16.118-36-36 16.118-36 36-36 36 16.118 36 36z"/></svg></a></span></div><div class=post-meta-line><svg class="icon" viewBox="0 0 448 512"><path d="M148 288h-40c-6.6.0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h48c26.5.0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3.0 6-2.7 6-6z"/></svg>&nbsp;<time datetime=2025-11-06>2025-11-06</time>&nbsp;<svg class="icon" viewBox="0 0 576 512"><path d="M402.3 344.9l32-32c5-5 13.7-1.5 13.7 5.7V464c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h273.5c7.1.0 10.7 8.6 5.7 13.7l-32 32c-1.5 1.5-3.5 2.3-5.7 2.3H48v352h352V350.5c0-2.1.8-4.1 2.3-5.6zm156.6-201.8L296.3 405.7l-90.4 10c-26.2 2.9-48.5-19.2-45.6-45.6l10-90.4L432.9 17.1c22.9-22.9 59.9-22.9 82.7.0l43.2 43.2c22.9 22.9 22.9 60 .1 82.8zM460.1 174 402 115.9 216.2 301.8l-7.3 65.3 65.3-7.3L460.1 174zm64.8-79.7-43.2-43.2c-4.1-4.1-10.8-4.1-14.8.0L436 82l58.1 58.1 30.9-30.9c4-4.2 4-10.8-.1-14.9z"/></svg>&nbsp;<time datetime=2025-11-06>2025-11-06</time>&nbsp;<svg class="icon" viewBox="0 0 512 512"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3.0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9.0l60.1 60.1c18.8 18.7 18.8 49.1.0 67.9zM284.2 99.8 21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3.0-17l-111-111c-4.8-4.7-12.4-4.7-17.1.0zM124.1 339.9c-5.5-5.5-5.5-14.3.0-19.8l154-154c5.5-5.5 14.3-5.5 19.8.0s5.5 14.3.0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8.0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg>&nbsp;约 3592 字&nbsp;
<svg class="icon" viewBox="0 0 512 512"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5.0-2e2-89.5-2e2-2e2S145.5 56 256 56s2e2 89.5 2e2 2e2-89.5 2e2-2e2 2e2zm61.8-104.4-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6.0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"/></svg>&nbsp;预计阅读 16 分钟&nbsp;</div></div><div class="details toc print:!tw-block" id=toc-static kept=true><div class="details-summary toc-title"><span>目录</span>
<span class=details-icon><svg class="icon" viewBox="0 0 256 512"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9.0l-22.6-22.6c-9.4-9.4-9.4-24.6.0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6.0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9.0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#0-速览30-秒>0. 速览（30 秒）</a></li><li><a href=#1-cpu-与-gpu差异场景与类比>1. CPU 与 GPU：差异、场景与类比</a><ul><li><a href=#11-一句话对比>1.1 一句话对比</a></li><li><a href=#12-形象类比>1.2 形象类比</a></li><li><a href=#13-可选-mermaid-图cpu-执行-vs-gpu-并行>1.3 可选 Mermaid 图（CPU 执行 vs GPU 并行）</a></li></ul></li><li><a href=#2-张量tensor精度与量化配例子>2. 张量（Tensor）、精度与量化（配例子）</a><ul><li><a href=#21-张量分级>2.1 张量分级</a></li><li><a href=#22-精度floating-point>2.2 精度（Floating Point）</a></li><li><a href=#23-量化integer>2.3 量化（Integer）</a></li></ul></li><li><a href=#3-cuda-与生态>3. CUDA 与生态</a></li><li><a href=#4-训练工作流从-0-到-1>4. 训练工作流（从 0 到 1）</a><ul><li><a href=#41-训练循环通用版>4.1 训练循环（通用版）</a></li><li><a href=#42-pytorch-最小闭环可直接粘贴>4.2 PyTorch 最小闭环（可直接粘贴）</a></li></ul></li><li><a href=#5-硬件选型与显存感知>5. 硬件选型与显存感知</a><ul><li><a href=#51-粗略显存直觉仅作量级参考>5.1 粗略显存直觉（仅作量级参考）</a></li><li><a href=#52-常见卡与场景示意>5.2 常见卡与场景（示意）</a></li></ul></li><li><a href=#6-面试常见问答可背要点>6. 面试常见问答（可背要点）</a></li><li><a href=#7-常见排错清单checklist>7. 常见排错清单（Checklist）</a></li><li><a href=#8-术语小词典面试快速解释>8. 术语小词典（面试快速解释）</a></li><li><a href=#9-附录简明示例与片段>9. 附录：简明示例与片段</a><ul><li><a href=#91-张量形状与上卡>9.1 张量形状与上卡</a></li><li><a href=#92-混合精度训练骨架>9.2 混合精度训练骨架</a></li><li><a href=#93-dataparallelddp-提示>9.3 DataParallel/DDP 提示</a></li></ul></li><li><a href=#10-一页总结可口号式记忆>10. 一页总结（可口号式记忆）</a></li><li><a href=#-延伸阅读>📚 延伸阅读</a><ul><li><a href=#-ai-大模型系统教程系列>🔗 AI 大模型系统教程系列</a></li><li><a href=#-实战建议>🎯 实战建议</a></li></ul></li></ul></nav></div></div><div class=content id=content data-pagefind-body><h1 id=ai-教程-cpugpu-与大模型训练 class=headerLink><a href=#ai-%e6%95%99%e7%a8%8b-cpugpu-%e4%b8%8e%e5%a4%a7%e6%a8%a1%e5%9e%8b%e8%ae%ad%e7%bb%83 class=header-mark></a>AI 教程: CPU/GPU 与大模型训练</h1><blockquote><p>这是一份高浓缩资料：结构清晰、要点到位，涵盖 CPU/GPU 基础、张量与数值精度、CUDA 与 PyTorch 实操、硬件选型、常见问答与排错清单。</p></blockquote><hr><h2 id=0-速览30-秒 class=headerLink><a href=#0-%e9%80%9f%e8%a7%8830-%e7%a7%92 class=header-mark></a>0. 速览（30 秒）</h2><ul><li><strong>CPU vs GPU</strong>：CPU 擅长<strong>通用/顺序</strong>处理；GPU 擅长<strong>大规模并行</strong>（矩阵/向量）。</li><li><strong>大模型必备 GPU</strong>：训练/推理核心是矩阵乘和并行化，GPU 的高并发 + 高带宽显存恰好匹配。</li><li><strong>张量与精度</strong>：一切数据 → 张量；精度（FP16/FP8）与<strong>量化</strong>（INT8/INT4）是速度/显存与效果之间的权衡。</li><li><strong>PyTorch 上卡口诀</strong>：<code>device = "cuda" if ...; model.to(device); data.to(device)</code></li><li><strong>选卡看显存</strong>：先显存，再带宽/算力；生产尽量用<strong>满血高质量模型</strong>或云端托管 API。</li></ul><hr><h2 id=1-cpu-与-gpu差异场景与类比 class=headerLink><a href=#1-cpu-%e4%b8%8e-gpu%e5%b7%ae%e5%bc%82%e5%9c%ba%e6%99%af%e4%b8%8e%e7%b1%bb%e6%af%94 class=header-mark></a>1. CPU 与 GPU：差异、场景与类比</h2><h3 id=11-一句话对比 class=headerLink><a href=#11-%e4%b8%80%e5%8f%a5%e8%af%9d%e5%af%b9%e6%af%94 class=header-mark></a>1.1 一句话对比</h3><div class=table-wrapper><table><thead><tr><th style=text-align:>维度</th><th style=text-align:>CPU</th><th style=text-align:>GPU</th></tr></thead><tbody><tr><td style=text-align:>架构</td><td style=text-align:>少核、复杂控制流</td><td style=text-align:>海量小核、SIMT 并行</td></tr><tr><td style=text-align:>擅长</td><td style=text-align:>分支/系统任务/小规模计算</td><td style=text-align:>矩阵乘、卷积、注意力、图形渲染</td></tr><tr><td style=text-align:>任务模型</td><td style=text-align:>时间片轮转、低延迟切换</td><td style=text-align:>批处理&吞吐导向</td></tr><tr><td style=text-align:>典型用法</td><td style=text-align:>业务逻辑、调度、I/O</td><td style=text-align:>训练/推理主算子（GEMM、Conv 等）</td></tr></tbody></table></div><h3 id=12-形象类比 class=headerLink><a href=#12-%e5%bd%a2%e8%b1%a1%e7%b1%bb%e6%af%94 class=header-mark></a>1.2 形象类比</h3><ul><li><strong>CPU = 老专家</strong>：思考缜密、一次做一件事快切换。</li><li><strong>GPU = 千军万马</strong>：海量士兵同时干活，适合“<strong>同构小任务</strong>”的并行。</li></ul><h3 id=13-可选-mermaid-图cpu-执行-vs-gpu-并行 class=headerLink><a href=#13-%e5%8f%af%e9%80%89-mermaid-%e5%9b%becpu-%e6%89%a7%e8%a1%8c-vs-gpu-%e5%b9%b6%e8%a1%8c class=header-mark></a>1.3 可选 Mermaid 图（CPU 执行 vs GPU 并行）</h3><pre class=mermaid>flowchart LR
    subgraph CPU["CPU（顺序/少核）"]
      A1[任务1-片段A] --> A2[任务2-片段B] --> A3[任务3-片段C]
    end
    subgraph GPU["GPU（并行/多核）"]
      B1[元素1计算]:::p
      B2[元素2计算]:::p
      B3[元素3计算]:::p
      B4[元素4计算]:::p
    end
    classDef p fill:#e9f5ff,stroke:#3b82f6,stroke-width:1px;
</pre><hr><h2 id=2-张量tensor精度与量化配例子 class=headerLink><a href=#2-%e5%bc%a0%e9%87%8ftensor%e7%b2%be%e5%ba%a6%e4%b8%8e%e9%87%8f%e5%8c%96%e9%85%8d%e4%be%8b%e5%ad%90 class=header-mark></a>2. 张量（Tensor）、精度与量化（配例子）</h2><h3 id=21-张量分级 class=headerLink><a href=#21-%e5%bc%a0%e9%87%8f%e5%88%86%e7%ba%a7 class=header-mark></a>2.1 张量分级</h3><ul><li><strong>0D</strong>：标量 <code>3.14</code></li><li><strong>1D</strong>：向量 <code>[1,2,3]</code></li><li><strong>2D</strong>：矩阵（如 3×3 表）</li><li><strong>3D+</strong>：仍称张量（如 <code>batch×channel×height×width</code>）</li></ul><p><strong>图像例子</strong>：一批 32 张 224×224 RGB 图 → <code>32×3×224×224</code>（或 <code>N×H×W×C</code>，视框架而定）。</p><h3 id=22-精度floating-point class=headerLink><a href=#22-%e7%b2%be%e5%ba%a6floating-point class=header-mark></a>2.2 精度（Floating Point）</h3><ul><li><strong>FP32/FP16/FP8…</strong>：位宽越小 → <strong>显存更省、吞吐更高</strong>，但<strong>数值稳定性/精度</strong>下降。</li><li><strong>累计误差类比</strong>：按“1 元/秒” vs “1.1 元/秒”计薪，一个月累计差可能<strong>上万</strong>（长链路累积误差效应）。</li></ul><h3 id=23-量化integer class=headerLink><a href=#23-%e9%87%8f%e5%8c%96integer class=header-mark></a>2.3 量化（Integer）</h3><ul><li>把浮点权重/激活用更短整数（<strong>INT8/INT4</strong>）近似，<strong>显存/带宽显著降低</strong>。</li><li><strong>代价</strong>：生成质量/可对齐性下降（INT4 节省最多，质量下滑也更明显）。</li><li><strong>面试提示</strong>：回答量化时要<strong>分开</strong>谈权重量化、激活量化、PTQ（训练后量化）与 QAT（量化感知训练）。</li></ul><hr><h2 id=3-cuda-与生态 class=headerLink><a href=#3-cuda-%e4%b8%8e%e7%94%9f%e6%80%81 class=header-mark></a>3. CUDA 与生态</h2><ul><li><strong>CUDA</strong>（读“库达”）：NVIDIA 的并行计算平台/编程模型，深度学习框架通过 CUDA 使用 GPU。</li><li><strong>框架</strong>：PyTorch、TensorFlow、JAX、ONNX Runtime、TensorRT（推理优化）等。</li><li><strong>设备抽象</strong>：高层 API 屏蔽很多复杂度，<strong>核心就是把数据与模型迁移到“cuda”设备</strong>。</li></ul><hr><h2 id=4-训练工作流从-0-到-1 class=headerLink><a href=#4-%e8%ae%ad%e7%bb%83%e5%b7%a5%e4%bd%9c%e6%b5%81%e4%bb%8e-0-%e5%88%b0-1 class=header-mark></a>4. 训练工作流（从 0 到 1）</h2><h3 id=41-训练循环通用版 class=headerLink><a href=#41-%e8%ae%ad%e7%bb%83%e5%be%aa%e7%8e%af%e9%80%9a%e7%94%a8%e7%89%88 class=header-mark></a>4.1 训练循环（通用版）</h3><pre class=mermaid>flowchart TD
  A[准备数据 X,y] --> B[建模 nn.Module]
  B --> C[选择设备 device]
  C --> D[迁移 model/data 到 device]
  D --> E[前向计算 y_hat = model(X)]
  E --> F[计算损失 Loss(y_hat, y)]
  F --> G[反传 loss.backward()]
  G --> H[优化器更新 optimizer.step()]
  H --> I{终止条件?}
  I -- 否 --> D
  I -- 是 --> J[评估与保存]
</pre><h3 id=42-pytorch-最小闭环可直接粘贴 class=headerLink><a href=#42-pytorch-%e6%9c%80%e5%b0%8f%e9%97%ad%e7%8e%af%e5%8f%af%e7%9b%b4%e6%8e%a5%e7%b2%98%e8%b4%b4 class=header-mark></a>4.2 PyTorch 最小闭环（可直接粘贴）</h3><div class="code-block highlight is-closed show-line-numbers tw-group tw-my-2"><div class="tw-flex
tw-flex-row
tw-flex-1
tw-justify-between
tw-w-full tw-bg-bgColor-secondary"><button class="code-block-button
tw-mx-2
tw-flex
tw-flex-row
tw-flex-1" aria-hidden=true><div class="group-[.is-open]:tw-rotate-90 tw-transition-[transform] tw-duration-500 tw-ease-in-out print:!tw-hidden tw-w-min tw-h-min tw-my-1 tw-mx-1"><svg class="icon" viewBox="0 0 320 512"><path d="M285.476 272.971 91.132 467.314c-9.373 9.373-24.569 9.373-33.941.0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941.0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z"/></svg></div><p class="tw-select-none !tw-my-1">python</p></button><div class=tw-flex><button class="line-number-button
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
group-[.show-line-numbers]:tw-text-fgColor-link
print:!tw-hidden" title="Toggle line numbers"><svg class="icon" viewBox="0 0 512 512"><path d="M61.77 401l17.5-20.15a19.92 19.92.0 005.07-14.19v-3.31C84.34 356 80.5 352 73 352H16a8 8 0 00-8 8v16a8 8 0 008 8h22.83a157.41 157.41.0 00-11 12.31l-5.61 7c-4 5.07-5.25 10.13-2.8 14.88l1.05 1.93c3 5.76 6.29 7.88 12.25 7.88h4.73c10.33.0 15.94 2.44 15.94 9.09.0 4.72-4.2 8.22-14.36 8.22a41.54 41.54.0 01-15.47-3.12c-6.49-3.88-11.74-3.5-15.6 3.12l-5.59 9.31c-3.72 6.13-3.19 11.72 2.63 15.94 7.71 4.69 20.38 9.44 37 9.44 34.16.0 48.5-22.75 48.5-44.12-.03-14.38-9.12-29.76-28.73-34.88zM496 224H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16v-32a16 16 0 00-16-16zm0-160H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16V80a16 16 0 00-16-16zm0 320H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16v-32a16 16 0 00-16-16zM16 160h64a8 8 0 008-8v-16a8 8 0 00-8-8H64V40a8 8 0 00-8-8H32a8 8 0 00-7.14 4.42l-8 16A8 8 0 0024 64h8v64H16a8 8 0 00-8 8v16a8 8 0 008 8zm-3.91 160H80a8 8 0 008-8v-16a8 8 0 00-8-8H41.32c3.29-10.29 48.34-18.68 48.34-56.44.0-29.06-25-39.56-44.47-39.56-21.36.0-33.8 10-40.46 18.75-4.37 5.59-3 10.84 2.8 15.37l8.58 6.88c5.61 4.56 11 2.47 16.12-2.44a13.44 13.44.0 019.46-3.84c3.33.0 9.28 1.56 9.28 8.75C51 248.19.0 257.31.0 304.59v4C0 316 5.08 320 12.09 320z"/></svg></button>
<button class="wrap-code-button
tw-select-none
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
group-[.is-wrap]:tw-text-fgColor-link
print:!tw-hidden" title="Toggle code wrap"><svg class="icon" viewBox="0 0 448 512"><path d="M16 132h416c8.837.0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163.0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"/></svg></button>
<button class="copy-code-button
tw-select-none
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
hover:tw-text-fgColor-link
print:!tw-hidden" title="Copy code">
<span class="copy-icon tw-block"><svg class="icon" viewBox="0 0 448 512"><path d="M433.941 65.941l-51.882-51.882A48 48 0 00348.118.0H176c-26.51.0-48 21.49-48 48v48H48c-26.51.0-48 21.49-48 48v320c0 26.51 21.49 48 48 48h224c26.51.0 48-21.49 48-48v-48h80c26.51.0 48-21.49 48-48V99.882a48 48 0 00-14.059-33.941zM266 464H54a6 6 0 01-6-6V150a6 6 0 016-6h74v224c0 26.51 21.49 48 48 48h96v42a6 6 0 01-6 6zm128-96H182a6 6 0 01-6-6V54a6 6 0 016-6h106v88c0 13.255 10.745 24 24 24h88v202a6 6 0 01-6 6zm6-256h-64V48h9.632c1.591.0 3.117.632 4.243 1.757l48.368 48.368a6 6 0 011.757 4.243V112z"/></svg></span>
<span class="check-icon tw-hidden"><svg class="icon" viewBox="0 0 512 512"><path d="M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206.0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204.0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204.0l36.203 36.204c9.997 9.997 9.997 26.206.0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z"/></svg></span>
</button>
<button class="tw-select-none
tw-mx-2
tw-block
group-[.is-open]:tw-hidden
print:!tw-hidden" disabled aria-hidden=true><svg class="icon" viewBox="0 0 512 512"><path d="M328 256c0 39.8-32.2 72-72 72s-72-32.2-72-72 32.2-72 72-72 72 32.2 72 72zm104-72c-39.8.0-72 32.2-72 72s32.2 72 72 72 72-32.2 72-72-32.2-72-72-72zm-352 0c-39.8.0-72 32.2-72 72s32.2 72 72 72 72-32.2 72-72-32.2-72-72-72z"/></svg></button></div></div><pre style=counter-reset:codeblock class="tw-block tw-m-0 tw-p-0"><code id=codeblock-id-1 class="chroma
!tw-block
tw-p-0
tw-m-0
tw-transition-[max-height]
tw-duration-500
tw-ease-in-out
group-[.is-closed]:!tw-max-h-0
group-[.is-wrap]:tw-text-wrap
tw-overflow-y-hidden
tw-overflow-x-auto
tw-scrollbar-thin"><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1) 设备</span>
</span></span><span class=line><span class=cl><span class=n>device</span> <span class=o>=</span> <span class=s2>&#34;cuda&#34;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&#34;cpu&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2) 假数据：y = 2.0*x - 3.0 + noise</span>
</span></span><span class=line><span class=cl><span class=n>N</span> <span class=o>=</span> <span class=mi>100_000</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>y</span> <span class=o>=</span> <span class=mf>2.0</span> <span class=o>*</span> <span class=n>X</span> <span class=o>-</span> <span class=mf>3.0</span> <span class=o>+</span> <span class=mf>0.1</span> <span class=o>*</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>y</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3) 模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4) 优化与损失</span>
</span></span><span class=line><span class=cl><span class=n>opt</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>1e-2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>loss_fn</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MSELoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 5) 训练</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>200</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>opt</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>y_hat</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span> <span class=o>=</span> <span class=n>loss_fn</span><span class=p>(</span><span class=n>y_hat</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>opt</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>epoch</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=mi>50</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;epoch </span><span class=si>{</span><span class=n>epoch</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2>: loss=</span><span class=si>{</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 6) 保存</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span> <span class=s2>&#34;linear.pth&#34;</span><span class=p>)</span></span></span></code></pre></div><blockquote><p>口令：<strong>模型与数据都要 <code>.to(device)</code></strong>；多卡并行看 <code>DistributedDataParallel</code>（生产优先）或 <code>DataParallel</code>（入门/演示）。</p></blockquote><hr><h2 id=5-硬件选型与显存感知 class=headerLink><a href=#5-%e7%a1%ac%e4%bb%b6%e9%80%89%e5%9e%8b%e4%b8%8e%e6%98%be%e5%ad%98%e6%84%9f%e7%9f%a5 class=header-mark></a>5. 硬件选型与显存感知</h2><blockquote><p>面试时“会估”很加分：先问<strong>模型大小/精度/序列长度/并发</strong>，再给建议。</p></blockquote><h3 id=51-粗略显存直觉仅作量级参考 class=headerLink><a href=#51-%e7%b2%97%e7%95%a5%e6%98%be%e5%ad%98%e7%9b%b4%e8%a7%89%e4%bb%85%e4%bd%9c%e9%87%8f%e7%ba%a7%e5%8f%82%e8%80%83 class=header-mark></a>5.1 粗略显存直觉（仅作量级参考）</h3><div class=table-wrapper><table><thead><tr><th style=text-align:>模型规模</th><th style=text-align:right>FP16 估计</th><th style=text-align:right>INT8 估计</th><th style=text-align:right>INT4 估计</th><th style=text-align:>备注</th></tr></thead><tbody><tr><td style=text-align:>7B</td><td style=text-align:right>~14–16 GB</td><td style=text-align:right>~8–10 GB</td><td style=text-align:right>~5–6 GB</td><td style=text-align:>仅权重，不含 KV Cache/激活峰值</td></tr><tr><td style=text-align:>13B</td><td style=text-align:right>~26–28 GB</td><td style=text-align:right>~14–16 GB</td><td style=text-align:right>~8–10 GB</td><td style=text-align:>实占依实现差异很大</td></tr><tr><td style=text-align:>70B</td><td style=text-align:right>需要多卡/数据中心卡</td><td style=text-align:right>量化+牺牲并发</td><td style=text-align:right>量化+更强约束</td><td style=text-align:>常见为 A100/H100 或多卡集群</td></tr></tbody></table></div><blockquote><p><strong>KV Cache/序列长度/批量并发</strong> 会显著抬高占用：面试时要主动声明这一点。</p></blockquote><h3 id=52-常见卡与场景示意 class=headerLink><a href=#52-%e5%b8%b8%e8%a7%81%e5%8d%a1%e4%b8%8e%e5%9c%ba%e6%99%af%e7%a4%ba%e6%84%8f class=header-mark></a>5.2 常见卡与场景（示意）</h3><div class=table-wrapper><table><thead><tr><th style=text-align:>场景</th><th style=text-align:>建议</th></tr></thead><tbody><tr><td style=text-align:>学习/小实验</td><td style=text-align:>RTX 3090/4090（24GB），Colab/云上临时卡</td></tr><tr><td style=text-align:>7B–13B 推理/轻微调</td><td style=text-align:>24GB 卡 + 量化/LoRA；或小型云实例</td></tr><tr><td style=text-align:>30B+ / 70B+</td><td style=text-align:>A100/H100 等数据中心卡或多卡；生产优先云托管 API</td></tr></tbody></table></div><blockquote><p>原则：<strong>生产尽量用满血高质量模型（云 API/托管服务）</strong>，避免把强量化小模型硬塞到本地承担严肃质量目标。</p></blockquote><hr><h2 id=6-面试常见问答可背要点 class=headerLink><a href=#6-%e9%9d%a2%e8%af%95%e5%b8%b8%e8%a7%81%e9%97%ae%e7%ad%94%e5%8f%af%e8%83%8c%e8%a6%81%e7%82%b9 class=header-mark></a>6. 面试常见问答（可背要点）</h2><ol><li><p><strong>为什么 GPU 比 CPU 适合训练？</strong>
因为训练/推理核心是矩阵/向量批运算（GEMM/Attention），GPU 的海量并行核与高带宽显存能显著提升吞吐与能效。</p></li><li><p><strong>张量是什么？</strong>
多维数组的统称：标量 → 向量 → 矩阵 → 更高维（图像/语音/文本 embedding 最终都映射为张量）。</p></li><li><p><strong>FP16 与 INT8 的差别？</strong>
FP16 属于浮点降精；INT8 是整数量化。INT8 更省资源但更容易带来可感知质量下降；FP16 在速度/效果间更平衡。</p></li><li><p><strong>PTQ vs QAT？</strong>
PTQ：训练后量化，成本低；QAT：在训练中模拟量化，效果更好、成本更高。</p></li><li><p><strong>如何让代码“用上 GPU”？</strong>
检测设备、<code>model.to(device)</code>、<code>tensor.to(device)</code>；多卡优先 <code>DistributedDataParallel</code>；警惕<strong>显存转移/类型不一致</strong>导致的隐性回退。</p></li><li><p><strong>为什么评估要用测试集？</strong>
防止过拟合/数据泄漏；训练集表现不代表泛化能力。</p></li><li><p><strong>量化后效果下降如何缓解？</strong>
QAT、混合精度（关键层高精度）、校准高代表性数据、感知度高任务（长文案/代码）谨慎使用低位量化。</p></li><li><p><strong>本地部署 vs 云端 API？</strong>
本地可控性与成本可见，但硬件/维护重；云端<strong>弹性/稳定/上线快</strong>且能用到<strong>更强模型</strong>，生产优先。</p></li><li><p><strong>Mac（Apple Silicon）如何加速？</strong>
用 <code>mps</code> 后端（Metal）；生态/性能与 CUDA 有差异，复杂训练建议仍用 NVIDIA GPU 或云端。</p></li><li><p><strong>显存不够还能做什么？</strong>
量化、LoRA/QLoRA、梯度检查点、张量并行/流水线并行、减少序列长度/批量/并发、KV Cache 复用与卸载策略。</p></li></ol><hr><h2 id=7-常见排错清单checklist class=headerLink><a href=#7-%e5%b8%b8%e8%a7%81%e6%8e%92%e9%94%99%e6%b8%85%e5%8d%95checklist class=header-mark></a>7. 常见排错清单（Checklist）</h2><ul><li><strong>设备不一致</strong>：确认 <code>model</code>、<code>inputs</code>、<code>labels</code> <strong>都在同一 device</strong>。</li><li><strong>精度/类型错配</strong>：<code>float16</code> vs <code>float32</code>、<code>long</code> vs <code>float</code>；启用 AMP（自动混合精度）时关注溢出/NaN。</li><li><strong>显存 OOM</strong>：减 batch/seq len、开梯度检查点、量化、分布式并行切片。</li><li><strong>数据瓶颈</strong>：DataLoader <code>num_workers/pin_memory</code>、预处理并行、I/O 排队。</li><li><strong>多卡“只用一张”</strong>：是否真的走了 <code>DDP</code>，环境变量、初始化方法、NCCL 配置是否正确。</li><li><strong>评估偏差</strong>：确保严格的训练/验证/测试划分，避免数据泄漏。</li></ul><hr><h2 id=8-术语小词典面试快速解释 class=headerLink><a href=#8-%e6%9c%af%e8%af%ad%e5%b0%8f%e8%af%8d%e5%85%b8%e9%9d%a2%e8%af%95%e5%bf%ab%e9%80%9f%e8%a7%a3%e9%87%8a class=header-mark></a>8. 术语小词典（面试快速解释）</h2><ul><li><strong>Tensor</strong>：多维数组；0D 标量、1D 向量、2D 矩阵、3D+ 张量。</li><li><strong>FP16/FP8</strong>：浮点降精，速度快/显存省；稳定性需关注。</li><li><strong>INT8/INT4</strong>：整数量化，更省但质量更敏感。</li><li><strong>PTQ/QAT</strong>：训练后量化 / 量化感知训练。</li><li><strong>AMP</strong>：自动混合精度（如 PyTorch autocast + GradScaler）。</li><li><strong>KV Cache</strong>：注意力缓存，加速生成但占显存。</li><li><strong>DDP</strong>：分布式数据并行（生产首选）。</li><li><strong>TensorRT</strong>：NVIDIA 推理优化工具链。</li><li><strong>LoRA/QLoRA</strong>：低秩适配（/结合量化），小显存微调利器。</li></ul><hr><h2 id=9-附录简明示例与片段 class=headerLink><a href=#9-%e9%99%84%e5%bd%95%e7%ae%80%e6%98%8e%e7%a4%ba%e4%be%8b%e4%b8%8e%e7%89%87%e6%ae%b5 class=header-mark></a>9. 附录：简明示例与片段</h2><h3 id=91-张量形状与上卡 class=headerLink><a href=#91-%e5%bc%a0%e9%87%8f%e5%bd%a2%e7%8a%b6%e4%b8%8e%e4%b8%8a%e5%8d%a1 class=header-mark></a>9.1 张量形状与上卡</h3><div class="code-block highlight is-open show-line-numbers tw-group tw-my-2"><div class="tw-flex
tw-flex-row
tw-flex-1
tw-justify-between
tw-w-full tw-bg-bgColor-secondary"><button class="code-block-button
tw-mx-2
tw-flex
tw-flex-row
tw-flex-1" aria-hidden=true><div class="group-[.is-open]:tw-rotate-90 tw-transition-[transform] tw-duration-500 tw-ease-in-out print:!tw-hidden tw-w-min tw-h-min tw-my-1 tw-mx-1"><svg class="icon" viewBox="0 0 320 512"><path d="M285.476 272.971 91.132 467.314c-9.373 9.373-24.569 9.373-33.941.0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941.0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z"/></svg></div><p class="tw-select-none !tw-my-1">python</p></button><div class=tw-flex><button class="line-number-button
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
group-[.show-line-numbers]:tw-text-fgColor-link
print:!tw-hidden" title="Toggle line numbers"><svg class="icon" viewBox="0 0 512 512"><path d="M61.77 401l17.5-20.15a19.92 19.92.0 005.07-14.19v-3.31C84.34 356 80.5 352 73 352H16a8 8 0 00-8 8v16a8 8 0 008 8h22.83a157.41 157.41.0 00-11 12.31l-5.61 7c-4 5.07-5.25 10.13-2.8 14.88l1.05 1.93c3 5.76 6.29 7.88 12.25 7.88h4.73c10.33.0 15.94 2.44 15.94 9.09.0 4.72-4.2 8.22-14.36 8.22a41.54 41.54.0 01-15.47-3.12c-6.49-3.88-11.74-3.5-15.6 3.12l-5.59 9.31c-3.72 6.13-3.19 11.72 2.63 15.94 7.71 4.69 20.38 9.44 37 9.44 34.16.0 48.5-22.75 48.5-44.12-.03-14.38-9.12-29.76-28.73-34.88zM496 224H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16v-32a16 16 0 00-16-16zm0-160H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16V80a16 16 0 00-16-16zm0 320H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16v-32a16 16 0 00-16-16zM16 160h64a8 8 0 008-8v-16a8 8 0 00-8-8H64V40a8 8 0 00-8-8H32a8 8 0 00-7.14 4.42l-8 16A8 8 0 0024 64h8v64H16a8 8 0 00-8 8v16a8 8 0 008 8zm-3.91 160H80a8 8 0 008-8v-16a8 8 0 00-8-8H41.32c3.29-10.29 48.34-18.68 48.34-56.44.0-29.06-25-39.56-44.47-39.56-21.36.0-33.8 10-40.46 18.75-4.37 5.59-3 10.84 2.8 15.37l8.58 6.88c5.61 4.56 11 2.47 16.12-2.44a13.44 13.44.0 019.46-3.84c3.33.0 9.28 1.56 9.28 8.75C51 248.19.0 257.31.0 304.59v4C0 316 5.08 320 12.09 320z"/></svg></button>
<button class="wrap-code-button
tw-select-none
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
group-[.is-wrap]:tw-text-fgColor-link
print:!tw-hidden" title="Toggle code wrap"><svg class="icon" viewBox="0 0 448 512"><path d="M16 132h416c8.837.0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163.0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"/></svg></button>
<button class="copy-code-button
tw-select-none
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
hover:tw-text-fgColor-link
print:!tw-hidden" title="Copy code">
<span class="copy-icon tw-block"><svg class="icon" viewBox="0 0 448 512"><path d="M433.941 65.941l-51.882-51.882A48 48 0 00348.118.0H176c-26.51.0-48 21.49-48 48v48H48c-26.51.0-48 21.49-48 48v320c0 26.51 21.49 48 48 48h224c26.51.0 48-21.49 48-48v-48h80c26.51.0 48-21.49 48-48V99.882a48 48 0 00-14.059-33.941zM266 464H54a6 6 0 01-6-6V150a6 6 0 016-6h74v224c0 26.51 21.49 48 48 48h96v42a6 6 0 01-6 6zm128-96H182a6 6 0 01-6-6V54a6 6 0 016-6h106v88c0 13.255 10.745 24 24 24h88v202a6 6 0 01-6 6zm6-256h-64V48h9.632c1.591.0 3.117.632 4.243 1.757l48.368 48.368a6 6 0 011.757 4.243V112z"/></svg></span>
<span class="check-icon tw-hidden"><svg class="icon" viewBox="0 0 512 512"><path d="M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206.0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204.0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204.0l36.203 36.204c9.997 9.997 9.997 26.206.0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z"/></svg></span>
</button>
<button class="tw-select-none
tw-mx-2
tw-block
group-[.is-open]:tw-hidden
print:!tw-hidden" disabled aria-hidden=true><svg class="icon" viewBox="0 0 512 512"><path d="M328 256c0 39.8-32.2 72-72 72s-72-32.2-72-72 32.2-72 72-72 72 32.2 72 72zm104-72c-39.8.0-72 32.2-72 72s32.2 72 72 72 72-32.2 72-72-32.2-72-72-72zm-352 0c-39.8.0-72 32.2-72 72s32.2 72 72 72 72-32.2 72-72-32.2-72-72-72z"/></svg></button></div></div><pre style=counter-reset:codeblock class="tw-block tw-m-0 tw-p-0"><code id=codeblock-id-2 class="chroma
!tw-block
tw-p-0
tw-m-0
tw-transition-[max-height]
tw-duration-500
tw-ease-in-out
group-[.is-closed]:!tw-max-h-0
group-[.is-wrap]:tw-text-wrap
tw-overflow-y-hidden
tw-overflow-x-auto
tw-scrollbar-thin"><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>)</span>     <span class=c1># NCHW</span>
</span></span><span class=line><span class=cl><span class=n>device</span> <span class=o>=</span> <span class=s2>&#34;cuda&#34;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&#34;cpu&#34;</span>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span></span></span></code></pre></div><h3 id=92-混合精度训练骨架 class=headerLink><a href=#92-%e6%b7%b7%e5%90%88%e7%b2%be%e5%ba%a6%e8%ae%ad%e7%bb%83%e9%aa%a8%e6%9e%b6 class=header-mark></a>9.2 混合精度训练骨架</h3><div class="code-block highlight is-open show-line-numbers tw-group tw-my-2"><div class="tw-flex
tw-flex-row
tw-flex-1
tw-justify-between
tw-w-full tw-bg-bgColor-secondary"><button class="code-block-button
tw-mx-2
tw-flex
tw-flex-row
tw-flex-1" aria-hidden=true><div class="group-[.is-open]:tw-rotate-90 tw-transition-[transform] tw-duration-500 tw-ease-in-out print:!tw-hidden tw-w-min tw-h-min tw-my-1 tw-mx-1"><svg class="icon" viewBox="0 0 320 512"><path d="M285.476 272.971 91.132 467.314c-9.373 9.373-24.569 9.373-33.941.0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941.0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z"/></svg></div><p class="tw-select-none !tw-my-1">python</p></button><div class=tw-flex><button class="line-number-button
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
group-[.show-line-numbers]:tw-text-fgColor-link
print:!tw-hidden" title="Toggle line numbers"><svg class="icon" viewBox="0 0 512 512"><path d="M61.77 401l17.5-20.15a19.92 19.92.0 005.07-14.19v-3.31C84.34 356 80.5 352 73 352H16a8 8 0 00-8 8v16a8 8 0 008 8h22.83a157.41 157.41.0 00-11 12.31l-5.61 7c-4 5.07-5.25 10.13-2.8 14.88l1.05 1.93c3 5.76 6.29 7.88 12.25 7.88h4.73c10.33.0 15.94 2.44 15.94 9.09.0 4.72-4.2 8.22-14.36 8.22a41.54 41.54.0 01-15.47-3.12c-6.49-3.88-11.74-3.5-15.6 3.12l-5.59 9.31c-3.72 6.13-3.19 11.72 2.63 15.94 7.71 4.69 20.38 9.44 37 9.44 34.16.0 48.5-22.75 48.5-44.12-.03-14.38-9.12-29.76-28.73-34.88zM496 224H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16v-32a16 16 0 00-16-16zm0-160H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16V80a16 16 0 00-16-16zm0 320H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16v-32a16 16 0 00-16-16zM16 160h64a8 8 0 008-8v-16a8 8 0 00-8-8H64V40a8 8 0 00-8-8H32a8 8 0 00-7.14 4.42l-8 16A8 8 0 0024 64h8v64H16a8 8 0 00-8 8v16a8 8 0 008 8zm-3.91 160H80a8 8 0 008-8v-16a8 8 0 00-8-8H41.32c3.29-10.29 48.34-18.68 48.34-56.44.0-29.06-25-39.56-44.47-39.56-21.36.0-33.8 10-40.46 18.75-4.37 5.59-3 10.84 2.8 15.37l8.58 6.88c5.61 4.56 11 2.47 16.12-2.44a13.44 13.44.0 019.46-3.84c3.33.0 9.28 1.56 9.28 8.75C51 248.19.0 257.31.0 304.59v4C0 316 5.08 320 12.09 320z"/></svg></button>
<button class="wrap-code-button
tw-select-none
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
group-[.is-wrap]:tw-text-fgColor-link
print:!tw-hidden" title="Toggle code wrap"><svg class="icon" viewBox="0 0 448 512"><path d="M16 132h416c8.837.0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163.0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"/></svg></button>
<button class="copy-code-button
tw-select-none
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
hover:tw-text-fgColor-link
print:!tw-hidden" title="Copy code">
<span class="copy-icon tw-block"><svg class="icon" viewBox="0 0 448 512"><path d="M433.941 65.941l-51.882-51.882A48 48 0 00348.118.0H176c-26.51.0-48 21.49-48 48v48H48c-26.51.0-48 21.49-48 48v320c0 26.51 21.49 48 48 48h224c26.51.0 48-21.49 48-48v-48h80c26.51.0 48-21.49 48-48V99.882a48 48 0 00-14.059-33.941zM266 464H54a6 6 0 01-6-6V150a6 6 0 016-6h74v224c0 26.51 21.49 48 48 48h96v42a6 6 0 01-6 6zm128-96H182a6 6 0 01-6-6V54a6 6 0 016-6h106v88c0 13.255 10.745 24 24 24h88v202a6 6 0 01-6 6zm6-256h-64V48h9.632c1.591.0 3.117.632 4.243 1.757l48.368 48.368a6 6 0 011.757 4.243V112z"/></svg></span>
<span class="check-icon tw-hidden"><svg class="icon" viewBox="0 0 512 512"><path d="M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206.0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204.0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204.0l36.203 36.204c9.997 9.997 9.997 26.206.0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z"/></svg></span>
</button>
<button class="tw-select-none
tw-mx-2
tw-block
group-[.is-open]:tw-hidden
print:!tw-hidden" disabled aria-hidden=true><svg class="icon" viewBox="0 0 512 512"><path d="M328 256c0 39.8-32.2 72-72 72s-72-32.2-72-72 32.2-72 72-72 72 32.2 72 72zm104-72c-39.8.0-72 32.2-72 72s32.2 72 72 72 72-32.2 72-72-32.2-72-72-72zm-352 0c-39.8.0-72 32.2-72 72s32.2 72 72 72 72-32.2 72-72-32.2-72-72-72z"/></svg></button></div></div><pre style=counter-reset:codeblock class="tw-block tw-m-0 tw-p-0"><code id=codeblock-id-3 class="chroma
!tw-block
tw-p-0
tw-m-0
tw-transition-[max-height]
tw-duration-500
tw-ease-in-out
group-[.is-closed]:!tw-max-h-0
group-[.is-wrap]:tw-text-wrap
tw-overflow-y-hidden
tw-overflow-x-auto
tw-scrollbar-thin"><span class=line><span class=cl><span class=n>scaler</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>amp</span><span class=o>.</span><span class=n>GradScaler</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>step</span><span class=p>,</span> <span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>loader</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>y</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>amp</span><span class=o>.</span><span class=n>autocast</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>y_hat</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=n>loss_fn</span><span class=p>(</span><span class=n>y_hat</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scaler</span><span class=o>.</span><span class=n>scale</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>scaler</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>optimizer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scaler</span><span class=o>.</span><span class=n>update</span><span class=p>()</span></span></span></code></pre></div><h3 id=93-dataparallelddp-提示 class=headerLink><a href=#93-dataparallelddp-%e6%8f%90%e7%a4%ba class=header-mark></a>9.3 DataParallel/DDP 提示</h3><ul><li><strong>演示</strong>可用 <code>nn.DataParallel(model)</code>；</li><li><strong>生产</strong>优先 <code>torch.distributed</code> + <code>DistributedDataParallel</code>，启动脚本与环境变量（<code>MASTER_ADDR/PORT</code>、<code>WORLD_SIZE</code> 等）务必正确。</li></ul><hr><h2 id=10-一页总结可口号式记忆 class=headerLink><a href=#10-%e4%b8%80%e9%a1%b5%e6%80%bb%e7%bb%93%e5%8f%af%e5%8f%a3%e5%8f%b7%e5%bc%8f%e8%ae%b0%e5%bf%86 class=header-mark></a>10. 一页总结（可口号式记忆）</h2><ul><li><strong>CPU 顺序通用，GPU 并行矩阵</strong>。</li><li><strong>把模型与数据都 <code>.to("cuda")</code></strong>。</li><li><strong>精度越低越快越省，但更"糙"</strong>（FP16/FP8/INT8/INT4）。</li><li><strong>量化与蒸馏不是一回事</strong>：位宽压缩 vs 老带新。</li><li><strong>估显存先抓权重，再想 KV/并发/长度</strong>。</li><li><strong>生产优先满血强模型（云端）</strong>；本地量化适合学习/原型。</li><li><strong>评估看测试集，不看训练集</strong>。</li><li><strong>多卡优先 DDP</strong>，留心通信与初始化。</li></ul><hr><h2 id=-延伸阅读 class=headerLink><a href=#-%e5%bb%b6%e4%bc%b8%e9%98%85%e8%af%bb class=header-mark></a>📚 延伸阅读</h2><h3 id=-ai-大模型系统教程系列 class=headerLink><a href=#-ai-%e5%a4%a7%e6%a8%a1%e5%9e%8b%e7%b3%bb%e7%bb%9f%e6%95%99%e7%a8%8b%e7%b3%bb%e5%88%97 class=header-mark></a>🔗 AI 大模型系统教程系列</h3><ol><li><strong><a href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B1/ rel>AI 大模型完全指南</a></strong> - 从零基础到 Token 与向量的深度解析</li><li><strong><a href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B2/ rel>Transformer 架构深度解析</a></strong> - 注意力机制与 AI 大模型的核心技术</li><li><strong><a href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B3/ rel>Prompt Engineering 完全指南</a></strong> - 从提示工程到上下文工程的实战教程</li><li><strong>[本文] GPU 加速训练实战指南</strong> - 从 CPU 架构到 CUDA 编程的完整教程</li><li><strong><a href=https://byronfinn.github.io/ai%E4%B8%93%E4%B8%9A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A%E8%A1%A8/ rel>AI 专业名词解释表</a></strong> - 270+术语完全指南与 AI 技术体系词典</li></ol><h3 id=-实战建议 class=headerLink><a href=#-%e5%ae%9e%e6%88%98%e5%bb%ba%e8%ae%ae class=header-mark></a>🎯 实战建议</h3><ul><li><strong>理论先行</strong>：如果对 Token、向量、Transformer 等概念不熟悉，建议先阅读前三篇基础教程</li><li><strong>实践结合</strong>：本文为实战指南，建议结合实际项目进行 GPU 训练实践</li><li><strong>术语查阅</strong>：开发过程中遇到专业术语时，可随时查阅 AI 专业名词解释表</li><li><strong>硬件选型</strong>：根据项目需求和预算，参考本文硬件选型建议进行配置</li></ul><hr></div><h2>相关内容</h2><div class=related-container><div class=related-item-container><h2 class=related-title><a href=/claudeskills%E7%9A%84%E5%8F%91%E6%95%A3/>利用 MCP 实现 Claude Skills 的渐进式披露机制: 复用Claude Code Skill in Anywhere</a></h2></div><div class=related-item-container><h2 class=related-title><a href=/pdf2md/>PDF2Markdown - 大型PDF文档智能文章提取工具完全指南</a></h2></div><div class=related-item-container><h2 class=related-title><a href=/pg-vector%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/>Docker安装PostgreSQL+pgvector完整教程：AI向量数据库快速部署指南</a></h2></div><div class=related-item-container><h2 class=related-title><a href=/ai%E6%95%99%E7%A8%8B5/>RAG系统完全指南——从零搭建本地检索增强生成系统</a></h2></div><div class=related-item-container><h2 class=related-title><a href=/ai%E4%B8%93%E4%B8%9A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A%E8%A1%A8/>AI专业名词解释表：270+术语完全指南与AI技术体系词典</a></h2></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>更新于 2025-11-06</span></div><div class=post-info-license></div></div><div class="post-info-line print:!tw-hidden"><div class=post-info-md></div><div class=post-info-share><button title="分享到 Twitter" data-sharer=twitter data-url=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B4/ data-title="CPU/GPU 与大模型训练" data-hashtags=GPU,CUDA,PyTorch,模型训练,深度学习,教程,硬件,实战><svg class="icon" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></button><button title="分享到 Evernote" data-sharer=evernote data-url=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B4/ data-title="CPU/GPU 与大模型训练"><svg class="icon" viewBox="0 0 384 512"><path d="M120.82 132.21c1.6 22.31-17.55 21.59-21.61 21.59-68.93.0-73.64-1-83.58 3.34-.56.22-.74.0-.37-.37L123.79 46.45c.38-.37.6-.22.38.37-4.35 9.99-3.35 15.09-3.35 85.39zm79 308c-14.68-37.08 13-76.93 52.52-76.62 17.49.0 22.6 23.21 7.95 31.42-6.19 3.3-24.95 1.74-25.14 19.2-.05 17.09 19.67 25 31.2 24.89A45.64 45.64.0 00312 393.45v-.08c0-11.63-7.79-47.22-47.54-55.34-7.72-1.54-65-6.35-68.35-50.52-3.74 16.93-17.4 63.49-43.11 69.09-8.74 1.94-69.68 7.64-112.92-36.77.0.0-18.57-15.23-28.23-57.95-3.38-15.75-9.28-39.7-11.14-62 0-18 11.14-30.45 25.07-32.2 81 0 90 2.32 101-7.8 9.82-9.24 7.8-15.5 7.8-102.78 1-8.3 7.79-30.81 53.41-24.14 6 .86 31.91 4.18 37.48 30.64l64.26 11.15c20.43 3.71 70.94 7 80.6 57.94 22.66 121.09 8.91 238.46 7.8 238.46C362.15 485.53 267.06 480 267.06 480c-18.95-.23-54.25-9.4-67.27-39.83zm80.94-204.84c-1 1.92-2.2 6 .85 7 14.09 4.93 39.75 6.84 45.88 5.53 3.11-.25 3.05-4.43 2.48-6.65-3.53-21.85-40.83-26.5-49.24-5.92z"/></svg></button></div></div></div><div class=post-info-more><section class=post-tags><svg class="icon" viewBox="0 0 640 512"><path d="M497.941 225.941 286.059 14.059A48 48 0 00252.118.0H48C21.49.0.0 21.49.0 48v204.118a48 48 0 0014.059 33.941l211.882 211.882c18.744 18.745 49.136 18.746 67.882.0l204.118-204.118c18.745-18.745 18.745-49.137.0-67.882zM112 160c-26.51.0-48-21.49-48-48s21.49-48 48-48 48 21.49 48 48-21.49 48-48 48zm513.941 133.823L421.823 497.941c-18.745 18.745-49.137 18.745-67.882.0l-.36-.36L527.64 323.522c16.999-16.999 26.36-39.6 26.36-63.64s-9.362-46.641-26.36-63.64L331.397.0h48.721a48 48 0 0133.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137.0 67.882z"/></svg>&nbsp;<a href=/tags/gpu/>GPU</a>,&nbsp;<a href=/tags/cuda/>CUDA</a>,&nbsp;<a href=/tags/pytorch/>PyTorch</a>,&nbsp;<a href=/tags/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/>模型训练</a>,&nbsp;<a href=/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/>深度学习</a>,&nbsp;<a href=/tags/%E6%95%99%E7%A8%8B/>教程</a>,&nbsp;<a href=/tags/%E7%A1%AC%E4%BB%B6/>硬件</a>,&nbsp;<a href=/tags/%E5%AE%9E%E6%88%98/>实战</a></section><section class=print:!tw-hidden><span><button class="tw-text-fgColor-link-muted hover:tw-text-fgColor-link-muted-hover" onclick=window.history.back()>返回</button></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class="post-nav print:tw-hidden"><a href=/ai%E6%95%99%E7%A8%8B5/ class=prev rel=prev title=RAG系统完全指南——从零搭建本地检索增强生成系统><svg class="icon" viewBox="0 0 256 512"><path d="M31.7 239l136-136c9.4-9.4 24.6-9.4 33.9.0l22.6 22.6c9.4 9.4 9.4 24.6.0 33.9L127.9 256l96.4 96.4c9.4 9.4 9.4 24.6.0 33.9L201.7 409c-9.4 9.4-24.6 9.4-33.9.0l-136-136c-9.5-9.4-9.5-24.6-.1-34z"/></svg>RAG系统完全指南——从零搭建本地检索增强生成系统</a>
<a href=/pg-vector%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/ class=next rel=next title=Docker安装PostgreSQL+pgvector完整教程：AI向量数据库快速部署指南>Docker安装PostgreSQL+pgvector完整教程：AI向量数据库快速部署指南<svg class="icon" viewBox="0 0 256 512"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9.0l-22.6-22.6c-9.4-9.4-9.4-24.6.0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6.0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9.0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a></div></div><div id=comments class="print:!tw-hidden tw-pt-32 tw-pb-8"><div id=giscus></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://giscus.app/>giscus</a>.</noscript></div></article></main><footer class=footer><div class=footer-container><div class=footer-line><svg class="icon" viewBox="0 0 512 512"><path d="M256 8C119.033 8 8 119.033 8 256s111.033 248 248 248 248-111.033 248-248S392.967 8 256 8zm0 448c-110.532.0-2e2-89.451-2e2-2e2.0-110.531 89.451-2e2 2e2-2e2 110.532.0 2e2 89.451 2e2 2e2.0 110.532-89.451 2e2-2e2 2e2zm107.351-101.064c-9.614 9.712-45.53 41.396-104.065 41.396-82.43.0-140.484-61.425-140.484-141.567.0-79.152 60.275-139.401 139.762-139.401 55.531.0 88.738 26.62 97.593 34.779a11.965 11.965.0 011.936 15.322l-18.155 28.113c-3.841 5.95-11.966 7.282-17.499 2.921-8.595-6.776-31.814-22.538-61.708-22.538-48.303.0-77.916 35.33-77.916 80.082.0 41.589 26.888 83.692 78.277 83.692 32.657.0 56.843-19.039 65.726-27.225 5.27-4.857 13.596-4.039 17.82 1.738l19.865 27.17a11.947 11.947.0 01-1.152 15.518z"/></svg>2025<span class=author>&nbsp;<a href=https://blog.baifan.site target=_blank rel="noopener noreferrer">Finn</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class=footer-line></div><div class=footer-line></div></div><script>"serviceWorker"in navigator&&(navigator.serviceWorker.register("/sw.min.js",{scope:"/"}).then(function(){}),navigator.serviceWorker.ready.then(function(){}))</script></footer><div class="print:!tw-hidden tw-flex tw-flex-col tw-fixed tw-right-4 tw-bottom-4 tw-gap-2"><a href=#back-to-top id=back-to-top-button class="tw-transition-opacity tw-opacity-0 tw-block tw-bg-bgColor-secondary tw-rounded-full" style=padding:.6rem;line-height:1.3rem;font-size:1rem title=回到顶部><svg class="icon" viewBox="0 0 448 512"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6.0-33.9L207 39c9.4-9.4 24.6-9.4 33.9.0l194.3 194.3c9.4 9.4 9.4 24.6.0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3.0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg>
</a><button id=toc-drawer-button class="tw-block tw-bg-bgColor-secondary tw-rounded-full md:tw-hidden" style=padding:.6rem;line-height:1.3rem;font-size:1rem>
<svg class="icon" viewBox="0 0 448 512"><path d="M16 132h416c8.837.0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163.0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"/></svg>
</button><a href=#comments id=view-comments class="tw-block tw-bg-bgColor-secondary tw-rounded-full" style=padding:.6rem;line-height:1.3rem;font-size:1rem title=查看评论>
<svg class="icon" viewBox="0 0 512 512"><path d="M256 32C114.6 32 0 125.1.0 240c0 49.6 21.4 95 57 130.7C44.5 421.1 2.7 466 2.2 466.5c-2.2 2.3-2.8 5.7-1.5 8.7S4.8 480 8 480c66.3.0 116-31.8 140.6-51.4 32.7 12.3 69 19.4 107.4 19.4 141.4.0 256-93.1 256-208S397.4 32 256 32z"/></svg></a></div><script type=module>
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
    mermaid.initialize({ startOnLoad: true, theme: (window.theme === 'dark' ? 'dark' : 'default') });
</script><div id=cookieconsent-container></div><link rel=stylesheet href=/lib/katex/katex.min.0c8126645bb983a788b167b1b97abe2505a962ad45e049001463c46012012a9b.css integrity="sha256-DIEmZFu5g6eIsWexuXq+JQWpYq1F4EkAFGPEYBIBKps="><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/katex/copy-tex.min.cf8e3e934d92a839d209ffdac331fa693da5958a6dff2c8788a4713cc1f50a47.css integrity="sha256-z44+k02SqDnSCf/awzH6aT2llYpt/yyHiKRxPMH1Ckc="><noscript><link rel=stylesheet href=/lib/katex/copy-tex.min.cf8e3e934d92a839d209ffdac331fa693da5958a6dff2c8788a4713cc1f50a47.css integrity="sha256-z44+k02SqDnSCf/awzH6aT2llYpt/yyHiKRxPMH1Ckc="></noscript><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.cd0d0b6e50ff01ff2f3a9a70d7cfb66a7c6cb9acf7a566325568be6d3bd31fc4.css integrity="sha256-zQ0LblD/Af8vOppw18+2anxsuaz3pWYyVWi+bTvTH8Q="><link rel=stylesheet href=/css/profile.003e858ff1233d9b981c64a8f06ff6ef394ebd60f81a472e374eb195bb673c7d.css integrity="sha256-AD6Fj/EjPZuYHGSo8G/27zlOvWD4GkcuN06xlbtnPH0="><script>window.config={"autocomplete.min.js":"/lib/autocomplete/autocomplete.min.js",comment:{giscus:{darkTheme:"dark",dataCategory:"Announcements",dataCategoryId:"DIC_kwDOQOVlP84Cxa17",dataEmitMetadata:"0",dataInputPosition:"top",dataLang:"zh-CN",dataLoading:"lazy",dataMapping:"pathname",dataReactionsEnabled:"1",dataRepo:"ByronFinn/ByronFinn.github.io",dataRepoId:"R_kgDOQOVlPw",dataStrict:"0",lightTheme:"light"}},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验."},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},data:{"desktop-header-typeit":"Daily Deep Think","mobile-header-typeit":"Daily Deep Think"},"fuse.min.js":"/lib/fuse/fuse.min.js",math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{distance:100,findAllMatches:!1,fuseIndexURL:"/index.json",highlightTag:"em",ignoreFieldNorm:!1,ignoreLocation:!1,isCaseSensitive:!1,location:0,maxResultLength:10,minMatchCharLength:2,noResultsFound:"没有找到结果",snippetLength:50,threshold:.3,type:"fuse",useExtendedSearch:!1},sharerjs:!0,table:{sort:!0},twemoji:!0,typeit:{cursorChar:"|",cursorSpeed:1e3,data:{"desktop-header-typeit":["desktop-header-typeit"],"mobile-header-typeit":["mobile-header-typeit"]},duration:-1,speed:100}}</script><script src=/lib/tablesort/tablesort.min.92de6dec051677787aed63503575b2f9be73f21f2745574e59647bc139a92d40.js integrity="sha256-kt5t7AUWd3h67WNQNXWy+b5z8h8nRVdOWWR7wTmpLUA="></script><script src=/lib/twemoji/twemoji.min.0e0e5259e3ff8ea805e0c5660c6336f7f46b14332e3cafb82939e1db3da8b6f8.js integrity="sha256-Dg5SWeP/jqgF4MVmDGM29/RrFDMuPK+4KTnh2z2otvg=" defer></script><script src=/js/twemoji.min.js defer></script><script src=/lib/sharer/sharer.min.8fe10eb615eb163a20f795484430a012805ec7c8c11df52df54ddb7a46084254.js integrity="sha256-j+EOthXrFjog95VIRDCgEoBex8jBHfUt9U3bekYIQlQ="></script><script src=/lib/typeit/typeit.min.06e0b9ba7bb3c9368aa26979037019306fef8e43dd2b9276854d227381445d0f.js integrity="sha256-BuC5unuzyTaKoml5A3AZMG/vjkPdK5J2hU0ic4FEXQ8="></script><script src=/lib/katex/katex.min.76d534cf1167067008fca12c4e903fc44cf8cfda8c5279c318d1f78cd90b086e.js integrity="sha256-dtU0zxFnBnAI/KEsTpA/xEz4z9qMUnnDGNH3jNkLCG4=" defer></script><script src=/lib/katex/auto-render.min.bb53eb953394531aae36fdd537065c4244eb8542901a3ce914601d932675b8ac.js integrity="sha256-u1PrlTOUUxquNv3VNwZcQkTrhUKQGjzpFGAdkyZ1uKw=" defer></script><script src=/lib/katex/copy-tex.min.07770af90943a1de1a1010794bc78c6a7346d46d48fb63e35cc76ba76b827604.js integrity="sha256-B3cK+QlDod4aEBB5S8eManNG1G1I+2PjXMdrp2uCdgQ=" defer></script><script src=/lib/katex/mhchem.min.9f87e5e9c384a160472d0045035a8641f6013358eddb3ece708634a50f946a40.js integrity="sha256-n4fl6cOEoWBHLQBFA1qGQfYBM1jt2z7OcIY0pQ+UakA=" defer></script><script src=/js/katex.min.js defer></script><script src=/lib/cookieconsent/cookieconsent.min.e55842a856a6d829feca3c3ad736c136b6c7549e9247274f78aa296259e06e24.js integrity="sha256-5VhCqFam2Cn+yjw61zbBNrbHVJ6SRydPeKopYlngbiQ=" defer></script><script src=/js/cookieconsent.min.js defer></script><script src=/js/theme.min.js defer></script><script src=/js/giscus.min.js defer></script><script type=speculationrules>
  {
    "prerender": [
      {
        "where": { "href_matches": "/*" },
        "eagerness": "moderate"
      }
    ]
  }
</script></body></html>