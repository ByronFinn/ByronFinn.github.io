<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>实战 - 标签 - 每日深度思考 | 技术、经济分析与深度思考</title><link>https://byronfinn.github.io/tags/%E5%AE%9E%E6%88%98/</link><description>实战 - 标签 - 每日深度思考 | 技术、经济分析与深度思考</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>baifan@z.org (Finn)</managingEditor><webMaster>baifan@z.org (Finn)</webMaster><lastBuildDate>Fri, 07 Nov 2025 10:18:00 +0800</lastBuildDate><atom:link href="https://byronfinn.github.io/tags/%E5%AE%9E%E6%88%98/" rel="self" type="application/rss+xml"/><item><title>PDF2Markdown - 大型PDF文档智能文章提取工具完全指南</title><link>https://byronfinn.github.io/pdf2md/</link><pubDate>Fri, 07 Nov 2025 10:18:00 +0800</pubDate><author><name>Finn</name></author><guid>https://byronfinn.github.io/pdf2md/</guid><description><![CDATA[<h1 id="pdf2markdown---大型-pdf-文档智能文章提取工具" class="headerLink">
    <a href="#pdf2markdown---%e5%a4%a7%e5%9e%8b-pdf-%e6%96%87%e6%a1%a3%e6%99%ba%e8%83%bd%e6%96%87%e7%ab%a0%e6%8f%90%e5%8f%96%e5%b7%a5%e5%85%b7" class="header-mark"></a>PDF2Markdown - 大型 PDF 文档智能文章提取工具</h1><p><a href="https://python.org" target="_blank" rel="noopener noreferrer"><img class="tw-inline" loading="lazy" src='/python-3.13+-blue_1423277123478464751.svg'   alt="Python Version"  ></a>
<a href="https://github.com/astral-sh/ruff" target="_blank" rel="noopener noreferrer"><img class="tw-inline" loading="lazy" src='/code%20style-ruff-green_7678052461911854896.svg'   alt="Code Style"  ></a>
<a href="https://mypy.readthedocs.io/" target="_blank" rel="noopener noreferrer"><img class="tw-inline" loading="lazy" src='/type%20checking-mypy-blue_13250137686053437545.svg'   alt="Type Checking"  ></a>
<a href="LICENSE" rel=""><img class="tw-inline" loading="lazy" src='/license-MIT-green_10730612941528799645.svg'   alt="License"  ></a></p>
<h2 id="项目概述" class="headerLink">
    <a href="#%e9%a1%b9%e7%9b%ae%e6%a6%82%e8%bf%b0" class="header-mark"></a>项目概述</h2><p>PDF2Markdown 是一个专门用于处理大型扫描件 PDF 文件的智能内容提取工具。结合传统 OCR 技术与现代 AI 大模型，智能提取文档中的纯文章内容，自动过滤图片、表格等非文章元素。完美支持中英文混合文档处理。</p>]]></description></item><item><title>Docker安装PostgreSQL+pgvector完整教程：AI向量数据库快速部署指南</title><link>https://byronfinn.github.io/pg-vector%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/</link><pubDate>Thu, 06 Nov 2025 10:00:00 +0800</pubDate><author><name>Finn</name></author><guid>https://byronfinn.github.io/pg-vector%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/</guid><description><![CDATA[<h1 id="-在-docker-中安装部署-postgresql--pgvector" class="headerLink">
    <a href="#-%e5%9c%a8-docker-%e4%b8%ad%e5%ae%89%e8%a3%85%e9%83%a8%e7%bd%b2-postgresql--pgvector" class="header-mark"></a>🐘 在 Docker 中安装部署 PostgreSQL + pgvector</h1><p>本文介绍如何在 <strong>Docker Compose</strong> 环境中快速部署带有 <strong>pgvector</strong> 扩展的 PostgreSQL 数据库，
以便在本地或开发环境中支持向量检索与 AI 应用（如 LangChain、RAG、语义搜索等）。</p>]]></description></item><item><title>CPU/GPU 与大模型训练</title><link>https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B4/</link><pubDate>Thu, 06 Nov 2025 09:36:42 +0800</pubDate><author><name>Finn</name></author><guid>https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B4/</guid><description><![CDATA[<h1 id="ai-教程-cpugpu-与大模型训练" class="headerLink">
    <a href="#ai-%e6%95%99%e7%a8%8b-cpugpu-%e4%b8%8e%e5%a4%a7%e6%a8%a1%e5%9e%8b%e8%ae%ad%e7%bb%83" class="header-mark"></a>AI 教程: CPU/GPU 与大模型训练</h1><blockquote>
  <p>这是一份高浓缩资料：结构清晰、要点到位，涵盖 CPU/GPU 基础、张量与数值精度、CUDA 与 PyTorch 实操、硬件选型、常见问答与排错清单。</p>

</blockquote><hr>
<h2 id="0-速览30-秒" class="headerLink">
    <a href="#0-%e9%80%9f%e8%a7%8830-%e7%a7%92" class="header-mark"></a>0. 速览（30 秒）</h2><ul>
<li><strong>CPU vs GPU</strong>：CPU 擅长<strong>通用/顺序</strong>处理；GPU 擅长<strong>大规模并行</strong>（矩阵/向量）。</li>
<li><strong>大模型必备 GPU</strong>：训练/推理核心是矩阵乘和并行化，GPU 的高并发 + 高带宽显存恰好匹配。</li>
<li><strong>张量与精度</strong>：一切数据 → 张量；精度（FP16/FP8）与<strong>量化</strong>（INT8/INT4）是速度/显存与效果之间的权衡。</li>
<li><strong>PyTorch 上卡口诀</strong>：<code>device = &quot;cuda&quot; if ...; model.to(device); data.to(device)</code></li>
<li><strong>选卡看显存</strong>：先显存，再带宽/算力；生产尽量用<strong>满血高质量模型</strong>或云端托管 API。</li>
</ul>
<hr>
<h2 id="1-cpu-与-gpu差异场景与类比" class="headerLink">
    <a href="#1-cpu-%e4%b8%8e-gpu%e5%b7%ae%e5%bc%82%e5%9c%ba%e6%99%af%e4%b8%8e%e7%b1%bb%e6%af%94" class="header-mark"></a>1. CPU 与 GPU：差异、场景与类比</h2><h3 id="11-一句话对比" class="headerLink">
    <a href="#11-%e4%b8%80%e5%8f%a5%e8%af%9d%e5%af%b9%e6%af%94" class="header-mark"></a>1.1 一句话对比</h3><table>
  <thead>
      <tr>
          <th>维度</th>
          <th>CPU</th>
          <th>GPU</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>架构</td>
          <td>少核、复杂控制流</td>
          <td>海量小核、SIMT 并行</td>
      </tr>
      <tr>
          <td>擅长</td>
          <td>分支/系统任务/小规模计算</td>
          <td>矩阵乘、卷积、注意力、图形渲染</td>
      </tr>
      <tr>
          <td>任务模型</td>
          <td>时间片轮转、低延迟切换</td>
          <td>批处理&amp;吞吐导向</td>
      </tr>
      <tr>
          <td>典型用法</td>
          <td>业务逻辑、调度、I/O</td>
          <td>训练/推理主算子（GEMM、Conv 等）</td>
      </tr>
  </tbody>
</table>
<h3 id="12-形象类比" class="headerLink">
    <a href="#12-%e5%bd%a2%e8%b1%a1%e7%b1%bb%e6%af%94" class="header-mark"></a>1.2 形象类比</h3><ul>
<li><strong>CPU = 老专家</strong>：思考缜密、一次做一件事快切换。</li>
<li><strong>GPU = 千军万马</strong>：海量士兵同时干活，适合“<strong>同构小任务</strong>”的并行。</li>
</ul>
<h3 id="13-可选-mermaid-图cpu-执行-vs-gpu-并行" class="headerLink">
    <a href="#13-%e5%8f%af%e9%80%89-mermaid-%e5%9b%becpu-%e6%89%a7%e8%a1%8c-vs-gpu-%e5%b9%b6%e8%a1%8c" class="header-mark"></a>1.3 可选 Mermaid 图（CPU 执行 vs GPU 并行）</h3><pre class="mermaid">flowchart LR
    subgraph CPU["CPU（顺序/少核）"]
      A1[任务1-片段A] --> A2[任务2-片段B] --> A3[任务3-片段C]
    end
    subgraph GPU["GPU（并行/多核）"]
      B1[元素1计算]:::p
      B2[元素2计算]:::p
      B3[元素3计算]:::p
      B4[元素4计算]:::p
    end
    classDef p fill:#e9f5ff,stroke:#3b82f6,stroke-width:1px;
</pre><hr>
<h2 id="2-张量tensor精度与量化配例子" class="headerLink">
    <a href="#2-%e5%bc%a0%e9%87%8ftensor%e7%b2%be%e5%ba%a6%e4%b8%8e%e9%87%8f%e5%8c%96%e9%85%8d%e4%be%8b%e5%ad%90" class="header-mark"></a>2. 张量（Tensor）、精度与量化（配例子）</h2><h3 id="21-张量分级" class="headerLink">
    <a href="#21-%e5%bc%a0%e9%87%8f%e5%88%86%e7%ba%a7" class="header-mark"></a>2.1 张量分级</h3><ul>
<li><strong>0D</strong>：标量 <code>3.14</code></li>
<li><strong>1D</strong>：向量 <code>[1,2,3]</code></li>
<li><strong>2D</strong>：矩阵（如 3×3 表）</li>
<li><strong>3D+</strong>：仍称张量（如 <code>batch×channel×height×width</code>）</li>
</ul>
<p><strong>图像例子</strong>：一批 32 张 224×224 RGB 图 → <code>32×3×224×224</code>（或 <code>N×H×W×C</code>，视框架而定）。</p>]]></description></item><item><title>RAG系统完全指南——从零搭建本地检索增强生成系统</title><link>https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B5/</link><pubDate>Thu, 06 Nov 2025 09:36:42 +0800</pubDate><author><name>Finn</name></author><guid>https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B5/</guid><description><![CDATA[<h1 id="用-langchain--ollama--pgvector-搭建本地-rag从-0-到-1-的完整实战含-uv-依赖管理--面试指南" class="headerLink">
    <a href="#%e7%94%a8-langchain--ollama--pgvector-%e6%90%ad%e5%bb%ba%e6%9c%ac%e5%9c%b0-rag%e4%bb%8e-0-%e5%88%b0-1-%e7%9a%84%e5%ae%8c%e6%95%b4%e5%ae%9e%e6%88%98%e5%90%ab-uv-%e4%be%9d%e8%b5%96%e7%ae%a1%e7%90%86--%e9%9d%a2%e8%af%95%e6%8c%87%e5%8d%97" class="header-mark"></a>用 LangChain + Ollama + pgvector 搭建本地 RAG：从 0 到 1 的完整实战（含 uv 依赖管理 &amp; 面试指南）</h1><blockquote>
  <p>本文是可直接落地的 <strong>Markdown 文档</strong>。按文档自上而下执行即可从零搭建出一个本地 RAG（检索增强生成）系统，并理解关键概念与代码。所有核心脚本都附带中文注释，便于学习与面试复盘。</p>]]></description></item></channel></rss>