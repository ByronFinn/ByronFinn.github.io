<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>教程 - 标签 - 每日深度思考 | 技术、经济分析与深度思考</title><link>https://byronfinn.github.io/tags/%E6%95%99%E7%A8%8B/</link><description>教程 - 标签 - 每日深度思考 | 技术、经济分析与深度思考</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>baifan@z.org (Finn)</managingEditor><webMaster>baifan@z.org (Finn)</webMaster><lastBuildDate>Thu, 06 Nov 2025 10:00:00 +0800</lastBuildDate><atom:link href="https://byronfinn.github.io/tags/%E6%95%99%E7%A8%8B/" rel="self" type="application/rss+xml"/><item><title>Docker安装PostgreSQL+pgvector完整教程：AI向量数据库快速部署指南</title><link>https://byronfinn.github.io/pg-vector%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/</link><pubDate>Thu, 06 Nov 2025 10:00:00 +0800</pubDate><author><name>Finn</name></author><guid>https://byronfinn.github.io/pg-vector%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/</guid><description><![CDATA[<h1 id="-在-docker-中安装部署-postgresql--pgvector" class="headerLink">
    <a href="#-%e5%9c%a8-docker-%e4%b8%ad%e5%ae%89%e8%a3%85%e9%83%a8%e7%bd%b2-postgresql--pgvector" class="header-mark"></a>🐘 在 Docker 中安装部署 PostgreSQL + pgvector</h1><p>本文介绍如何在 <strong>Docker Compose</strong> 环境中快速部署带有 <strong>pgvector</strong> 扩展的 PostgreSQL 数据库，
以便在本地或开发环境中支持向量检索与 AI 应用（如 LangChain、RAG、语义搜索等）。</p>]]></description></item><item><title>CPU/GPU 与大模型训练</title><link>https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B4/</link><pubDate>Thu, 06 Nov 2025 09:36:42 +0800</pubDate><author><name>Finn</name></author><guid>https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B4/</guid><description><![CDATA[<h1 id="ai-教程-cpugpu-与大模型训练" class="headerLink">
    <a href="#ai-%e6%95%99%e7%a8%8b-cpugpu-%e4%b8%8e%e5%a4%a7%e6%a8%a1%e5%9e%8b%e8%ae%ad%e7%bb%83" class="header-mark"></a>AI 教程: CPU/GPU 与大模型训练</h1><blockquote>
  <p>这是一份高浓缩资料：结构清晰、要点到位，涵盖 CPU/GPU 基础、张量与数值精度、CUDA 与 PyTorch 实操、硬件选型、常见问答与排错清单。</p>

</blockquote><hr>
<h2 id="0-速览30-秒" class="headerLink">
    <a href="#0-%e9%80%9f%e8%a7%8830-%e7%a7%92" class="header-mark"></a>0. 速览（30 秒）</h2><ul>
<li><strong>CPU vs GPU</strong>：CPU 擅长<strong>通用/顺序</strong>处理；GPU 擅长<strong>大规模并行</strong>（矩阵/向量）。</li>
<li><strong>大模型必备 GPU</strong>：训练/推理核心是矩阵乘和并行化，GPU 的高并发 + 高带宽显存恰好匹配。</li>
<li><strong>张量与精度</strong>：一切数据 → 张量；精度（FP16/FP8）与<strong>量化</strong>（INT8/INT4）是速度/显存与效果之间的权衡。</li>
<li><strong>PyTorch 上卡口诀</strong>：<code>device = &quot;cuda&quot; if ...; model.to(device); data.to(device)</code></li>
<li><strong>选卡看显存</strong>：先显存，再带宽/算力；生产尽量用<strong>满血高质量模型</strong>或云端托管 API。</li>
</ul>
<hr>
<h2 id="1-cpu-与-gpu差异场景与类比" class="headerLink">
    <a href="#1-cpu-%e4%b8%8e-gpu%e5%b7%ae%e5%bc%82%e5%9c%ba%e6%99%af%e4%b8%8e%e7%b1%bb%e6%af%94" class="header-mark"></a>1. CPU 与 GPU：差异、场景与类比</h2><h3 id="11-一句话对比" class="headerLink">
    <a href="#11-%e4%b8%80%e5%8f%a5%e8%af%9d%e5%af%b9%e6%af%94" class="header-mark"></a>1.1 一句话对比</h3><table>
  <thead>
      <tr>
          <th>维度</th>
          <th>CPU</th>
          <th>GPU</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>架构</td>
          <td>少核、复杂控制流</td>
          <td>海量小核、SIMT 并行</td>
      </tr>
      <tr>
          <td>擅长</td>
          <td>分支/系统任务/小规模计算</td>
          <td>矩阵乘、卷积、注意力、图形渲染</td>
      </tr>
      <tr>
          <td>任务模型</td>
          <td>时间片轮转、低延迟切换</td>
          <td>批处理&amp;吞吐导向</td>
      </tr>
      <tr>
          <td>典型用法</td>
          <td>业务逻辑、调度、I/O</td>
          <td>训练/推理主算子（GEMM、Conv 等）</td>
      </tr>
  </tbody>
</table>
<h3 id="12-形象类比" class="headerLink">
    <a href="#12-%e5%bd%a2%e8%b1%a1%e7%b1%bb%e6%af%94" class="header-mark"></a>1.2 形象类比</h3><ul>
<li><strong>CPU = 老专家</strong>：思考缜密、一次做一件事快切换。</li>
<li><strong>GPU = 千军万马</strong>：海量士兵同时干活，适合“<strong>同构小任务</strong>”的并行。</li>
</ul>
<h3 id="13-可选-mermaid-图cpu-执行-vs-gpu-并行" class="headerLink">
    <a href="#13-%e5%8f%af%e9%80%89-mermaid-%e5%9b%becpu-%e6%89%a7%e8%a1%8c-vs-gpu-%e5%b9%b6%e8%a1%8c" class="header-mark"></a>1.3 可选 Mermaid 图（CPU 执行 vs GPU 并行）</h3><pre class="mermaid">flowchart LR
    subgraph CPU["CPU（顺序/少核）"]
      A1[任务1-片段A] --> A2[任务2-片段B] --> A3[任务3-片段C]
    end
    subgraph GPU["GPU（并行/多核）"]
      B1[元素1计算]:::p
      B2[元素2计算]:::p
      B3[元素3计算]:::p
      B4[元素4计算]:::p
    end
    classDef p fill:#e9f5ff,stroke:#3b82f6,stroke-width:1px;
</pre><hr>
<h2 id="2-张量tensor精度与量化配例子" class="headerLink">
    <a href="#2-%e5%bc%a0%e9%87%8ftensor%e7%b2%be%e5%ba%a6%e4%b8%8e%e9%87%8f%e5%8c%96%e9%85%8d%e4%be%8b%e5%ad%90" class="header-mark"></a>2. 张量（Tensor）、精度与量化（配例子）</h2><h3 id="21-张量分级" class="headerLink">
    <a href="#21-%e5%bc%a0%e9%87%8f%e5%88%86%e7%ba%a7" class="header-mark"></a>2.1 张量分级</h3><ul>
<li><strong>0D</strong>：标量 <code>3.14</code></li>
<li><strong>1D</strong>：向量 <code>[1,2,3]</code></li>
<li><strong>2D</strong>：矩阵（如 3×3 表）</li>
<li><strong>3D+</strong>：仍称张量（如 <code>batch×channel×height×width</code>）</li>
</ul>
<p><strong>图像例子</strong>：一批 32 张 224×224 RGB 图 → <code>32×3×224×224</code>（或 <code>N×H×W×C</code>，视框架而定）。</p>]]></description></item><item><title>RAG系统完全指南——从零搭建本地检索增强生成系统</title><link>https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B5/</link><pubDate>Thu, 06 Nov 2025 09:36:42 +0800</pubDate><author><name>Finn</name></author><guid>https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B5/</guid><description><![CDATA[<h1 id="用-langchain--ollama--pgvector-搭建本地-rag从-0-到-1-的完整实战含-uv-依赖管理--面试指南" class="headerLink">
    <a href="#%e7%94%a8-langchain--ollama--pgvector-%e6%90%ad%e5%bb%ba%e6%9c%ac%e5%9c%b0-rag%e4%bb%8e-0-%e5%88%b0-1-%e7%9a%84%e5%ae%8c%e6%95%b4%e5%ae%9e%e6%88%98%e5%90%ab-uv-%e4%be%9d%e8%b5%96%e7%ae%a1%e7%90%86--%e9%9d%a2%e8%af%95%e6%8c%87%e5%8d%97" class="header-mark"></a>用 LangChain + Ollama + pgvector 搭建本地 RAG：从 0 到 1 的完整实战（含 uv 依赖管理 &amp; 面试指南）</h1><blockquote>
  <p>本文是可直接落地的 <strong>Markdown 文档</strong>。按文档自上而下执行即可从零搭建出一个本地 RAG（检索增强生成）系统，并理解关键概念与代码。所有核心脚本都附带中文注释，便于学习与面试复盘。</p>]]></description></item><item><title>Prompt Engineering完全指南：从提示工程到上下文工程的实战教程</title><link>https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B3/</link><pubDate>Wed, 05 Nov 2025 09:58:24 +0800</pubDate><author><name>Finn</name></author><guid>https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B3/</guid><description><![CDATA[<h1 id="ai-教程prompt-engineering" class="headerLink">
    <a href="#ai-%e6%95%99%e7%a8%8bprompt-engineering" class="header-mark"></a>AI 教程：Prompt Engineering</h1><p>提示工程主要关注提示词的设计、优化与策略制定，致力于帮助用户更高效地调动大语言模型的能力，进而推动其在各类实际场景和研究领域中的应用。</p>]]></description></item><item><title>Transformer架构深度解析：注意力机制与AI大模型的核心技术</title><link>https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B2/</link><pubDate>Wed, 05 Nov 2025 09:58:24 +0800</pubDate><author><name>Finn</name></author><guid>https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B2/</guid><description><![CDATA[<h1 id="ai-教程---transformer" class="headerLink">
    <a href="#ai-%e6%95%99%e7%a8%8b---transformer" class="header-mark"></a>AI 教程 - Transformer</h1><h2 id="-一transformer-是什么" class="headerLink">
    <a href="#-%e4%b8%80transformer-%e6%98%af%e4%bb%80%e4%b9%88" class="header-mark"></a>🧩 一、Transformer 是什么？</h2><blockquote>
  <p><strong>Transformer 是一种深度学习架构，用来处理序列（例如文字、语音、代码等）信息。</strong></p>

</blockquote><p>它最早由 Google 在 2017 年的论文《Attention Is All You Need（注意力机制就是全部）》中提出。</p>]]></description></item><item><title>AI大模型完全指南：从零基础到Token与向量的深度解析</title><link>https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B1/</link><pubDate>Wed, 05 Nov 2025 08:58:24 +0800</pubDate><author><name>Finn</name></author><guid>https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B1/</guid><description><![CDATA[<h1 id="ai-教程从基础到深入的-ai-大模型指南" class="headerLink">
    <a href="#ai-%e6%95%99%e7%a8%8b%e4%bb%8e%e5%9f%ba%e7%a1%80%e5%88%b0%e6%b7%b1%e5%85%a5%e7%9a%84-ai-%e5%a4%a7%e6%a8%a1%e5%9e%8b%e6%8c%87%e5%8d%97" class="header-mark"></a>AI 教程：从基础到深入的 AI 大模型指南</h1><p>本文将带你深入理解 AI 大模型的核心概念，从基本原理到向量表示，循序渐进地构建完整的知识体系。</p>
<hr>
<h2 id="一ai-应用开发基础" class="headerLink">
    <a href="#%e4%b8%80ai-%e5%ba%94%e7%94%a8%e5%bc%80%e5%8f%91%e5%9f%ba%e7%a1%80" class="header-mark"></a>一、AI 应用开发基础</h2><h3 id="11-基本原理与概念" class="headerLink">
    <a href="#11-%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86%e4%b8%8e%e6%a6%82%e5%bf%b5" class="header-mark"></a>1.1 基本原理与概念</h3><h4 id="通俗理解" class="headerLink">
    <a href="#%e9%80%9a%e4%bf%97%e7%90%86%e8%a7%a3" class="header-mark"></a>通俗理解</h4><ul>
<li><strong>核心机制</strong>：根据上一个词预测下一个词，类似成语接龙</li>
<li><strong>工作方式</strong>：通过 token 逐字生成输出</li>
</ul>
<h4 id="进阶理解" class="headerLink">
    <a href="#%e8%bf%9b%e9%98%b6%e7%90%86%e8%a7%a3" class="header-mark"></a>进阶理解</h4><p>AI 大模型包含两个关键阶段：</p>]]></description></item></channel></rss>