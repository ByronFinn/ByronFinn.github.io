# AI大模型完全指南：从零基础到Token与向量的深度解析


# AI 教程：从基础到深入的 AI 大模型指南

本文将带你深入理解 AI 大模型的核心概念，从基本原理到向量表示，循序渐进地构建完整的知识体系。

---

## 一、AI 应用开发基础

### 1.1 基本原理与概念

#### 通俗理解

- **核心机制**：根据上一个词预测下一个词，类似成语接龙
- **工作方式**：通过 token 逐字生成输出

#### 进阶理解

AI 大模型包含两个关键阶段：

| 阶段     | 比喻   | 具体作用                           |
| -------- | ------ | ---------------------------------- |
| **训练** | "学习" | 阅读海量数据构建模型，形成知识储备 |
| **推理** | "应用" | 根据输入生成响应，提供服务能力     |

#### 核心技术组件

- **Transformer 架构**

  - 由 encoder 编码器 + decoder 解码器组成
  - 核心是注意力机制，实现高效的信息处理

- **Embedding 与位置编码**

  - 将文字转换为计算机可处理的数字向量
  - 加入顺序信息，理解语言的时序关系

- **多头注意力机制**
  - 核心计算步骤
  - 决定哪些内容更重要，从而影响输出结果

---

## 二、核心概念解析

### 2.1 基本术语

- **AGI（通用人工智能）**：大模型的最终目标，具备人类水平的智能
- **LLM（Large Language Model）**：大语言模型的简称
- **对话产品 vs 大模型**：应用层与模型层的区别

### 2.2 模型与应用的关系

| 比喻      | 概念     | 作用                             |
| --------- | -------- | -------------------------------- |
| 大脑      | 大模型   | 拥有强大的理解与生成能力         |
| 应用/产品 | 对话产品 | 让普通人能方便、安全地使用大模型 |

---

## 三、Token：AI 语言的最小单位

### 3.1 什么是 Token？

> **token = 模型处理文本的最小单位。**
> 它既不是严格的"字"，也不是固定的"词"，而是通过一种压缩规则把文本切成的片段。

#### Token 的切分特点

- **英文**：常被切成**词片段**

  - `"I love apples"` → `["I", " love", " apple", "s"]`

- **中文**：常按**字或短词**切

  - `"我喜欢苹果"` → `["我", "喜欢", "苹果"]`
  - _（具体切分粒度取决于分词器）_

- **特殊 Token**：如开始/结束标记、换行、工具调用边界等

> 💡 **直觉理解**：token 像"AI 的字粒子"，模型是**一个 token 一个 token**地读入和生成。

### 3.2 Token 是如何切出来的？

大多数 LLM 使用**BPE/Unigram**等算法：

- 找到文本里最常见的字符组合，给它们分配一个"词表 ID"
- 这样既能表示单个字符，也能表示常见词或词片段
- 兼顾**效率**（更少 token）和**泛化**（罕见词能被拆开）

> ⚠️ **重要提示**：同一句话在不同模型/词表下，**token 数可能不同**。

### 3.3 Token 与产品的关系

| 影响因素     | 具体表现                             | 优化策略                   |
| ------------ | ------------------------------------ | -------------------------- |
| **长度限制** | 模型一次能读/记住的 token 总数有上限 | 截断或分批检索             |
| **费用**     | 绝大多数商用 LLM 按**token 数计费**  | 优化提示词，减少无效 token |
| **速度**     | 输出是逐 token 流式生成              | 控制输出长度，减少延迟     |
| **质量**     | 合理控制 token 能显著提升效果        | 清理提示词，优化检索内容   |

#### 📊 Token 估算经验

- **英文**：~3-4 个词 ≈ 1 个 token（100token ≈ 75 英文词）
- **中文**：1 字/词 ≈ 0.6 个 token（因词表不同会有浮动）
- **注意事项**：真实计数以具体模型的分词器为准

---

## 四、向量：AI 理解的基石

### 4.1 什么是向量？

> 向量（Vector）在数学里指的是：一个有**大小**和**方向**的量，或者更一般地说，是一组有顺序的数字。

最简单的向量可以写成：

```plaintext
(2, 3)
```

这代表：

- 沿着 x 轴走 2 个单位
- 沿着 y 轴走 3 个单位

它可以表示一个**点的位置**（相对于原点的偏移），也可以表示一个**从原点出发的箭头（方向+长度）**。

### 4.2 🧭 几何意义举例

想象你在一个平面上走路：

- 向量 **(2, 3)** 表示"向右走 2，向上走 3"
- 向量 **(-1, 4)** 表示"向左走 1，向上走 4"

这些数字就像**坐标**，告诉你在空间中"往哪里去"。

📊 如果我们画出来：

- 原点在 (0, 0)
- 终点在 (2, 3)
  → 这就是一个箭头指向的"向量"

### 4.3 💡 从特征的角度理解

当我们把这个概念应用到人工智能时，向量不仅仅是"位置"，还可以表示"特征"或"意义"。

#### 举例 1：颜色向量

假设我们用 3 个数字表示颜色的红、绿、蓝成分：

```plaintext
红色： (255, 0, 0)
绿色： (0, 255, 0)
蓝色： (0, 0, 255)
```

这就是一个**3 维向量空间**。每个颜色都能用一个三维点表示在空间中，这样我们就能"计算颜色之间的相似度"。

#### 举例 2：人类特征向量

假设我们想用数字来描述一个人：

| 特征 | 含义 | 数值 |
| ---- | ---- | ---- |
| 年龄 | 岁数 | 25   |
| 身高 | cm   | 180  |
| 体重 | kg   | 70   |

那么一个人可以表示为：`(25, 180, 70)`

这也是一个三维向量。如果我们要比较两个人的相似程度，就可以用数学方式计算他们向量之间的距离。

比如：

```plaintext
A(25, 180, 70)
B(26, 178, 72)
```

他们的向量"距离"很近 → 表示两人特征相似。

#### 举例 3：词语的语义向量

在自然语言处理（NLP）中，模型会把每个词变成一个高维向量（比如 768 维）。

| 词语 | 向量（部分展示）         |
| ---- | ------------------------ |
| 国王 | `[0.25, -0.12, 0.78, …]` |
| 王后 | `[0.27, -0.10, 0.74, …]` |
| 男人 | `[0.30, -0.15, 0.70, …]` |
| 女人 | `[0.28, -0.13, 0.72, …]` |

然后模型会发现：

> `「国王」 - 「男人」 + 「女人」 ≈ 「王后」`

也就是说，向量之间的数学关系**能表达语义关系**。这就是为什么我们说：

> 向量让机器"理解意义"，而不仅仅是看到文字。

---

## 五、LLM 业务流程中的 Token 管理

### 5.1 完整业务流程

以下是一条"对话/问答类"应用的主流程（每步与 token 的关系）：

#### 1. 用户输入

- **文本原文**：例如"帮我写一封面试感谢信"
- ✅ **关键点**：长度不可控，需要后续做清洗与限制

#### 2. 预处理（清洗/结构化）

- 去除无意义空白、控制文本格式
- 注入角色/语气要求（Prompt 模板化）
- ✅ **关键点**：减少"脏 token"，用更少的 token 传达更清楚的意图

#### 3. 检索（可选：RAG）

- 把用户问题向量化 → 在向量库里找相关文档 → 取回若干段落
- 将这些段落拼进提示词作为"上下文"
- ✅ **关键点**：检索段落要**裁剪与摘要**，否则容易爆上下文窗口

#### 4. 拼装最终 Prompt（输入序列）

- **组成**：`系统指令 + 工具/函数定义 + 检索证据 + 历史对话 + 本次用户问法`
- 然后**Tokenizer 把它们全部切成 token**
- ✅ **关键点**：统计输入 token，若接近上限：
  - 优先保留"高相关证据"
  - 对历史对话做**摘要/滑窗**
  - 控制生成上限（max_tokens）

#### 5. 模型前向与生成循环（Decoding）

- 模型读入输入 token → 输出**下一个 token 的概率分布**
- 采样策略（greedy/temperature/top-p…）选中下一个 token
- 将新 token**追加到上下文**里，再预测下一个（循环往复）
- 直到满足**停止条件**：遇到结束符 / 达到 max_tokens / 命中停止词

- ✅ **关键点**：
  - **输出 token**是"流式"推出来的
  - 采样越"发散"（高`temperature`），token 可能更多、风格更活泼
  - 设定合理的**`max_tokens`**可以控成本与延迟

#### 6. 反分词（Detokenization）

- 模型输出的是 token 序列，需还原成文本字符串
- ✅ **关键点**：某些看似细节的空格/缩进，其实都是 token 的一部分

#### 7. 后处理（Post-processing）

- 结构化提取、格式化成 Markdown/JSON
- 敏感信息/合规过滤
- 结果摘要或多轮工具调用
- ✅ **关键点**：减少**无效输出 token**，能降成本也提速

#### 8. 日志与计费

- 记录输入/输出 token 数、延迟、失败重试情况
- 结合质量指标做提示词与检索策略迭代

> 🔄 **流程图**：

{{< figure src="/pictures/note/2025-11-05-ai-001.svg" title="AI大模型概念关联图（五层结构）" caption="从基础概念、数学表示、模型架构、工程与优化到智能体与未来的层级关系与主要术语" class="center" >}}

### 5.2 🎯 实际案例分析

#### 案例 1：为什么"长上下文"不等于"高质量"

- **问题**：把 20 页文档全塞进 Prompt，token 爆表 → 不得不截断
- **结果**：反而漏掉了最相关的 2 段
- **解决**：**检索 + 片段评分 + 摘要**，用**更少 token**保留**更关键信息**

#### 案例 2：控制成本与延迟

- **需求**：用户只要"要点列表"，没必要让模型写 1,000token 的长文
- **策略**：设置`max_tokens=120` + 提示"用 6 条要点，每条 ≤20 字"
- **效果**：成本、时延都立降，且对齐需求

#### 案例 3：中英 token 体感差异

- **现象**：同样 100 个中文字符和 100 个英文单词，**token 数通常不同**
- **建议**：产品层面要以**真实 token 计数**为准来做限流与预算

### 5.3 🛠️ 产品/工程实操建议

#### 核心策略

1. **实时 token 计数**：在拼装 Prompt 后、请求模型前做一次计数，接近上限就触发"裁剪策略"
2. **分层上下文**：系统指令（短且稳定）+ 高相关证据（短/精）+ 近几轮对话（摘要后）
3. **输出上限与停用词**：为不同场景配置`max_tokens`和 stop words，避免"越写越长"
4. **检索片段控长**：给每段设置最大 token，并做句内裁剪（只留命中句两侧若干字）
5. **指标闭环**：记录`input_tokens/output_tokens/latency/success_rate`，用 A/B 迭代提示词与检索策略
6. **多语言场景**：不同语言 token 利率不同，必要时做**语言检测 + 翻译到统一语种**再进模型

---

## 六、🧠 核心要点总结

### 6.1 关键概念对照

| 概念            | 一句话理解                                      |
| --------------- | ----------------------------------------------- |
| **Token**       | AI 语言的"字粒子"，一切长度、速度、费用都围绕它 |
| **向量**        | 意义的数字化表示，让机器理解语义关系            |
| **Transformer** | 现代 AI 的核心架构，通过注意力机制处理信息      |

### 6.2 学习要点回顾

1. **基本原理**：预测下一个词，通过 token 逐字生成
2. **核心架构**：Transformer + 注意力机制
3. **关键概念**：向量表示让机器理解语义
4. **实际应用**：从模型到产品的完整链条
5. **Token 管理**：控制长度、费用、质量的关键

### 6.3 💡 学习建议

- **理解 token 概念**：这是深入 AI 领域的关键一步，它构成了现代 AI 模型处理语言的基础
- **实践 token 优化**：在产品开发中，好的 token 管理能显著提升效果、降低成本
- **掌握向量表示**：理解如何将人类语言转化为机器可理解的数学形式

> 🚀 **下一步**：需要的话，我可以给你画一张「LLM 业务流程 ×token 交互点」的中文流程图，或者做一个小脚本帮你**计算具体文本在不同模型里的 token 数**并给出费用/延迟估算。

---

## 📚 延伸阅读

### 🔗 AI 大模型系统教程系列

1. **[本文] AI 大模型完全指南** - 从零基础到 Token 与向量的深度解析
2. **[Transformer 架构深度解析]({{< ref "/posts/note/AI教程2.md" >}})** - 注意力机制与 AI 大模型的核心技术
3. **[Prompt Engineering 完全指南]({{< ref "/posts/note/AI教程3.md" >}})** - 从提示工程到上下文工程的实战教程
4. **[AI 专业名词解释表]({{< ref "/posts/note/AI专业名词解释表.md" >}})** - 270+术语完全指南与 AI 技术体系词典

### 🎯 建议学习路径

- **初学者**：先阅读本文掌握基础概念，然后查看专业名词解释表巩固术语
- **开发者**：学习完本文后，重点阅读 Prompt Engineering 实战教程
- **研究者**：深入学习 Transformer 架构，掌握 AI 核心技术原理

