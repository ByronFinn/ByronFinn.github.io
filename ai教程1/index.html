<!doctype html><html lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>AI大模型完全指南：从零基础到Token与向量的深度解析 - 每日深度思考 | 技术、经济分析与深度思考</title><meta name=Description content="AI大模型完全指南：从零基础到Token与向量的深度解析。系统学习AI核心技术原理，包括Token机制、向量表示、Transformer架构等关键概念。深入理解LLM工作机制，掌握人工智能基础理论，通过实例和图表详细阐述AI应用开发的核心要点，为深度学习和AI实践奠定扎实基础。"><meta property="og:url" content="https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B1/"><meta property="og:site_name" content="每日深度思考 | 技术、经济分析与深度思考"><meta property="og:title" content="AI大模型完全指南：从零基础到Token与向量的深度解析"><meta property="og:description" content="AI大模型完全指南：从零基础到Token与向量的深度解析。系统学习AI核心技术原理，包括Token机制、向量表示、Transformer架构等关键概念。深入理解LLM工作机制，掌握人工智能基础理论，通过实例和图表详细阐述AI应用开发的核心要点，为深度学习和AI实践奠定扎实基础。"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-11-05T08:58:24+08:00"><meta property="article:modified_time" content="2025-11-06T13:19:28+08:00"><meta property="article:tag" content="AI大模型"><meta property="article:tag" content="LLM"><meta property="article:tag" content="Token机制"><meta property="article:tag" content="向量表示"><meta property="article:tag" content="Transformer架构"><meta property="article:tag" content="深度学习"><meta property="og:image" content="https://byronfinn.github.io/static/avatar/angryCat.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://byronfinn.github.io/static/avatar/angryCat.png"><meta name=twitter:title content="AI大模型完全指南：从零基础到Token与向量的深度解析"><meta name=twitter:description content="AI大模型完全指南：从零基础到Token与向量的深度解析。系统学习AI核心技术原理，包括Token机制、向量表示、Transformer架构等关键概念。深入理解LLM工作机制，掌握人工智能基础理论，通过实例和图表详细阐述AI应用开发的核心要点，为深度学习和AI实践奠定扎实基础。"><meta name=application-name content="Daily Deep Think"><meta name=apple-mobile-web-app-title content="Daily Deep Think"><meta name=theme-color content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel=icon href=/static/icos/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B1/><link rel=prev href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B2/><link rel=stylesheet href=/css/main.min.css><link rel=stylesheet href=/css/style.min.css><meta name=google-site-verification content="google8f3e688b6959e353"><meta name=msvalidate.01 content="请在此添加你的Bing验证码"><meta name=yandex-verification content="请在此添加你的Yandex验证码"><meta name=p:domain_verify content="请在此添加你的Pinterest验证码"><meta name=baidu-site-verification content="请在此添加你的百度验证码"><meta name=sogou_site_verification content="请在此添加你的搜狗验证码"><meta name=360-site-verification content="请在此添加你的360搜索验证码"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"AI大模型完全指南：从零基础到Token与向量的深度解析","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B1/"},"image":["https://byronfinn.github.io/static/avatar/angryCat.png"],"genre":"posts","keywords":["AI大模型","LLM","Token","向量","Transformer","人工智能","深度学习","机器学习","神经网络","AI教程"],"wordcount":4245,"url":"https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B1/","datePublished":"2025-11-05T08:58:24+08:00","dateModified":"2025-11-06T13:19:28+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Finn","url":"https://blog.baifan.site"},"description":"AI大模型完全指南：从零基础到Token与向量的深度解析。系统学习AI核心技术原理，包括Token机制、向量表示、Transformer架构等关键概念。深入理解LLM工作机制，掌握人工智能基础理论，通过实例和图表详细阐述AI应用开发的核心要点，为深度学习和AI实践奠定扎实基础。"}</script></head><body data-instant-intensity=viewport class="tw-flex tw-min-h-screen tw-flex-col"><script>function setTheme(e){document.body.setAttribute("theme",e),document.documentElement.className=e,document.documentElement.style.setProperty("color-scheme",e==="light"?"light":"dark"),e==="light"?document.documentElement.classList.remove("tw-dark"):document.documentElement.classList.add("tw-dark"),window.theme=e,window.isDark=window.theme!=="light"}function saveTheme(e){window.localStorage&&localStorage.setItem("theme",e)}function getMeta(e){const t=document.getElementsByTagName("meta");for(let n=0;n<t.length;n++)if(t[n].getAttribute("name")===e)return t[n];return""}if(window.localStorage&&localStorage.getItem("theme")){let e=localStorage.getItem("theme");e==="light"||e==="dark"?setTheme(e):setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")}else"auto"==="light"||"auto"==="dark"?(setTheme("auto"),saveTheme("auto")):(saveTheme("auto"),setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"));let metaColors={light:"#f8f8f8",dark:"#161b22"};getMeta("theme-color").content=metaColors[document.body.getAttribute("theme")],window.switchThemeEventSet=new Set</script><div id=back-to-top></div><div id=mask></div><header class="desktop print:!tw-hidden" id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="每日深度思考 | 技术、经济分析与深度思考"><span id=desktop-header-typeit class=typeit></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/profile/ title=了解我的个人信息和专业背景>关于我 </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder=搜索... id=search-input-desktop>
<button class="search-button search-toggle" id=search-toggle-desktop title=搜索>
<svg class="icon" viewBox="0 0 512 512"><path d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</button>
<button class="search-button search-clear" id=search-clear-desktop title=清空>
<svg class="icon" viewBox="0 0 512 512"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm121.6 313.1c4.7 4.7 4.7 12.3.0 17L338 377.6c-4.7 4.7-12.3 4.7-17 0L256 312l-65.1 65.6c-4.7 4.7-12.3 4.7-17 0L134.4 338c-4.7-4.7-4.7-12.3.0-17l65.6-65-65.6-65.1c-4.7-4.7-4.7-12.3.0-17l39.6-39.6c4.7-4.7 12.3-4.7 17 0l65 65.7 65.1-65.6c4.7-4.7 12.3-4.7 17 0l39.6 39.6c4.7 4.7 4.7 12.3.0 17L312 256l65.6 65.1z"/></svg>
</button>
<span class="search-button search-loading tw-animate-spin" id=search-loading-desktop><svg class="icon" viewBox="0 0 512 512"><path d="M304 48c0 26.51-21.49 48-48 48s-48-21.49-48-48 21.49-48 48-48 48 21.49 48 48zm-48 368c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm208-208c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zM96 256c0-26.51-21.49-48-48-48S0 229.49.0 256s21.49 48 48 48 48-21.49 48-48zm12.922 99.078c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.491-48-48-48zm294.156.0c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.49-48-48-48zM108.922 60.922c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.491-48-48-48z"/></svg>
</span></span><button class="menu-item theme-switch" aria-label=切换主题>
<svg class="icon" viewBox="0 0 512 512"><path d="M8 256c0 136.966 111.033 248 248 248s248-111.034 248-248S392.966 8 256 8 8 119.033 8 256zm248 184V72c101.705.0 184 82.311 184 184 0 101.705-82.311 184-184 184z"/></svg></button></div></div></div></header><header class="mobile print:!tw-hidden" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="每日深度思考 | 技术、经济分析与深度思考"><span id=mobile-header-typeit class=typeit></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索... id=search-input-mobile>
<button class="search-button search-toggle tw-h-10" id=search-toggle-mobile title=搜索>
<svg class="icon" viewBox="0 0 512 512"><path d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</button>
<button class="search-button search-clear tw-h-fit" id=search-clear-mobile title=清空>
<svg class="icon" viewBox="0 0 512 512"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm121.6 313.1c4.7 4.7 4.7 12.3.0 17L338 377.6c-4.7 4.7-12.3 4.7-17 0L256 312l-65.1 65.6c-4.7 4.7-12.3 4.7-17 0L134.4 338c-4.7-4.7-4.7-12.3.0-17l65.6-65-65.6-65.1c-4.7-4.7-4.7-12.3.0-17l39.6-39.6c4.7-4.7 12.3-4.7 17 0l65 65.7 65.1-65.6c4.7-4.7 12.3-4.7 17 0l39.6 39.6c4.7 4.7 4.7 12.3.0 17L312 256l65.6 65.1z"/></svg>
</button>
<span class="search-button search-loading tw-animate-spin" id=search-loading-mobile><svg class="icon" viewBox="0 0 512 512"><path d="M304 48c0 26.51-21.49 48-48 48s-48-21.49-48-48 21.49-48 48-48 48 21.49 48 48zm-48 368c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm208-208c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zM96 256c0-26.51-21.49-48-48-48S0 229.49.0 256s21.49 48 48 48 48-21.49 48-48zm12.922 99.078c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.491-48-48-48zm294.156.0c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48c0-26.509-21.49-48-48-48zM108.922 60.922c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.491-48-48-48z"/></svg></span></div><button class=search-cancel id=search-cancel-mobile>
取消</button></div><a class=menu-item href=/posts/ title>文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/profile/ title=了解我的个人信息和专业背景>关于我</a><button class="menu-item theme-switch tw-w-full" aria-label=切换主题>
<svg class="icon" viewBox="0 0 512 512"><path d="M8 256c0 136.966 111.033 248 248 248s248-111.034 248-248S392.966 8 256 8 8 119.033 8 256zm248 184V72c101.705.0 184 82.311 184 184 0 101.705-82.311 184-184 184z"/></svg></button></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class="tw-mx-4 tw-flex-1"><dialog id=toc-dialog class="tw-max-w-full tw-w-full tw-max-h-full tw-h-full tw-ml-16"><div class="toc tw-mx-4 tw-max-w-full"><h2 class="tw-mx-0 tw-my-6 tw-uppercase tw-text-2xl">目录</h2><div class=toc-content><nav id=TableOfContents><ul><li><a href=#一ai应用开发基础>一、AI应用开发基础</a><ul><li><a href=#11-基本原理与概念>1.1 基本原理与概念</a><ul><li><a href=#通俗理解>通俗理解</a></li><li><a href=#进阶理解>进阶理解</a></li><li><a href=#核心技术组件>核心技术组件</a></li></ul></li></ul></li><li><a href=#二核心概念解析>二、核心概念解析</a><ul><li><a href=#21-基本术语>2.1 基本术语</a></li><li><a href=#22-模型与应用的关系>2.2 模型与应用的关系</a></li></ul></li><li><a href=#三tokenai语言的最小单位>三、Token：AI语言的最小单位</a><ul><li><a href=#31-什么是token>3.1 什么是Token？</a><ul><li><a href=#token的切分特点>Token的切分特点</a></li></ul></li><li><a href=#32-token是如何切出来的>3.2 Token是如何切出来的？</a></li><li><a href=#33-token与产品的关系>3.3 Token与产品的关系</a><ul><li><a href=#-token估算经验>📊 Token估算经验</a></li></ul></li></ul></li><li><a href=#四向量ai理解的基石>四、向量：AI理解的基石</a><ul><li><a href=#41-什么是向量>4.1 什么是向量？</a></li><li><a href=#42--几何意义举例>4.2 🧭 几何意义举例</a></li><li><a href=#43--从特征的角度理解>4.3 💡 从特征的角度理解</a><ul><li><a href=#举例-1颜色向量>举例 1：颜色向量</a></li><li><a href=#举例-2人类特征向量>举例 2：人类特征向量</a></li><li><a href=#举例-3词语的语义向量>举例 3：词语的语义向量</a></li></ul></li></ul></li><li><a href=#五llm业务流程中的token管理>五、LLM业务流程中的Token管理</a><ul><li><a href=#51-完整业务流程>5.1 完整业务流程</a><ul><li><a href=#1-用户输入>1. 用户输入</a></li><li><a href=#2-预处理清洗结构化>2. 预处理（清洗/结构化）</a></li><li><a href=#3-检索可选rag>3. 检索（可选：RAG）</a></li><li><a href=#4-拼装最终prompt输入序列>4. 拼装最终Prompt（输入序列）</a></li><li><a href=#5-模型前向与生成循环decoding>5. 模型前向与生成循环（Decoding）</a></li><li><a href=#6-反分词detokenization>6. 反分词（Detokenization）</a></li><li><a href=#7-后处理post-processing>7. 后处理（Post-processing）</a></li><li><a href=#8-日志与计费>8. 日志与计费</a></li></ul></li><li><a href=#52--实际案例分析>5.2 🎯 实际案例分析</a><ul><li><a href=#案例1为什么长上下文不等于高质量>案例1：为什么"长上下文"不等于"高质量"</a></li><li><a href=#案例2控制成本与延迟>案例2：控制成本与延迟</a></li><li><a href=#案例3中英token体感差异>案例3：中英token体感差异</a></li></ul></li><li><a href=#53--产品工程实操建议>5.3 🛠️ 产品/工程实操建议</a><ul><li><a href=#核心策略>核心策略</a></li></ul></li></ul></li><li><a href=#六-核心要点总结>六、🧠 核心要点总结</a><ul><li><a href=#61-关键概念对照>6.1 关键概念对照</a></li><li><a href=#62-学习要点回顾>6.2 学习要点回顾</a></li><li><a href=#63--学习建议>6.3 💡 学习建议</a></li></ul></li><li><a href=#-延伸阅读>📚 延伸阅读</a><ul><li><a href=#-ai大模型系统教程系列>🔗 AI大模型系统教程系列</a></li><li><a href=#-建议学习路径>🎯 建议学习路径</a></li></ul></li></ul></nav></div></div></dialog><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC","false")</script><article class="page single print:!tw-w-full print:!tw-max-w-none print:!tw-m-0 print:!tw-p-0"><h1 class=single-title data-pagefind-meta=date:2025-11-05 data-pagefind-body>AI大模型完全指南：从零基础到Token与向量的深度解析</h1><div class=post-meta><div class=post-meta-line><span class=post-author><img class="tw-inline-block tw-max-h-4 tw-rounded-full tw-translate-y-[-2px] tw-mr-1" src=/static/avatar/angryCat.png alt="Finn avatar" height=16 width=16><a href=https://blog.baifan.site title=Author target=_blank rel="noopener noreferrer author" class=author>Finn</a>
</span>&nbsp;<span class=post-category>收录于 </span>&nbsp;<span class=post-category>类别 <a href=/categories/ai%E6%95%99%E7%A8%8B/><svg class="icon" viewBox="0 0 512 512"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49.0 112v288c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>AI教程</a>&nbsp;<a href=/categories/%E6%8A%80%E6%9C%AF%E6%B7%B1%E5%BA%A6/><svg class="icon" viewBox="0 0 512 512"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49.0 112v288c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>技术深度</a>&nbsp;<a href=/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/><svg class="icon" viewBox="0 0 512 512"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49.0 112v288c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>人工智能</a></span>&nbsp;<span class=post-category>和</span>&nbsp;<span class=post-series>系列 <a href><svg class="icon" viewBox="0 0 512 512"><path d="M464 32H48C21.49 32 0 53.49.0 80v352c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V80c0-26.51-21.49-48-48-48zm-6 4e2H54a6 6 0 01-6-6V86a6 6 0 016-6h404a6 6 0 016 6v340a6 6 0 01-6 6zm-42-92v24c0 6.627-5.373 12-12 12H204c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h2e2c6.627.0 12 5.373 12 12zm0-96v24c0 6.627-5.373 12-12 12H204c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h2e2c6.627.0 12 5.373 12 12zm0-96v24c0 6.627-5.373 12-12 12H204c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h2e2c6.627.0 12 5.373 12 12zm-252 12c0 19.882-16.118 36-36 36s-36-16.118-36-36 16.118-36 36-36 36 16.118 36 36zm0 96c0 19.882-16.118 36-36 36s-36-16.118-36-36 16.118-36 36-36 36 16.118 36 36zm0 96c0 19.882-16.118 36-36 36s-36-16.118-36-36 16.118-36 36-36 36 16.118 36 36z"/></svg></a></span></div><div class=post-meta-line><svg class="icon" viewBox="0 0 448 512"><path d="M148 288h-40c-6.6.0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h48c26.5.0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3.0 6-2.7 6-6z"/></svg>&nbsp;<time datetime=2025-11-05>2025-11-05</time>&nbsp;<svg class="icon" viewBox="0 0 576 512"><path d="M402.3 344.9l32-32c5-5 13.7-1.5 13.7 5.7V464c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h273.5c7.1.0 10.7 8.6 5.7 13.7l-32 32c-1.5 1.5-3.5 2.3-5.7 2.3H48v352h352V350.5c0-2.1.8-4.1 2.3-5.6zm156.6-201.8L296.3 405.7l-90.4 10c-26.2 2.9-48.5-19.2-45.6-45.6l10-90.4L432.9 17.1c22.9-22.9 59.9-22.9 82.7.0l43.2 43.2c22.9 22.9 22.9 60 .1 82.8zM460.1 174 402 115.9 216.2 301.8l-7.3 65.3 65.3-7.3L460.1 174zm64.8-79.7-43.2-43.2c-4.1-4.1-10.8-4.1-14.8.0L436 82l58.1 58.1 30.9-30.9c4-4.2 4-10.8-.1-14.9z"/></svg>&nbsp;<time datetime=2025-11-06>2025-11-06</time>&nbsp;<svg class="icon" viewBox="0 0 512 512"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3.0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9.0l60.1 60.1c18.8 18.7 18.8 49.1.0 67.9zM284.2 99.8 21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3.0-17l-111-111c-4.8-4.7-12.4-4.7-17.1.0zM124.1 339.9c-5.5-5.5-5.5-14.3.0-19.8l154-154c5.5-5.5 14.3-5.5 19.8.0s5.5 14.3.0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8.0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg>&nbsp;约 4245 字&nbsp;
<svg class="icon" viewBox="0 0 512 512"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5.0-2e2-89.5-2e2-2e2S145.5 56 256 56s2e2 89.5 2e2 2e2-89.5 2e2-2e2 2e2zm61.8-104.4-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6.0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"/></svg>&nbsp;预计阅读 19 分钟&nbsp;</div></div><div class="details toc print:!tw-block" id=toc-static kept=true><div class="details-summary toc-title"><span>目录</span>
<span class=details-icon><svg class="icon" viewBox="0 0 256 512"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9.0l-22.6-22.6c-9.4-9.4-9.4-24.6.0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6.0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9.0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#一ai应用开发基础>一、AI应用开发基础</a><ul><li><a href=#11-基本原理与概念>1.1 基本原理与概念</a><ul><li><a href=#通俗理解>通俗理解</a></li><li><a href=#进阶理解>进阶理解</a></li><li><a href=#核心技术组件>核心技术组件</a></li></ul></li></ul></li><li><a href=#二核心概念解析>二、核心概念解析</a><ul><li><a href=#21-基本术语>2.1 基本术语</a></li><li><a href=#22-模型与应用的关系>2.2 模型与应用的关系</a></li></ul></li><li><a href=#三tokenai语言的最小单位>三、Token：AI语言的最小单位</a><ul><li><a href=#31-什么是token>3.1 什么是Token？</a><ul><li><a href=#token的切分特点>Token的切分特点</a></li></ul></li><li><a href=#32-token是如何切出来的>3.2 Token是如何切出来的？</a></li><li><a href=#33-token与产品的关系>3.3 Token与产品的关系</a><ul><li><a href=#-token估算经验>📊 Token估算经验</a></li></ul></li></ul></li><li><a href=#四向量ai理解的基石>四、向量：AI理解的基石</a><ul><li><a href=#41-什么是向量>4.1 什么是向量？</a></li><li><a href=#42--几何意义举例>4.2 🧭 几何意义举例</a></li><li><a href=#43--从特征的角度理解>4.3 💡 从特征的角度理解</a><ul><li><a href=#举例-1颜色向量>举例 1：颜色向量</a></li><li><a href=#举例-2人类特征向量>举例 2：人类特征向量</a></li><li><a href=#举例-3词语的语义向量>举例 3：词语的语义向量</a></li></ul></li></ul></li><li><a href=#五llm业务流程中的token管理>五、LLM业务流程中的Token管理</a><ul><li><a href=#51-完整业务流程>5.1 完整业务流程</a><ul><li><a href=#1-用户输入>1. 用户输入</a></li><li><a href=#2-预处理清洗结构化>2. 预处理（清洗/结构化）</a></li><li><a href=#3-检索可选rag>3. 检索（可选：RAG）</a></li><li><a href=#4-拼装最终prompt输入序列>4. 拼装最终Prompt（输入序列）</a></li><li><a href=#5-模型前向与生成循环decoding>5. 模型前向与生成循环（Decoding）</a></li><li><a href=#6-反分词detokenization>6. 反分词（Detokenization）</a></li><li><a href=#7-后处理post-processing>7. 后处理（Post-processing）</a></li><li><a href=#8-日志与计费>8. 日志与计费</a></li></ul></li><li><a href=#52--实际案例分析>5.2 🎯 实际案例分析</a><ul><li><a href=#案例1为什么长上下文不等于高质量>案例1：为什么"长上下文"不等于"高质量"</a></li><li><a href=#案例2控制成本与延迟>案例2：控制成本与延迟</a></li><li><a href=#案例3中英token体感差异>案例3：中英token体感差异</a></li></ul></li><li><a href=#53--产品工程实操建议>5.3 🛠️ 产品/工程实操建议</a><ul><li><a href=#核心策略>核心策略</a></li></ul></li></ul></li><li><a href=#六-核心要点总结>六、🧠 核心要点总结</a><ul><li><a href=#61-关键概念对照>6.1 关键概念对照</a></li><li><a href=#62-学习要点回顾>6.2 学习要点回顾</a></li><li><a href=#63--学习建议>6.3 💡 学习建议</a></li></ul></li><li><a href=#-延伸阅读>📚 延伸阅读</a><ul><li><a href=#-ai大模型系统教程系列>🔗 AI大模型系统教程系列</a></li><li><a href=#-建议学习路径>🎯 建议学习路径</a></li></ul></li></ul></nav></div></div><div class=content id=content data-pagefind-body><h1 id=ai教程从基础到深入的ai大模型指南 class=headerLink><a href=#ai%e6%95%99%e7%a8%8b%e4%bb%8e%e5%9f%ba%e7%a1%80%e5%88%b0%e6%b7%b1%e5%85%a5%e7%9a%84ai%e5%a4%a7%e6%a8%a1%e5%9e%8b%e6%8c%87%e5%8d%97 class=header-mark></a>AI教程：从基础到深入的AI大模型指南</h1><p>本文将带你深入理解AI大模型的核心概念，从基本原理到向量表示，循序渐进地构建完整的知识体系。</p><hr><h2 id=一ai应用开发基础 class=headerLink><a href=#%e4%b8%80ai%e5%ba%94%e7%94%a8%e5%bc%80%e5%8f%91%e5%9f%ba%e7%a1%80 class=header-mark></a>一、AI应用开发基础</h2><h3 id=11-基本原理与概念 class=headerLink><a href=#11-%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86%e4%b8%8e%e6%a6%82%e5%bf%b5 class=header-mark></a>1.1 基本原理与概念</h3><h4 id=通俗理解 class=headerLink><a href=#%e9%80%9a%e4%bf%97%e7%90%86%e8%a7%a3 class=header-mark></a>通俗理解</h4><ul><li><strong>核心机制</strong>：根据上一个词预测下一个词，类似成语接龙</li><li><strong>工作方式</strong>：通过token逐字生成输出</li></ul><h4 id=进阶理解 class=headerLink><a href=#%e8%bf%9b%e9%98%b6%e7%90%86%e8%a7%a3 class=header-mark></a>进阶理解</h4><p>AI大模型包含两个关键阶段：</p><div class=table-wrapper><table><thead><tr><th style=text-align:>阶段</th><th style=text-align:>比喻</th><th style=text-align:>具体作用</th></tr></thead><tbody><tr><td style=text-align:><strong>训练</strong></td><td style=text-align:>&ldquo;学习&rdquo;</td><td style=text-align:>阅读海量数据构建模型，形成知识储备</td></tr><tr><td style=text-align:><strong>推理</strong></td><td style=text-align:>&ldquo;应用&rdquo;</td><td style=text-align:>根据输入生成响应，提供服务能力</td></tr></tbody></table></div><h4 id=核心技术组件 class=headerLink><a href=#%e6%a0%b8%e5%bf%83%e6%8a%80%e6%9c%af%e7%bb%84%e4%bb%b6 class=header-mark></a>核心技术组件</h4><ul><li><p><strong>Transformer架构</strong></p><ul><li>由encoder编码器 + decoder解码器组成</li><li>核心是注意力机制，实现高效的信息处理</li></ul></li><li><p><strong>Embedding与位置编码</strong></p><ul><li>将文字转换为计算机可处理的数字向量</li><li>加入顺序信息，理解语言的时序关系</li></ul></li><li><p><strong>多头注意力机制</strong></p><ul><li>核心计算步骤</li><li>决定哪些内容更重要，从而影响输出结果</li></ul></li></ul><hr><h2 id=二核心概念解析 class=headerLink><a href=#%e4%ba%8c%e6%a0%b8%e5%bf%83%e6%a6%82%e5%bf%b5%e8%a7%a3%e6%9e%90 class=header-mark></a>二、核心概念解析</h2><h3 id=21-基本术语 class=headerLink><a href=#21-%e5%9f%ba%e6%9c%ac%e6%9c%af%e8%af%ad class=header-mark></a>2.1 基本术语</h3><ul><li><strong>AGI（通用人工智能）</strong>：大模型的最终目标，具备人类水平的智能</li><li><strong>LLM（Large Language Model）</strong>：大语言模型的简称</li><li><strong>对话产品 vs 大模型</strong>：应用层与模型层的区别</li></ul><h3 id=22-模型与应用的关系 class=headerLink><a href=#22-%e6%a8%a1%e5%9e%8b%e4%b8%8e%e5%ba%94%e7%94%a8%e7%9a%84%e5%85%b3%e7%b3%bb class=header-mark></a>2.2 模型与应用的关系</h3><div class=table-wrapper><table><thead><tr><th style=text-align:>比喻</th><th style=text-align:>概念</th><th style=text-align:>作用</th></tr></thead><tbody><tr><td style=text-align:>大脑</td><td style=text-align:>大模型</td><td style=text-align:>拥有强大的理解与生成能力</td></tr><tr><td style=text-align:>应用/产品</td><td style=text-align:>对话产品</td><td style=text-align:>让普通人能方便、安全地使用大模型</td></tr></tbody></table></div><hr><h2 id=三tokenai语言的最小单位 class=headerLink><a href=#%e4%b8%89tokenai%e8%af%ad%e8%a8%80%e7%9a%84%e6%9c%80%e5%b0%8f%e5%8d%95%e4%bd%8d class=header-mark></a>三、Token：AI语言的最小单位</h2><h3 id=31-什么是token class=headerLink><a href=#31-%e4%bb%80%e4%b9%88%e6%98%aftoken class=header-mark></a>3.1 什么是Token？</h3><blockquote><p><strong>token = 模型处理文本的最小单位。</strong>
它既不是严格的"字"，也不是固定的"词"，而是通过一种压缩规则把文本切成的片段。</p></blockquote><h4 id=token的切分特点 class=headerLink><a href=#token%e7%9a%84%e5%88%87%e5%88%86%e7%89%b9%e7%82%b9 class=header-mark></a>Token的切分特点</h4><ul><li><p><strong>英文</strong>：常被切成<strong>词片段</strong></p><ul><li><code>"I love apples"</code> → <code>["I", " love", " apple", "s"]</code></li></ul></li><li><p><strong>中文</strong>：常按<strong>字或短词</strong>切</p><ul><li><code>"我喜欢苹果"</code> → <code>["我", "喜欢", "苹果"]</code></li><li><em>（具体切分粒度取决于分词器）</em></li></ul></li><li><p><strong>特殊Token</strong>：如开始/结束标记、换行、工具调用边界等</p></li></ul><blockquote><p>💡 <strong>直觉理解</strong>：token 像"AI的字粒子"，模型是<strong>一个token一个token</strong>地读入和生成。</p></blockquote><h3 id=32-token是如何切出来的 class=headerLink><a href=#32-token%e6%98%af%e5%a6%82%e4%bd%95%e5%88%87%e5%87%ba%e6%9d%a5%e7%9a%84 class=header-mark></a>3.2 Token是如何切出来的？</h3><p>大多数LLM使用<strong>BPE/Unigram</strong>等算法：</p><ul><li>找到文本里最常见的字符组合，给它们分配一个"词表ID"</li><li>这样既能表示单个字符，也能表示常见词或词片段</li><li>兼顾<strong>效率</strong>（更少token）和<strong>泛化</strong>（罕见词能被拆开）</li></ul><blockquote><p>⚠️ <strong>重要提示</strong>：同一句话在不同模型/词表下，<strong>token数可能不同</strong>。</p></blockquote><h3 id=33-token与产品的关系 class=headerLink><a href=#33-token%e4%b8%8e%e4%ba%a7%e5%93%81%e7%9a%84%e5%85%b3%e7%b3%bb class=header-mark></a>3.3 Token与产品的关系</h3><div class=table-wrapper><table><thead><tr><th style=text-align:>影响因素</th><th style=text-align:>具体表现</th><th style=text-align:>优化策略</th></tr></thead><tbody><tr><td style=text-align:><strong>长度限制</strong></td><td style=text-align:>模型一次能读/记住的token总数有上限</td><td style=text-align:>截断或分批检索</td></tr><tr><td style=text-align:><strong>费用</strong></td><td style=text-align:>绝大多数商用LLM按<strong>token数计费</strong></td><td style=text-align:>优化提示词，减少无效token</td></tr><tr><td style=text-align:><strong>速度</strong></td><td style=text-align:>输出是逐token流式生成</td><td style=text-align:>控制输出长度，减少延迟</td></tr><tr><td style=text-align:><strong>质量</strong></td><td style=text-align:>合理控制token能显著提升效果</td><td style=text-align:>清理提示词，优化检索内容</td></tr></tbody></table></div><h4 id=-token估算经验 class=headerLink><a href=#-token%e4%bc%b0%e7%ae%97%e7%bb%8f%e9%aa%8c class=header-mark></a>📊 Token估算经验</h4><ul><li><strong>英文</strong>：~3-4个词 ≈ 1个token（100token ≈ 75英文词）</li><li><strong>中文</strong>：1字/词 ≈ 0.6个token（因词表不同会有浮动）</li><li><strong>注意事项</strong>：真实计数以具体模型的分词器为准</li></ul><hr><h2 id=四向量ai理解的基石 class=headerLink><a href=#%e5%9b%9b%e5%90%91%e9%87%8fai%e7%90%86%e8%a7%a3%e7%9a%84%e5%9f%ba%e7%9f%b3 class=header-mark></a>四、向量：AI理解的基石</h2><h3 id=41-什么是向量 class=headerLink><a href=#41-%e4%bb%80%e4%b9%88%e6%98%af%e5%90%91%e9%87%8f class=header-mark></a>4.1 什么是向量？</h3><blockquote><p>向量（Vector）在数学里指的是：一个有<strong>大小</strong>和<strong>方向</strong>的量，或者更一般地说，是一组有顺序的数字。</p></blockquote><p>最简单的向量可以写成：</p><div class="code-block highlight is-open show-line-numbers tw-group tw-my-2"><div class="tw-flex
tw-flex-row
tw-flex-1
tw-justify-between
tw-w-full tw-bg-bgColor-secondary"><button class="code-block-button
tw-mx-2
tw-flex
tw-flex-row
tw-flex-1" aria-hidden=true><div class="group-[.is-open]:tw-rotate-90 tw-transition-[transform] tw-duration-500 tw-ease-in-out print:!tw-hidden tw-w-min tw-h-min tw-my-1 tw-mx-1"><svg class="icon" viewBox="0 0 320 512"><path d="M285.476 272.971 91.132 467.314c-9.373 9.373-24.569 9.373-33.941.0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941.0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z"/></svg></div><p class="tw-select-none !tw-my-1">plaintext</p></button><div class=tw-flex><button class="line-number-button
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
group-[.show-line-numbers]:tw-text-fgColor-link
print:!tw-hidden" title="Toggle line numbers"><svg class="icon" viewBox="0 0 512 512"><path d="M61.77 401l17.5-20.15a19.92 19.92.0 005.07-14.19v-3.31C84.34 356 80.5 352 73 352H16a8 8 0 00-8 8v16a8 8 0 008 8h22.83a157.41 157.41.0 00-11 12.31l-5.61 7c-4 5.07-5.25 10.13-2.8 14.88l1.05 1.93c3 5.76 6.29 7.88 12.25 7.88h4.73c10.33.0 15.94 2.44 15.94 9.09.0 4.72-4.2 8.22-14.36 8.22a41.54 41.54.0 01-15.47-3.12c-6.49-3.88-11.74-3.5-15.6 3.12l-5.59 9.31c-3.72 6.13-3.19 11.72 2.63 15.94 7.71 4.69 20.38 9.44 37 9.44 34.16.0 48.5-22.75 48.5-44.12-.03-14.38-9.12-29.76-28.73-34.88zM496 224H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16v-32a16 16 0 00-16-16zm0-160H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16V80a16 16 0 00-16-16zm0 320H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16v-32a16 16 0 00-16-16zM16 160h64a8 8 0 008-8v-16a8 8 0 00-8-8H64V40a8 8 0 00-8-8H32a8 8 0 00-7.14 4.42l-8 16A8 8 0 0024 64h8v64H16a8 8 0 00-8 8v16a8 8 0 008 8zm-3.91 160H80a8 8 0 008-8v-16a8 8 0 00-8-8H41.32c3.29-10.29 48.34-18.68 48.34-56.44.0-29.06-25-39.56-44.47-39.56-21.36.0-33.8 10-40.46 18.75-4.37 5.59-3 10.84 2.8 15.37l8.58 6.88c5.61 4.56 11 2.47 16.12-2.44a13.44 13.44.0 019.46-3.84c3.33.0 9.28 1.56 9.28 8.75C51 248.19.0 257.31.0 304.59v4C0 316 5.08 320 12.09 320z"/></svg></button>
<button class="wrap-code-button
tw-select-none
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
group-[.is-wrap]:tw-text-fgColor-link
print:!tw-hidden" title="Toggle code wrap"><svg class="icon" viewBox="0 0 448 512"><path d="M16 132h416c8.837.0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163.0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"/></svg></button>
<button class="copy-code-button
tw-select-none
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
hover:tw-text-fgColor-link
print:!tw-hidden" title="Copy code">
<span class="copy-icon tw-block"><svg class="icon" viewBox="0 0 448 512"><path d="M433.941 65.941l-51.882-51.882A48 48 0 00348.118.0H176c-26.51.0-48 21.49-48 48v48H48c-26.51.0-48 21.49-48 48v320c0 26.51 21.49 48 48 48h224c26.51.0 48-21.49 48-48v-48h80c26.51.0 48-21.49 48-48V99.882a48 48 0 00-14.059-33.941zM266 464H54a6 6 0 01-6-6V150a6 6 0 016-6h74v224c0 26.51 21.49 48 48 48h96v42a6 6 0 01-6 6zm128-96H182a6 6 0 01-6-6V54a6 6 0 016-6h106v88c0 13.255 10.745 24 24 24h88v202a6 6 0 01-6 6zm6-256h-64V48h9.632c1.591.0 3.117.632 4.243 1.757l48.368 48.368a6 6 0 011.757 4.243V112z"/></svg></span>
<span class="check-icon tw-hidden"><svg class="icon" viewBox="0 0 512 512"><path d="M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206.0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204.0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204.0l36.203 36.204c9.997 9.997 9.997 26.206.0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z"/></svg></span>
</button>
<button class="tw-select-none
tw-mx-2
tw-block
group-[.is-open]:tw-hidden
print:!tw-hidden" disabled aria-hidden=true><svg class="icon" viewBox="0 0 512 512"><path d="M328 256c0 39.8-32.2 72-72 72s-72-32.2-72-72 32.2-72 72-72 72 32.2 72 72zm104-72c-39.8.0-72 32.2-72 72s32.2 72 72 72 72-32.2 72-72-32.2-72-72-72zm-352 0c-39.8.0-72 32.2-72 72s32.2 72 72 72 72-32.2 72-72-32.2-72-72-72z"/></svg></button></div></div><pre style=counter-reset:codeblock class="tw-block tw-m-0 tw-p-0"><code id=codeblock-id-1 class="chroma
!tw-block
tw-p-0
tw-m-0
tw-transition-[max-height]
tw-duration-500
tw-ease-in-out
group-[.is-closed]:!tw-max-h-0
group-[.is-wrap]:tw-text-wrap
tw-overflow-y-hidden
tw-overflow-x-auto
tw-scrollbar-thin"><span class=line><span class=cl>(2, 3)</span></span></code></pre></div><p>这代表：</p><ul><li>沿着 x 轴走 2 个单位</li><li>沿着 y 轴走 3 个单位</li></ul><p>它可以表示一个<strong>点的位置</strong>（相对于原点的偏移），也可以表示一个<strong>从原点出发的箭头（方向+长度）</strong>。</p><h3 id=42--几何意义举例 class=headerLink><a href=#42--%e5%87%a0%e4%bd%95%e6%84%8f%e4%b9%89%e4%b8%be%e4%be%8b class=header-mark></a>4.2 🧭 几何意义举例</h3><p>想象你在一个平面上走路：</p><ul><li>向量 <strong>(2, 3)</strong> 表示"向右走 2，向上走 3"</li><li>向量 <strong>(-1, 4)</strong> 表示"向左走 1，向上走 4"</li></ul><p>这些数字就像<strong>坐标</strong>，告诉你在空间中"往哪里去"。</p><p>📊 如果我们画出来：</p><ul><li>原点在 (0, 0)</li><li>终点在 (2, 3)
→ 这就是一个箭头指向的"向量"</li></ul><h3 id=43--从特征的角度理解 class=headerLink><a href=#43--%e4%bb%8e%e7%89%b9%e5%be%81%e7%9a%84%e8%a7%92%e5%ba%a6%e7%90%86%e8%a7%a3 class=header-mark></a>4.3 💡 从特征的角度理解</h3><p>当我们把这个概念应用到人工智能时，向量不仅仅是"位置"，还可以表示"特征"或"意义"。</p><h4 id=举例-1颜色向量 class=headerLink><a href=#%e4%b8%be%e4%be%8b-1%e9%a2%9c%e8%89%b2%e5%90%91%e9%87%8f class=header-mark></a>举例 1：颜色向量</h4><p>假设我们用 3 个数字表示颜色的红、绿、蓝成分：</p><div class="code-block highlight is-open show-line-numbers tw-group tw-my-2"><div class="tw-flex
tw-flex-row
tw-flex-1
tw-justify-between
tw-w-full tw-bg-bgColor-secondary"><button class="code-block-button
tw-mx-2
tw-flex
tw-flex-row
tw-flex-1" aria-hidden=true><div class="group-[.is-open]:tw-rotate-90 tw-transition-[transform] tw-duration-500 tw-ease-in-out print:!tw-hidden tw-w-min tw-h-min tw-my-1 tw-mx-1"><svg class="icon" viewBox="0 0 320 512"><path d="M285.476 272.971 91.132 467.314c-9.373 9.373-24.569 9.373-33.941.0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941.0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z"/></svg></div><p class="tw-select-none !tw-my-1">plaintext</p></button><div class=tw-flex><button class="line-number-button
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
group-[.show-line-numbers]:tw-text-fgColor-link
print:!tw-hidden" title="Toggle line numbers"><svg class="icon" viewBox="0 0 512 512"><path d="M61.77 401l17.5-20.15a19.92 19.92.0 005.07-14.19v-3.31C84.34 356 80.5 352 73 352H16a8 8 0 00-8 8v16a8 8 0 008 8h22.83a157.41 157.41.0 00-11 12.31l-5.61 7c-4 5.07-5.25 10.13-2.8 14.88l1.05 1.93c3 5.76 6.29 7.88 12.25 7.88h4.73c10.33.0 15.94 2.44 15.94 9.09.0 4.72-4.2 8.22-14.36 8.22a41.54 41.54.0 01-15.47-3.12c-6.49-3.88-11.74-3.5-15.6 3.12l-5.59 9.31c-3.72 6.13-3.19 11.72 2.63 15.94 7.71 4.69 20.38 9.44 37 9.44 34.16.0 48.5-22.75 48.5-44.12-.03-14.38-9.12-29.76-28.73-34.88zM496 224H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16v-32a16 16 0 00-16-16zm0-160H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16V80a16 16 0 00-16-16zm0 320H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16v-32a16 16 0 00-16-16zM16 160h64a8 8 0 008-8v-16a8 8 0 00-8-8H64V40a8 8 0 00-8-8H32a8 8 0 00-7.14 4.42l-8 16A8 8 0 0024 64h8v64H16a8 8 0 00-8 8v16a8 8 0 008 8zm-3.91 160H80a8 8 0 008-8v-16a8 8 0 00-8-8H41.32c3.29-10.29 48.34-18.68 48.34-56.44.0-29.06-25-39.56-44.47-39.56-21.36.0-33.8 10-40.46 18.75-4.37 5.59-3 10.84 2.8 15.37l8.58 6.88c5.61 4.56 11 2.47 16.12-2.44a13.44 13.44.0 019.46-3.84c3.33.0 9.28 1.56 9.28 8.75C51 248.19.0 257.31.0 304.59v4C0 316 5.08 320 12.09 320z"/></svg></button>
<button class="wrap-code-button
tw-select-none
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
group-[.is-wrap]:tw-text-fgColor-link
print:!tw-hidden" title="Toggle code wrap"><svg class="icon" viewBox="0 0 448 512"><path d="M16 132h416c8.837.0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163.0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"/></svg></button>
<button class="copy-code-button
tw-select-none
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
hover:tw-text-fgColor-link
print:!tw-hidden" title="Copy code">
<span class="copy-icon tw-block"><svg class="icon" viewBox="0 0 448 512"><path d="M433.941 65.941l-51.882-51.882A48 48 0 00348.118.0H176c-26.51.0-48 21.49-48 48v48H48c-26.51.0-48 21.49-48 48v320c0 26.51 21.49 48 48 48h224c26.51.0 48-21.49 48-48v-48h80c26.51.0 48-21.49 48-48V99.882a48 48 0 00-14.059-33.941zM266 464H54a6 6 0 01-6-6V150a6 6 0 016-6h74v224c0 26.51 21.49 48 48 48h96v42a6 6 0 01-6 6zm128-96H182a6 6 0 01-6-6V54a6 6 0 016-6h106v88c0 13.255 10.745 24 24 24h88v202a6 6 0 01-6 6zm6-256h-64V48h9.632c1.591.0 3.117.632 4.243 1.757l48.368 48.368a6 6 0 011.757 4.243V112z"/></svg></span>
<span class="check-icon tw-hidden"><svg class="icon" viewBox="0 0 512 512"><path d="M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206.0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204.0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204.0l36.203 36.204c9.997 9.997 9.997 26.206.0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z"/></svg></span>
</button>
<button class="tw-select-none
tw-mx-2
tw-block
group-[.is-open]:tw-hidden
print:!tw-hidden" disabled aria-hidden=true><svg class="icon" viewBox="0 0 512 512"><path d="M328 256c0 39.8-32.2 72-72 72s-72-32.2-72-72 32.2-72 72-72 72 32.2 72 72zm104-72c-39.8.0-72 32.2-72 72s32.2 72 72 72 72-32.2 72-72-32.2-72-72-72zm-352 0c-39.8.0-72 32.2-72 72s32.2 72 72 72 72-32.2 72-72-32.2-72-72-72z"/></svg></button></div></div><pre style=counter-reset:codeblock class="tw-block tw-m-0 tw-p-0"><code id=codeblock-id-2 class="chroma
!tw-block
tw-p-0
tw-m-0
tw-transition-[max-height]
tw-duration-500
tw-ease-in-out
group-[.is-closed]:!tw-max-h-0
group-[.is-wrap]:tw-text-wrap
tw-overflow-y-hidden
tw-overflow-x-auto
tw-scrollbar-thin"><span class=line><span class=cl>红色： (255, 0, 0)
</span></span><span class=line><span class=cl>绿色： (0, 255, 0)
</span></span><span class=line><span class=cl>蓝色： (0, 0, 255)</span></span></code></pre></div><p>这就是一个<strong>3维向量空间</strong>。每个颜色都能用一个三维点表示在空间中，这样我们就能"计算颜色之间的相似度"。</p><h4 id=举例-2人类特征向量 class=headerLink><a href=#%e4%b8%be%e4%be%8b-2%e4%ba%ba%e7%b1%bb%e7%89%b9%e5%be%81%e5%90%91%e9%87%8f class=header-mark></a>举例 2：人类特征向量</h4><p>假设我们想用数字来描述一个人：</p><div class=table-wrapper><table><thead><tr><th style=text-align:>特征</th><th style=text-align:>含义</th><th style=text-align:>数值</th></tr></thead><tbody><tr><td style=text-align:>年龄</td><td style=text-align:>岁数</td><td style=text-align:>25</td></tr><tr><td style=text-align:>身高</td><td style=text-align:>cm</td><td style=text-align:>180</td></tr><tr><td style=text-align:>体重</td><td style=text-align:>kg</td><td style=text-align:>70</td></tr></tbody></table></div><p>那么一个人可以表示为：<code>(25, 180, 70)</code></p><p>这也是一个三维向量。如果我们要比较两个人的相似程度，就可以用数学方式计算他们向量之间的距离。</p><p>比如：</p><div class="code-block highlight is-open show-line-numbers tw-group tw-my-2"><div class="tw-flex
tw-flex-row
tw-flex-1
tw-justify-between
tw-w-full tw-bg-bgColor-secondary"><button class="code-block-button
tw-mx-2
tw-flex
tw-flex-row
tw-flex-1" aria-hidden=true><div class="group-[.is-open]:tw-rotate-90 tw-transition-[transform] tw-duration-500 tw-ease-in-out print:!tw-hidden tw-w-min tw-h-min tw-my-1 tw-mx-1"><svg class="icon" viewBox="0 0 320 512"><path d="M285.476 272.971 91.132 467.314c-9.373 9.373-24.569 9.373-33.941.0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941.0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z"/></svg></div><p class="tw-select-none !tw-my-1">plaintext</p></button><div class=tw-flex><button class="line-number-button
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
group-[.show-line-numbers]:tw-text-fgColor-link
print:!tw-hidden" title="Toggle line numbers"><svg class="icon" viewBox="0 0 512 512"><path d="M61.77 401l17.5-20.15a19.92 19.92.0 005.07-14.19v-3.31C84.34 356 80.5 352 73 352H16a8 8 0 00-8 8v16a8 8 0 008 8h22.83a157.41 157.41.0 00-11 12.31l-5.61 7c-4 5.07-5.25 10.13-2.8 14.88l1.05 1.93c3 5.76 6.29 7.88 12.25 7.88h4.73c10.33.0 15.94 2.44 15.94 9.09.0 4.72-4.2 8.22-14.36 8.22a41.54 41.54.0 01-15.47-3.12c-6.49-3.88-11.74-3.5-15.6 3.12l-5.59 9.31c-3.72 6.13-3.19 11.72 2.63 15.94 7.71 4.69 20.38 9.44 37 9.44 34.16.0 48.5-22.75 48.5-44.12-.03-14.38-9.12-29.76-28.73-34.88zM496 224H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16v-32a16 16 0 00-16-16zm0-160H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16V80a16 16 0 00-16-16zm0 320H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16v-32a16 16 0 00-16-16zM16 160h64a8 8 0 008-8v-16a8 8 0 00-8-8H64V40a8 8 0 00-8-8H32a8 8 0 00-7.14 4.42l-8 16A8 8 0 0024 64h8v64H16a8 8 0 00-8 8v16a8 8 0 008 8zm-3.91 160H80a8 8 0 008-8v-16a8 8 0 00-8-8H41.32c3.29-10.29 48.34-18.68 48.34-56.44.0-29.06-25-39.56-44.47-39.56-21.36.0-33.8 10-40.46 18.75-4.37 5.59-3 10.84 2.8 15.37l8.58 6.88c5.61 4.56 11 2.47 16.12-2.44a13.44 13.44.0 019.46-3.84c3.33.0 9.28 1.56 9.28 8.75C51 248.19.0 257.31.0 304.59v4C0 316 5.08 320 12.09 320z"/></svg></button>
<button class="wrap-code-button
tw-select-none
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
group-[.is-wrap]:tw-text-fgColor-link
print:!tw-hidden" title="Toggle code wrap"><svg class="icon" viewBox="0 0 448 512"><path d="M16 132h416c8.837.0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163.0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"/></svg></button>
<button class="copy-code-button
tw-select-none
tw-mx-2
tw-hidden
group-[.is-open]:tw-block
hover:tw-text-fgColor-link
print:!tw-hidden" title="Copy code">
<span class="copy-icon tw-block"><svg class="icon" viewBox="0 0 448 512"><path d="M433.941 65.941l-51.882-51.882A48 48 0 00348.118.0H176c-26.51.0-48 21.49-48 48v48H48c-26.51.0-48 21.49-48 48v320c0 26.51 21.49 48 48 48h224c26.51.0 48-21.49 48-48v-48h80c26.51.0 48-21.49 48-48V99.882a48 48 0 00-14.059-33.941zM266 464H54a6 6 0 01-6-6V150a6 6 0 016-6h74v224c0 26.51 21.49 48 48 48h96v42a6 6 0 01-6 6zm128-96H182a6 6 0 01-6-6V54a6 6 0 016-6h106v88c0 13.255 10.745 24 24 24h88v202a6 6 0 01-6 6zm6-256h-64V48h9.632c1.591.0 3.117.632 4.243 1.757l48.368 48.368a6 6 0 011.757 4.243V112z"/></svg></span>
<span class="check-icon tw-hidden"><svg class="icon" viewBox="0 0 512 512"><path d="M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206.0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204.0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204.0l36.203 36.204c9.997 9.997 9.997 26.206.0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z"/></svg></span>
</button>
<button class="tw-select-none
tw-mx-2
tw-block
group-[.is-open]:tw-hidden
print:!tw-hidden" disabled aria-hidden=true><svg class="icon" viewBox="0 0 512 512"><path d="M328 256c0 39.8-32.2 72-72 72s-72-32.2-72-72 32.2-72 72-72 72 32.2 72 72zm104-72c-39.8.0-72 32.2-72 72s32.2 72 72 72 72-32.2 72-72-32.2-72-72-72zm-352 0c-39.8.0-72 32.2-72 72s32.2 72 72 72 72-32.2 72-72-32.2-72-72-72z"/></svg></button></div></div><pre style=counter-reset:codeblock class="tw-block tw-m-0 tw-p-0"><code id=codeblock-id-3 class="chroma
!tw-block
tw-p-0
tw-m-0
tw-transition-[max-height]
tw-duration-500
tw-ease-in-out
group-[.is-closed]:!tw-max-h-0
group-[.is-wrap]:tw-text-wrap
tw-overflow-y-hidden
tw-overflow-x-auto
tw-scrollbar-thin"><span class=line><span class=cl>A(25, 180, 70)
</span></span><span class=line><span class=cl>B(26, 178, 72)</span></span></code></pre></div><p>他们的向量"距离"很近 → 表示两人特征相似。</p><h4 id=举例-3词语的语义向量 class=headerLink><a href=#%e4%b8%be%e4%be%8b-3%e8%af%8d%e8%af%ad%e7%9a%84%e8%af%ad%e4%b9%89%e5%90%91%e9%87%8f class=header-mark></a>举例 3：词语的语义向量</h4><p>在自然语言处理（NLP）中，模型会把每个词变成一个高维向量（比如 768 维）。</p><div class=table-wrapper><table><thead><tr><th style=text-align:>词语</th><th style=text-align:>向量（部分展示）</th></tr></thead><tbody><tr><td style=text-align:>国王</td><td style=text-align:><code>[0.25, -0.12, 0.78, …]</code></td></tr><tr><td style=text-align:>王后</td><td style=text-align:><code>[0.27, -0.10, 0.74, …]</code></td></tr><tr><td style=text-align:>男人</td><td style=text-align:><code>[0.30, -0.15, 0.70, …]</code></td></tr><tr><td style=text-align:>女人</td><td style=text-align:><code>[0.28, -0.13, 0.72, …]</code></td></tr></tbody></table></div><p>然后模型会发现：</p><blockquote><p><code>「国王」 - 「男人」 + 「女人」 ≈ 「王后」</code></p></blockquote><p>也就是说，向量之间的数学关系<strong>能表达语义关系</strong>。这就是为什么我们说：</p><blockquote><p>向量让机器"理解意义"，而不仅仅是看到文字。</p></blockquote><hr><h2 id=五llm业务流程中的token管理 class=headerLink><a href=#%e4%ba%94llm%e4%b8%9a%e5%8a%a1%e6%b5%81%e7%a8%8b%e4%b8%ad%e7%9a%84token%e7%ae%a1%e7%90%86 class=header-mark></a>五、LLM业务流程中的Token管理</h2><h3 id=51-完整业务流程 class=headerLink><a href=#51-%e5%ae%8c%e6%95%b4%e4%b8%9a%e5%8a%a1%e6%b5%81%e7%a8%8b class=header-mark></a>5.1 完整业务流程</h3><p>以下是一条"对话/问答类"应用的主流程（每步与token的关系）：</p><h4 id=1-用户输入 class=headerLink><a href=#1-%e7%94%a8%e6%88%b7%e8%be%93%e5%85%a5 class=header-mark></a>1. 用户输入</h4><ul><li><strong>文本原文</strong>：例如"帮我写一封面试感谢信"</li><li>✅ <strong>关键点</strong>：长度不可控，需要后续做清洗与限制</li></ul><h4 id=2-预处理清洗结构化 class=headerLink><a href=#2-%e9%a2%84%e5%a4%84%e7%90%86%e6%b8%85%e6%b4%97%e7%bb%93%e6%9e%84%e5%8c%96 class=header-mark></a>2. 预处理（清洗/结构化）</h4><ul><li>去除无意义空白、控制文本格式</li><li>注入角色/语气要求（Prompt模板化）</li><li>✅ <strong>关键点</strong>：减少"脏token"，用更少的token传达更清楚的意图</li></ul><h4 id=3-检索可选rag class=headerLink><a href=#3-%e6%a3%80%e7%b4%a2%e5%8f%af%e9%80%89rag class=header-mark></a>3. 检索（可选：RAG）</h4><ul><li>把用户问题向量化→在向量库里找相关文档→取回若干段落</li><li>将这些段落拼进提示词作为"上下文"</li><li>✅ <strong>关键点</strong>：检索段落要<strong>裁剪与摘要</strong>，否则容易爆上下文窗口</li></ul><h4 id=4-拼装最终prompt输入序列 class=headerLink><a href=#4-%e6%8b%bc%e8%a3%85%e6%9c%80%e7%bb%88prompt%e8%be%93%e5%85%a5%e5%ba%8f%e5%88%97 class=header-mark></a>4. 拼装最终Prompt（输入序列）</h4><ul><li><strong>组成</strong>：<code>系统指令 + 工具/函数定义 + 检索证据 + 历史对话 + 本次用户问法</code></li><li>然后<strong>Tokenizer把它们全部切成token</strong></li><li>✅ <strong>关键点</strong>：统计输入token，若接近上限：<ul><li>优先保留"高相关证据"</li><li>对历史对话做<strong>摘要/滑窗</strong></li><li>控制生成上限（max_tokens）</li></ul></li></ul><h4 id=5-模型前向与生成循环decoding class=headerLink><a href=#5-%e6%a8%a1%e5%9e%8b%e5%89%8d%e5%90%91%e4%b8%8e%e7%94%9f%e6%88%90%e5%be%aa%e7%8e%afdecoding class=header-mark></a>5. 模型前向与生成循环（Decoding）</h4><ul><li><p>模型读入输入token → 输出<strong>下一个token的概率分布</strong></p></li><li><p>采样策略（greedy/temperature/top-p…）选中下一个token</p></li><li><p>将新token<strong>追加到上下文</strong>里，再预测下一个（循环往复）</p></li><li><p>直到满足<strong>停止条件</strong>：遇到结束符 / 达到max_tokens / 命中停止词</p></li><li><p>✅ <strong>关键点</strong>：</p><ul><li><strong>输出token</strong>是"流式"推出来的</li><li>采样越"发散"（高<code>temperature</code>），token可能更多、风格更活泼</li><li>设定合理的**<code>max_tokens</code>**可以控成本与延迟</li></ul></li></ul><h4 id=6-反分词detokenization class=headerLink><a href=#6-%e5%8f%8d%e5%88%86%e8%af%8ddetokenization class=header-mark></a>6. 反分词（Detokenization）</h4><ul><li>模型输出的是token序列，需还原成文本字符串</li><li>✅ <strong>关键点</strong>：某些看似细节的空格/缩进，其实都是token的一部分</li></ul><h4 id=7-后处理post-processing class=headerLink><a href=#7-%e5%90%8e%e5%a4%84%e7%90%86post-processing class=header-mark></a>7. 后处理（Post-processing）</h4><ul><li>结构化提取、格式化成Markdown/JSON</li><li>敏感信息/合规过滤</li><li>结果摘要或多轮工具调用</li><li>✅ <strong>关键点</strong>：减少<strong>无效输出token</strong>，能降成本也提速</li></ul><h4 id=8-日志与计费 class=headerLink><a href=#8-%e6%97%a5%e5%bf%97%e4%b8%8e%e8%ae%a1%e8%b4%b9 class=header-mark></a>8. 日志与计费</h4><ul><li>记录输入/输出token数、延迟、失败重试情况</li><li>结合质量指标做提示词与检索策略迭代</li></ul><blockquote><p>🔄 <strong>流程图</strong>：</p></blockquote><figure class=center><img src=/pictures/note/2025-11-05-ai-001.svg alt=从基础概念、数学表示、模型架构、工程与优化到智能体与未来的层级关系与主要术语><figcaption><h4>AI大模型概念关联图（五层结构）</h4><p>从基础概念、数学表示、模型架构、工程与优化到智能体与未来的层级关系与主要术语</p></figcaption></figure><h3 id=52--实际案例分析 class=headerLink><a href=#52--%e5%ae%9e%e9%99%85%e6%a1%88%e4%be%8b%e5%88%86%e6%9e%90 class=header-mark></a>5.2 🎯 实际案例分析</h3><h4 id=案例1为什么长上下文不等于高质量 class=headerLink><a href=#%e6%a1%88%e4%be%8b1%e4%b8%ba%e4%bb%80%e4%b9%88%e9%95%bf%e4%b8%8a%e4%b8%8b%e6%96%87%e4%b8%8d%e7%ad%89%e4%ba%8e%e9%ab%98%e8%b4%a8%e9%87%8f class=header-mark></a>案例1：为什么"长上下文"不等于"高质量"</h4><ul><li><strong>问题</strong>：把20页文档全塞进Prompt，token爆表→不得不截断</li><li><strong>结果</strong>：反而漏掉了最相关的2段</li><li><strong>解决</strong>：<strong>检索 + 片段评分 + 摘要</strong>，用<strong>更少token</strong>保留<strong>更关键信息</strong></li></ul><h4 id=案例2控制成本与延迟 class=headerLink><a href=#%e6%a1%88%e4%be%8b2%e6%8e%a7%e5%88%b6%e6%88%90%e6%9c%ac%e4%b8%8e%e5%bb%b6%e8%bf%9f class=header-mark></a>案例2：控制成本与延迟</h4><ul><li><strong>需求</strong>：用户只要"要点列表"，没必要让模型写1,000token的长文</li><li><strong>策略</strong>：设置<code>max_tokens=120</code> + 提示"用6条要点，每条≤20字"</li><li><strong>效果</strong>：成本、时延都立降，且对齐需求</li></ul><h4 id=案例3中英token体感差异 class=headerLink><a href=#%e6%a1%88%e4%be%8b3%e4%b8%ad%e8%8b%b1token%e4%bd%93%e6%84%9f%e5%b7%ae%e5%bc%82 class=header-mark></a>案例3：中英token体感差异</h4><ul><li><strong>现象</strong>：同样100个中文字符和100个英文单词，<strong>token数通常不同</strong></li><li><strong>建议</strong>：产品层面要以<strong>真实token计数</strong>为准来做限流与预算</li></ul><h3 id=53--产品工程实操建议 class=headerLink><a href=#53--%e4%ba%a7%e5%93%81%e5%b7%a5%e7%a8%8b%e5%ae%9e%e6%93%8d%e5%bb%ba%e8%ae%ae class=header-mark></a>5.3 🛠️ 产品/工程实操建议</h3><h4 id=核心策略 class=headerLink><a href=#%e6%a0%b8%e5%bf%83%e7%ad%96%e7%95%a5 class=header-mark></a>核心策略</h4><ol><li><strong>实时token计数</strong>：在拼装Prompt后、请求模型前做一次计数，接近上限就触发"裁剪策略"</li><li><strong>分层上下文</strong>：系统指令（短且稳定）+ 高相关证据（短/精）+ 近几轮对话（摘要后）</li><li><strong>输出上限与停用词</strong>：为不同场景配置<code>max_tokens</code>和stop words，避免"越写越长"</li><li><strong>检索片段控长</strong>：给每段设置最大token，并做句内裁剪（只留命中句两侧若干字）</li><li><strong>指标闭环</strong>：记录<code>input_tokens/output_tokens/latency/success_rate</code>，用A/B迭代提示词与检索策略</li><li><strong>多语言场景</strong>：不同语言token利率不同，必要时做<strong>语言检测 + 翻译到统一语种</strong>再进模型</li></ol><hr><h2 id=六-核心要点总结 class=headerLink><a href=#%e5%85%ad-%e6%a0%b8%e5%bf%83%e8%a6%81%e7%82%b9%e6%80%bb%e7%bb%93 class=header-mark></a>六、🧠 核心要点总结</h2><h3 id=61-关键概念对照 class=headerLink><a href=#61-%e5%85%b3%e9%94%ae%e6%a6%82%e5%bf%b5%e5%af%b9%e7%85%a7 class=header-mark></a>6.1 关键概念对照</h3><div class=table-wrapper><table><thead><tr><th style=text-align:>概念</th><th style=text-align:>一句话理解</th></tr></thead><tbody><tr><td style=text-align:><strong>Token</strong></td><td style=text-align:>AI语言的"字粒子"，一切长度、速度、费用都围绕它</td></tr><tr><td style=text-align:><strong>向量</strong></td><td style=text-align:>意义的数字化表示，让机器理解语义关系</td></tr><tr><td style=text-align:><strong>Transformer</strong></td><td style=text-align:>现代AI的核心架构，通过注意力机制处理信息</td></tr></tbody></table></div><h3 id=62-学习要点回顾 class=headerLink><a href=#62-%e5%ad%a6%e4%b9%a0%e8%a6%81%e7%82%b9%e5%9b%9e%e9%a1%be class=header-mark></a>6.2 学习要点回顾</h3><ol><li><strong>基本原理</strong>：预测下一个词，通过token逐字生成</li><li><strong>核心架构</strong>：Transformer + 注意力机制</li><li><strong>关键概念</strong>：向量表示让机器理解语义</li><li><strong>实际应用</strong>：从模型到产品的完整链条</li><li><strong>Token管理</strong>：控制长度、费用、质量的关键</li></ol><h3 id=63--学习建议 class=headerLink><a href=#63--%e5%ad%a6%e4%b9%a0%e5%bb%ba%e8%ae%ae class=header-mark></a>6.3 💡 学习建议</h3><ul><li><strong>理解token概念</strong>：这是深入AI领域的关键一步，它构成了现代AI模型处理语言的基础</li><li><strong>实践token优化</strong>：在产品开发中，好的token管理能显著提升效果、降低成本</li><li><strong>掌握向量表示</strong>：理解如何将人类语言转化为机器可理解的数学形式</li></ul><blockquote><p>🚀 <strong>下一步</strong>：需要的话，我可以给你画一张「LLM业务流程×token交互点」的中文流程图，或者做一个小脚本帮你<strong>计算具体文本在不同模型里的token数</strong>并给出费用/延迟估算。</p></blockquote><hr><h2 id=-延伸阅读 class=headerLink><a href=#-%e5%bb%b6%e4%bc%b8%e9%98%85%e8%af%bb class=header-mark></a>📚 延伸阅读</h2><h3 id=-ai大模型系统教程系列 class=headerLink><a href=#-ai%e5%a4%a7%e6%a8%a1%e5%9e%8b%e7%b3%bb%e7%bb%9f%e6%95%99%e7%a8%8b%e7%b3%bb%e5%88%97 class=header-mark></a>🔗 AI大模型系统教程系列</h3><ol><li><strong>[本文] AI大模型完全指南</strong> - 从零基础到Token与向量的深度解析</li><li><strong><a href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B2/ rel>Transformer架构深度解析</a></strong> - 注意力机制与AI大模型的核心技术</li><li><strong><a href=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B3/ rel>Prompt Engineering完全指南</a></strong> - 从提示工程到上下文工程的实战教程</li><li><strong><a href=https://byronfinn.github.io/ai%E4%B8%93%E4%B8%9A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A%E8%A1%A8/ rel>AI专业名词解释表</a></strong> - 270+术语完全指南与AI技术体系词典</li></ol><h3 id=-建议学习路径 class=headerLink><a href=#-%e5%bb%ba%e8%ae%ae%e5%ad%a6%e4%b9%a0%e8%b7%af%e5%be%84 class=header-mark></a>🎯 建议学习路径</h3><ul><li><strong>初学者</strong>：先阅读本文掌握基础概念，然后查看专业名词解释表巩固术语</li><li><strong>开发者</strong>：学习完本文后，重点阅读Prompt Engineering实战教程</li><li><strong>研究者</strong>：深入学习Transformer架构，掌握AI核心技术原理</li></ul></div><h2>相关内容</h2><div class=related-container><div class=related-item-container><h2 class=related-title><a href=/ai%E6%95%99%E7%A8%8B2/>Transformer架构深度解析：注意力机制与AI大模型的核心技术</a></h2></div><div class=related-item-container><h2 class=related-title><a href=/ai%E4%B8%93%E4%B8%9A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A%E8%A1%A8/>AI专业名词解释表：270+术语完全指南与AI技术体系词典</a></h2></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>更新于 2025-11-06</span></div><div class=post-info-license></div></div><div class="post-info-line print:!tw-hidden"><div class=post-info-md></div><div class=post-info-share><button title="分享到 Twitter" data-sharer=twitter data-url=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B1/ data-title=AI大模型完全指南：从零基础到Token与向量的深度解析 data-hashtags=AI大模型,LLM,Token机制,向量表示,Transformer架构,深度学习,神经网络,人工智能教程><svg class="icon" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></button><button title="分享到 Evernote" data-sharer=evernote data-url=https://byronfinn.github.io/ai%E6%95%99%E7%A8%8B1/ data-title=AI大模型完全指南：从零基础到Token与向量的深度解析><svg class="icon" viewBox="0 0 384 512"><path d="M120.82 132.21c1.6 22.31-17.55 21.59-21.61 21.59-68.93.0-73.64-1-83.58 3.34-.56.22-.74.0-.37-.37L123.79 46.45c.38-.37.6-.22.38.37-4.35 9.99-3.35 15.09-3.35 85.39zm79 308c-14.68-37.08 13-76.93 52.52-76.62 17.49.0 22.6 23.21 7.95 31.42-6.19 3.3-24.95 1.74-25.14 19.2-.05 17.09 19.67 25 31.2 24.89A45.64 45.64.0 00312 393.45v-.08c0-11.63-7.79-47.22-47.54-55.34-7.72-1.54-65-6.35-68.35-50.52-3.74 16.93-17.4 63.49-43.11 69.09-8.74 1.94-69.68 7.64-112.92-36.77.0.0-18.57-15.23-28.23-57.95-3.38-15.75-9.28-39.7-11.14-62 0-18 11.14-30.45 25.07-32.2 81 0 90 2.32 101-7.8 9.82-9.24 7.8-15.5 7.8-102.78 1-8.3 7.79-30.81 53.41-24.14 6 .86 31.91 4.18 37.48 30.64l64.26 11.15c20.43 3.71 70.94 7 80.6 57.94 22.66 121.09 8.91 238.46 7.8 238.46C362.15 485.53 267.06 480 267.06 480c-18.95-.23-54.25-9.4-67.27-39.83zm80.94-204.84c-1 1.92-2.2 6 .85 7 14.09 4.93 39.75 6.84 45.88 5.53 3.11-.25 3.05-4.43 2.48-6.65-3.53-21.85-40.83-26.5-49.24-5.92z"/></svg></button></div></div></div><div class=post-info-more><section class=post-tags><svg class="icon" viewBox="0 0 640 512"><path d="M497.941 225.941 286.059 14.059A48 48 0 00252.118.0H48C21.49.0.0 21.49.0 48v204.118a48 48 0 0014.059 33.941l211.882 211.882c18.744 18.745 49.136 18.746 67.882.0l204.118-204.118c18.745-18.745 18.745-49.137.0-67.882zM112 160c-26.51.0-48-21.49-48-48s21.49-48 48-48 48 21.49 48 48-21.49 48-48 48zm513.941 133.823L421.823 497.941c-18.745 18.745-49.137 18.745-67.882.0l-.36-.36L527.64 323.522c16.999-16.999 26.36-39.6 26.36-63.64s-9.362-46.641-26.36-63.64L331.397.0h48.721a48 48 0 0133.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137.0 67.882z"/></svg>&nbsp;<a href=/tags/ai%E5%A4%A7%E6%A8%A1%E5%9E%8B/>AI大模型</a>,&nbsp;<a href=/tags/llm/>LLM</a>,&nbsp;<a href=/tags/token%E6%9C%BA%E5%88%B6/>Token机制</a>,&nbsp;<a href=/tags/%E5%90%91%E9%87%8F%E8%A1%A8%E7%A4%BA/>向量表示</a>,&nbsp;<a href=/tags/transformer%E6%9E%B6%E6%9E%84/>Transformer架构</a>,&nbsp;<a href=/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/>深度学习</a>,&nbsp;<a href=/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/>神经网络</a>,&nbsp;<a href=/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%95%99%E7%A8%8B/>人工智能教程</a></section><section class=print:!tw-hidden><span><button class="tw-text-fgColor-link-muted hover:tw-text-fgColor-link-muted-hover" onclick=window.history.back()>返回</button></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class="post-nav print:tw-hidden"><a href=/ai%E6%95%99%E7%A8%8B2/ class=prev rel=prev title=Transformer架构深度解析：注意力机制与AI大模型的核心技术><svg class="icon" viewBox="0 0 256 512"><path d="M31.7 239l136-136c9.4-9.4 24.6-9.4 33.9.0l22.6 22.6c9.4 9.4 9.4 24.6.0 33.9L127.9 256l96.4 96.4c9.4 9.4 9.4 24.6.0 33.9L201.7 409c-9.4 9.4-24.6 9.4-33.9.0l-136-136c-9.5-9.4-9.5-24.6-.1-34z"/></svg>Transformer架构深度解析：注意力机制与AI大模型的核心技术</a></div></div><div id=comments class="print:!tw-hidden tw-pt-32 tw-pb-8"><div id=giscus></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://giscus.app/>giscus</a>.</noscript></div></article></main><footer class=footer><div class=footer-container><div class=footer-line><svg class="icon" viewBox="0 0 512 512"><path d="M256 8C119.033 8 8 119.033 8 256s111.033 248 248 248 248-111.033 248-248S392.967 8 256 8zm0 448c-110.532.0-2e2-89.451-2e2-2e2.0-110.531 89.451-2e2 2e2-2e2 110.532.0 2e2 89.451 2e2 2e2.0 110.532-89.451 2e2-2e2 2e2zm107.351-101.064c-9.614 9.712-45.53 41.396-104.065 41.396-82.43.0-140.484-61.425-140.484-141.567.0-79.152 60.275-139.401 139.762-139.401 55.531.0 88.738 26.62 97.593 34.779a11.965 11.965.0 011.936 15.322l-18.155 28.113c-3.841 5.95-11.966 7.282-17.499 2.921-8.595-6.776-31.814-22.538-61.708-22.538-48.303.0-77.916 35.33-77.916 80.082.0 41.589 26.888 83.692 78.277 83.692 32.657.0 56.843-19.039 65.726-27.225 5.27-4.857 13.596-4.039 17.82 1.738l19.865 27.17a11.947 11.947.0 01-1.152 15.518z"/></svg>2025<span class=author>&nbsp;<a href=https://blog.baifan.site target=_blank rel="noopener noreferrer">Finn</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class=footer-line></div><div class=footer-line></div></div><script>"serviceWorker"in navigator&&(navigator.serviceWorker.register("/sw.min.js",{scope:"/"}).then(function(){}),navigator.serviceWorker.ready.then(function(){}))</script></footer><div class="print:!tw-hidden tw-flex tw-flex-col tw-fixed tw-right-4 tw-bottom-4 tw-gap-2"><a href=#back-to-top id=back-to-top-button class="tw-transition-opacity tw-opacity-0 tw-block tw-bg-bgColor-secondary tw-rounded-full" style=padding:.6rem;line-height:1.3rem;font-size:1rem title=回到顶部><svg class="icon" viewBox="0 0 448 512"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6.0-33.9L207 39c9.4-9.4 24.6-9.4 33.9.0l194.3 194.3c9.4 9.4 9.4 24.6.0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3.0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg>
</a><button id=toc-drawer-button class="tw-block tw-bg-bgColor-secondary tw-rounded-full md:tw-hidden" style=padding:.6rem;line-height:1.3rem;font-size:1rem>
<svg class="icon" viewBox="0 0 448 512"><path d="M16 132h416c8.837.0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163.0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837.0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837.0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"/></svg>
</button><a href=#comments id=view-comments class="tw-block tw-bg-bgColor-secondary tw-rounded-full" style=padding:.6rem;line-height:1.3rem;font-size:1rem title=查看评论>
<svg class="icon" viewBox="0 0 512 512"><path d="M256 32C114.6 32 0 125.1.0 240c0 49.6 21.4 95 57 130.7C44.5 421.1 2.7 466 2.2 466.5c-2.2 2.3-2.8 5.7-1.5 8.7S4.8 480 8 480c66.3.0 116-31.8 140.6-51.4 32.7 12.3 69 19.4 107.4 19.4 141.4.0 256-93.1 256-208S397.4 32 256 32z"/></svg></a></div><div id=cookieconsent-container></div><link rel=stylesheet href=/lib/katex/katex.min.0c8126645bb983a788b167b1b97abe2505a962ad45e049001463c46012012a9b.css integrity="sha256-DIEmZFu5g6eIsWexuXq+JQWpYq1F4EkAFGPEYBIBKps="><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/katex/copy-tex.min.cf8e3e934d92a839d209ffdac331fa693da5958a6dff2c8788a4713cc1f50a47.css integrity="sha256-z44+k02SqDnSCf/awzH6aT2llYpt/yyHiKRxPMH1Ckc="><noscript><link rel=stylesheet href=/lib/katex/copy-tex.min.cf8e3e934d92a839d209ffdac331fa693da5958a6dff2c8788a4713cc1f50a47.css integrity="sha256-z44+k02SqDnSCf/awzH6aT2llYpt/yyHiKRxPMH1Ckc="></noscript><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.cd0d0b6e50ff01ff2f3a9a70d7cfb66a7c6cb9acf7a566325568be6d3bd31fc4.css integrity="sha256-zQ0LblD/Af8vOppw18+2anxsuaz3pWYyVWi+bTvTH8Q="><script>window.config={"autocomplete.min.js":"/lib/autocomplete/autocomplete.min.js",comment:{giscus:{darkTheme:"dark",dataCategory:"Announcements",dataCategoryId:"DIC_kwDOQOVlP84Cxa17",dataEmitMetadata:"0",dataInputPosition:"top",dataLang:"zh-CN",dataLoading:"lazy",dataMapping:"pathname",dataReactionsEnabled:"1",dataRepo:"ByronFinn/ByronFinn.github.io",dataRepoId:"R_kgDOQOVlPw",dataStrict:"0",lightTheme:"light"}},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验."},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},data:{"desktop-header-typeit":"Daily Deep Think","mobile-header-typeit":"Daily Deep Think"},"fuse.min.js":"/lib/fuse/fuse.min.js",math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{distance:100,findAllMatches:!1,fuseIndexURL:"/index.json",highlightTag:"em",ignoreFieldNorm:!1,ignoreLocation:!1,isCaseSensitive:!1,location:0,maxResultLength:10,minMatchCharLength:2,noResultsFound:"没有找到结果",snippetLength:50,threshold:.3,type:"fuse",useExtendedSearch:!1},sharerjs:!0,table:{sort:!0},twemoji:!0,typeit:{cursorChar:"|",cursorSpeed:1e3,data:{"desktop-header-typeit":["desktop-header-typeit"],"mobile-header-typeit":["mobile-header-typeit"]},duration:-1,speed:100}}</script><script src=/lib/tablesort/tablesort.min.92de6dec051677787aed63503575b2f9be73f21f2745574e59647bc139a92d40.js integrity="sha256-kt5t7AUWd3h67WNQNXWy+b5z8h8nRVdOWWR7wTmpLUA="></script><script src=/lib/twemoji/twemoji.min.0e0e5259e3ff8ea805e0c5660c6336f7f46b14332e3cafb82939e1db3da8b6f8.js integrity="sha256-Dg5SWeP/jqgF4MVmDGM29/RrFDMuPK+4KTnh2z2otvg=" defer></script><script src=/js/twemoji.min.js defer></script><script src=/lib/sharer/sharer.min.8fe10eb615eb163a20f795484430a012805ec7c8c11df52df54ddb7a46084254.js integrity="sha256-j+EOthXrFjog95VIRDCgEoBex8jBHfUt9U3bekYIQlQ="></script><script src=/lib/typeit/typeit.min.06e0b9ba7bb3c9368aa26979037019306fef8e43dd2b9276854d227381445d0f.js integrity="sha256-BuC5unuzyTaKoml5A3AZMG/vjkPdK5J2hU0ic4FEXQ8="></script><script src=/lib/katex/katex.min.76d534cf1167067008fca12c4e903fc44cf8cfda8c5279c318d1f78cd90b086e.js integrity="sha256-dtU0zxFnBnAI/KEsTpA/xEz4z9qMUnnDGNH3jNkLCG4=" defer></script><script src=/lib/katex/auto-render.min.bb53eb953394531aae36fdd537065c4244eb8542901a3ce914601d932675b8ac.js integrity="sha256-u1PrlTOUUxquNv3VNwZcQkTrhUKQGjzpFGAdkyZ1uKw=" defer></script><script src=/lib/katex/copy-tex.min.07770af90943a1de1a1010794bc78c6a7346d46d48fb63e35cc76ba76b827604.js integrity="sha256-B3cK+QlDod4aEBB5S8eManNG1G1I+2PjXMdrp2uCdgQ=" defer></script><script src=/lib/katex/mhchem.min.9f87e5e9c384a160472d0045035a8641f6013358eddb3ece708634a50f946a40.js integrity="sha256-n4fl6cOEoWBHLQBFA1qGQfYBM1jt2z7OcIY0pQ+UakA=" defer></script><script src=/js/katex.min.js defer></script><script src=/lib/cookieconsent/cookieconsent.min.e55842a856a6d829feca3c3ad736c136b6c7549e9247274f78aa296259e06e24.js integrity="sha256-5VhCqFam2Cn+yjw61zbBNrbHVJ6SRydPeKopYlngbiQ=" defer></script><script src=/js/cookieconsent.min.js defer></script><script src=/js/theme.min.js defer></script><script src=/js/giscus.min.js defer></script><script type=speculationrules>
  {
    "prerender": [
      {
        "where": { "href_matches": "/*" },
        "eagerness": "moderate"
      }
    ]
  }
</script></body></html>